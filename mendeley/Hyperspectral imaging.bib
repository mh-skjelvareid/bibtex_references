Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Sivertsen2012a,
abstract = {Detection of objects embedded in tissue, using visible light, is difficult due to light scattering. The optical properties of the surrounding tissue will influence the spectral characteristics of the light interacting with the object, and the spectral signature observed from the object will be directly affected. A method for calibrating the spectral signature of small objects, embedded in translucent material, by the estimated local background spectrum is presented. The method is evaluated under industrial conditions in a new hyperspectral imaging system for automatic detection of nematodes in cod fillets. The system operates at a conveyor belt speed of 400mm/s which meets the industrial required speed of assessing one fillet per second. The local calibration method reduces the number of spectra needed to be classified by 89.6%. For one or more false alarms in 60% of the fillets sampled after the trimming station, the Gaussian maximum likelihood classifier detects 70.8% and 60.3% of the dark and pale nematodes, respectively. This is better than what is previously reported using a higher resolution instrument on a slow moving conveyor belt, and comparable or better to what is reported for manual inspection under industrial conditions.},
author = {Sivertsen, Agnar H. and Heia, Karsten and Hindberg, Kristian and Godtliebsen, Fred},
file = {:C\:/Users/mha114/Dropbox/Litteratur_Mendeley/2012/Sivertsen et al._2012_Automatic nematode detection in cod fillets (Gadus morhua L.) by hyperspectral imaging.pdf:pdf},
journal = {Journal of Food Engineering},
keywords = {Hyperspectral imaging,Image processing,Imaging spectroscopy,Industrial fish fillet inspection,Local calibration},
number = {4},
pages = {675--681},
title = {{Automatic nematode detection in cod fillets (Gadus morhua L.) by hyperspectral imaging}},
url = {http://www.sciencedirect.com/science/article/pii/S0260877412001161},
volume = {111},
year = {2012}
}
@article{Casal2012,
abstract = {R{\'{i}}a de Vigo and R{\'{i}}a de Ald{\'{a}}n have high biological richness that is reflected in the number of environmental protection areas like the Atlantic Islands National Park and five places of community interest. Benthic algal communities play an important role in these ecosystems due to their ecological functions and support a great part of this biological richness. We tested by means of bio-optical modelling and Airborne Hyperspectral Scanner (AHS) images to what extent remote sensing could be used to map these communities in R{\'{i}}a de Vigo and R{\'{i}}a de Ald{\'{a}}n (NW Spain). Reflectance spectra of dominating macroalgae groups were modelled for different water depths in order to estimate the separability of different bottom types based on their spectral signatures and the spectral characteristics of the AHS. Our results indicate that separation between three macroalgae groups (green, brown and red) as well as sand is possible when the bottoms are emerged during low tide. The spectra differences decrease rapidly with increasing water depth. Two types of classifications were carried out with the three AHS images: maximum likelihood and spectral angle mapper (SAM). Maximum likelihood showed positive results reaching overall accuracy percentages higher than 95 % and kappa coefficients higher than 0. 90 for the bottom classes: shallow sand, deep sand, emerged rock, emerged macroalgae and submerged macroalgae. Sand and algae substrates were then separately analysed with SAM. These classifications showed positive results for differentiation between green and brown macroalgae until 5 m depth and high differences between all macroalgae and sandy substrate. However, differences between red and brown macroalgae are only detectable when the algae are emerged. {\textcopyright} 2012 Springer-Verlag.},
author = {Casal, G. and S{\'{a}}nchez-Carnero, N. and Dom{\'{i}}nguez-G{\'{o}}mez, J. A. and Kutser, T. and Freire, J.},
doi = {10.1007/s00227-012-1987-5},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2012/Casal et al._2012_Assessment of AHS (Airborne Hyperspectral Scanner) sensor to map macroalgal communities on the R{\'{i}}a de vigo and R{\'{i}}a de.pdf:pdf},
issn = {00253162},
journal = {Marine Biology},
keywords = {Freshwater & Marine Ecology,Marine & Freshwater Sciences,Microbiology,Oceanography,Zoology},
month = {sep},
number = {9},
pages = {1997--2013},
publisher = {Springer},
title = {{Assessment of AHS (Airborne Hyperspectral Scanner) sensor to map macroalgal communities on the R{\'{i}}a de vigo and R{\'{i}}a de Ald{\'{a}}n coast (NW Spain)}},
url = {https://link.springer.com/article/10.1007/s00227-012-1987-5},
volume = {159},
year = {2012}
}
@misc{Hennessy2020,
abstract = {Hyperspectral sensing, measuring reflectance over visible to shortwave infrared wavelengths, has enabled the classification and mapping of vegetation at a range of taxonomic scales, often down to the species level. Classification with hyperspectral measurements, acquired by narrow band spectroradiometers or imaging sensors, has generally required some form of spectral feature selection to reduce the dimensionality of the data to a level suitable for the construction of a classification model. Despite the large number of hyperspectral plant classification studies, an in-depth review of feature selection methods and resultant waveband selections has not yet been performed. Here, we present a review of the last 22 years of hyperspectral vegetation classification literature that evaluates the overall waveband selection frequency, waveband selection frequency variation by taxonomic, structural, or functional group, and the influence of feature selection choice by comparing such methods as stepwise discriminant analysis (SDA), support vector machines (SVM), and random forests (RF). This review determined that all characteristics of hyperspectral plant studies influence the wavebands selected for classification. This includes the taxonomic, structural, and functional groups of the target samples, the methods, and scale at which hyperspectral measurements are recorded, as well as the feature selection method used. Furthermore, these influences do not appear to be consistent. Moreover, the considerable variability in waveband selection caused by the feature selectors effectively masks the analysis of any variability between studies related to plant groupings. Additionally, questions are raised about the suitability of SDA as a feature selection method, with it producing waveband selections at odds with the other feature selectors. Caution is recommended when choosing a feature selector for hyperspectral plant classification: We recommend multiple methods being performed. The resultant sets of selected spectral features can either be evaluated individually by multiple classification models or combined as an ensemble for evaluation by a single classifier. Additionally, we suggest caution when relying upon waveband recommendations from the literature to guide waveband selections or classifications for new plant discrimination applications, as such recommendations appear to be weakly generalizable between studies.},
author = {Hennessy, Andrew and Clarke, Kenneth and Lewis, Megan},
booktitle = {Remote Sensing},
doi = {10.3390/RS12010113},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2020/Hennessy, Clarke, Lewis_2020_Hyperspectral Classification of Plants A Review of Waveband Selection Generalisability.pdf:pdf},
issn = {20724292},
keywords = {Classification,Discrimination,Feature selection,Hyperspectral,Plant,Random forest,Spectra,Support vector machine,Vegetation,Waveband selection},
month = {jan},
number = {1},
pages = {113},
publisher = {MDPI AG},
title = {{Hyperspectral classification of plants: A review of waveband selection generalisability}},
url = {https://www.mdpi.com/2072-4292/12/1/113},
volume = {12},
year = {2020}
}
@article{Dumke2018,
abstract = {Identification of benthic megafauna is commonly based on analysis of physical samples or imagery acquired by cameras mounted on underwater platforms. Physical collection of samples is difficult, particularly from the deep sea, and identification of taxonomic morphotypes from imagery depends on resolution and investigator experience. Here, we show how an Underwater Hyperspectral Imager (UHI) can be used as an alternative in situ taxonomic tool for benthic megafauna. A UHI provides a much higher spectral resolution than standard RGB imagery, allowing marine organisms to be identified based on specific optical fingerprints. A set of reference spectra from identified organisms is established and supervised classification performed to identify benthic megafauna semi-autonomously. The UHI data provide an increased detection rate for small megafauna difficult to resolve in standard RGB imagery. In addition, seafloor anomalies with distinct spectral signatures are also detectable. In the region investigated, sediment anomalies (spectral reflectance minimum at $\sim$675 nm) unclear in RGB imagery were indicative of chlorophyll a on the seafloor. Underwater hyperspectral imaging therefore has a great potential in seafloor habitat mapping and monitoring, with areas of application ranging from shallow coastal areas to the deep sea.},
author = {Dumke, Ines and Purser, Autun and Marcon, Yann and Nornes, Stein M. and Johnsen, Geir and Ludvigsen, Martin and S{\o}reide, Fredrik},
doi = {10.1038/s41598-018-31261-4},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2018/Dumke et al._2018_Underwater hyperspectral imaging as an in situ taxonomic tool for deep-sea megafauna.pdf:pdf},
issn = {20452322},
journal = {Scientific Reports},
keywords = {Ecology,Imaging and sensing,Marine biology},
month = {dec},
number = {1},
pages = {12860},
pmid = {30150709},
publisher = {Nature Publishing Group},
title = {{Underwater hyperspectral imaging as an in situ taxonomic tool for deep-sea megafauna}},
url = {http://www.nature.com/articles/s41598-018-31261-4},
volume = {8},
year = {2018}
}
@article{Douay2022,
abstract = {The recent development and miniaturization of hyperspectral sensors embedded in drones has allowed the acquisition of hyperspectral images with high spectral and spatial resolution. The characteristics of both the embedded sensors and drones (viewing angle, flying altitude, resolution) create opportunities to consider the use of hyperspectral imagery to map and monitor macroalgae communities. In general, the overflight of the areas to be mapped is conconmittently associated accompanied with measurements carried out in the field to acquire the spectra of previously identified objects. An alternative to these simultaneous acquisitions is to use a hyperspectral library made up of pure spectra of the different species in place, that would spare field acquisition of spectra during each flight. However, the use of such a technique requires developed appropriate procedure for testing the level of species classification that can be achieved, as well as the reproducibility of the classification over time. This study presents a novel classification approach based on the use of reflectance spectra of macroalgae acquired in controlled conditions. This overall approach developed is based on both the use of the spectral angle mapper (SAM) algorithm applied on first derivative hyperspectral data. The efficiency of this approach has been tested on a hyperspectral library composed of 16 macroalgae species, and its temporal reproducibility has been tested on a monthly survey of the spectral response of different macro-algae species. In addition, the classification results obtained with this new approach were also compared to the results obtained through the use of the most recent and robust procedure published. The classification obtained shows that the developed approach allows to perfectly discriminate the different phyla, whatever the period. At the species level, the classification approach is less effective when the individuals studied belong to phylogenetically close species (i.e., Fucus spiralis and Fucus serratus).},
author = {Douay, Florian and Verpoorter, Charles and Duong, Gwendoline and Spilmont, Nicolas and Gevaert, Fran{\c{c}}ois},
doi = {10.3390/rs14020346},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2022/Douay et al._2022_New Hyperspectral Procedure to Discriminate Intertidal Macroalgae.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Hyperspectral library,Intertidal macroalgae,Photosynthetic pigments,Spectral classification},
number = {2},
title = {{New Hyperspectral Procedure to Discriminate Intertidal Macroalgae}},
volume = {14},
year = {2022}
}
@article{Schlapfer2020,
abstract = {Remote sensing with unmanned aerial vehicles (UAVs) is a fast and cost-efficient tool for mapping and environmental monitoring. The sensors are operated at low flight altitudes, usually below 500 m above ground, leading to spatial resolutions up to the centimeter range. This type of data causes new challenges in atmospheric compensation and surface reflectance retrieval. Based on these specific boundary conditions, a new drone based atmospheric correction concept (DROACOR) is proposed, which is designed for currently available UAV based sensors. It is suited for multispectral visible/near infrared sensors as well as hyperspectral instruments covering the 400-1000&thinsp;nm spectral region or the 400-2500&thinsp;nm spectrum. The goal of the development is a fully automatic processor which dynamically adjusts to the given instrument and the atmospheric conditions. Optionally, irradiance measurements from simultaneously measured cosine receptors or from in-field reference panels can be taken into account to improve the processing quality by adjusting the irradiance parameter or by performing an in-flight vicarious calibration. Examples of DROACOR processing results are presented for a multispectral image data set and a hyperspectral data set, both acquired at variable flight altitudes. The resulting spectra show the applicability of the methods for both sensor types and an accuracy level below 2.5% reflectance units.},
author = {Schl{\"{a}}pfer, D. and Popp, C. and Richter, R.},
doi = {10.5194/isprs-archives-XLIII-B3-2020-473-2020},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2020/Schl{\"{a}}pfer, Popp, Richter_2020_Drone data atmospheric correction concept for multi-and hyperspectral imagery-The droacor model.pdf:pdf},
issn = {16821750},
journal = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
keywords = {Atmospheric Correction,Drone data processing,Reflectance Retrieval,irradiance correction},
number = {B3},
pages = {473--478},
title = {{Drone data atmospheric correction concept for multi-and hyperspectral imagery-The droacor model}},
volume = {43},
year = {2020}
}
@article{Hill2014,
abstract = {Seagrasses provide a number of critical ecosystem services, including habitat for numerous species, sediment stabilization, and shoreline protection. Ariel photography is a useful tool to estimate the areal extent of seagrasses, but recent innovations in radiometrically calibrated sensors and algorithm development have allowed identification of benthic types and retrieval of absolute density. This study demonstrates the quantitative ability of a high spatial resolution (1 m) airborne hyperspectral sensor (3.2 nm bandwidth) in the complex coastal waters of Saint Joseph's Bay (SJB). Several benthic types were distinguished, including submerged and floating aquatic vegetation, benthic red algae, bare sand, and optically deep water. A total of 23.6 km2 of benthic vegetation was detected, indicating no dramatic change in vegetation area over the past 30 years. SJB supported high seagrass density at depths shallower than 2 m with an average leaf area index of 2.0 ± 0.6 m2 m−2. Annual seagrass production in the bay was 13,570 t C year−1 and represented 41 % of total marine primary production. The effects of coarser spatial resolution were investigated and found to reduce biomass retrievals, underestimate productivity, and alter patch size statistics. Although data requirements for this approach are considerable, water column optical modeling may reduce the in situ requirements and facilitate the transition of this technique to routine monitoring efforts. The ability to quantify not just areal extent but also productivity of a seagrass meadow in optically complex coastal waters can provide information on the capacity of these environments to support marine food webs.},
author = {Hill, Victoria J. and Zimmerman, Richard C. and Bissett, W. Paul and Dierssen, Heidi and Kohler, David D.R.},
doi = {10.1007/s12237-013-9764-3},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2014/Hill et al._2014_Evaluating Light Availability, Seagrass Biomass, and Productivity Using Hyperspectral Airborne Remote Sensing in Saint.pdf:pdf},
issn = {15592731},
journal = {Estuaries and Coasts},
keywords = {Hyperspectral,Remote sensing,Seagrass,Spatial patterns,Submarine landscape},
month = {nov},
number = {6},
pages = {1467--1489},
publisher = {Springer US},
title = {{Evaluating Light Availability, Seagrass Biomass, and Productivity Using Hyperspectral Airborne Remote Sensing in Saint Joseph's Bay, Florida}},
url = {http://link.springer.com/10.1007/s12237-013-9764-3},
volume = {37},
year = {2014}
}
@article{Kutser2020a,
abstract = {Technical advancements have widened the limits of remote sensing in mapping shallow water benthic habitats and bathymetry over the last decades. On the other hand, the needs of shallow water remote sensing have pushed instrument development. In this manuscript we provide 50-year retrospective of the developments in the field in terms of both instrumentation and methods. We also show that spectral features characteristic of the main benthic groups in shallow water are consistent from the tropics to sub-arctic regions and from salty to freshwaters. The fundamental limiting factor in both benthic mapping and bathymetry is absorption of light by water molecules. However, spectral absorption by water molecules is the key to bathymetry derivation. Variable backscattering by particles and absorption by dissolved organic matter is a confounding factor for all objectives. The combination of using the spectral and textural characteristics of bottom features and our knowledge about these features have now resulted in the ability to map habitats over large coastal systems. This manuscript has shown that optically shallow water remote sensing has reached levels where the satellite derived bathymetry and habitat maps are accepted by different end users (including the International Maritime Organisation) and are routinely used in ecological studies, monitoring and management of coastal environments.},
author = {Kutser, Tiit and Hedley, John and Giardino, Claudia and Roelfsema, Chris and Brando, Vittorio E.},
doi = {10.1016/j.rse.2019.111619},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2020/Kutser et al._2020_Remote sensing of shallow waters – A 50 year retrospective and future directions.pdf:pdf},
issn = {00344257},
journal = {Remote Sensing of Environment},
month = {apr},
pages = {111619},
publisher = {Elsevier Inc.},
title = {{Remote sensing of shallow waters – A 50 year retrospective and future directions}},
volume = {240},
year = {2020}
}
@article{Dierssen2003a,
abstract = {New coastal ocean remote sensing techniques permit benthic habitats to be explored with higher resolution than ever before. A mechanistic radiative transfer approach is developed that first removes the distorting influence of the water column on the remotely sensed signal to retrieve an estimate of the reflectance at the seafloor. The retrieved bottom reflectance is then used to classify the benthos. This spectrally based approach is advantageous because model components are separate and can be evaluated and modified individually for different environments. Here, we applied our approach to quantitatively estimate shallow-water bathymetry and leaf area index (LAI) of the seagrass Thalassia testudinum for a study site near Lee Stocking Island, Bahamas. Two high-resolution images were obtained from the ocean portable hyperspectral imager for low-light spectroscopy (Ocean PHILLS) over the study site in May 1999 and 2000. A combination of in situ observations of seafloor reflectance and radiative transfer modeling was used to develop and test our algorithm. Bathymetry was mapped to meter-scale resolution using a site-specific relationship (r2 = 0.97) derived from spectral ratios of remote sensing reflectance at 555 and 670 nm. Depth-independent bottom reflectance was retrieved from remote sensing reflectance using bathymetry and tables of modeled water column attenuation coefficients. The magnitude of retrieved bottom reflectance was highly correlated to seagrass LAI measured from diver surveys at seven stations within the image (r2 = 0.88-0.98). Mapped turtlegrass LAI was remarkably stable over a 2-yr period at our study site, even though Hurricane Floyd swept over the study site in September 1999.},
author = {Dierssen, Heidi M. and Zimmerman, Richard C. and Leathers, Robert A. and Downes, T. Valerie and Davis, Curtiss O.},
doi = {10.4319/lo.2003.48.1_part_2.0444},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2003/Dierssen et al._2003_Ocean color remote sensing of seagrass and bathymetry in the Bahamas Banks by high-resolution airborne imagery.pdf:pdf},
isbn = {0014971003},
issn = {00243590},
journal = {Limnology and Oceanography},
number = {1 II},
pages = {444--455},
title = {{Ocean color remote sensing of seagrass and bathymetry in the Bahamas Banks by high-resolution airborne imagery}},
volume = {48},
year = {2003}
}
@article{Mogstad2019,
abstract = {The impacts of human activity on coastal ecosystems are becoming increasingly evident across the world. Consequently, there is a growing need to map, monitor, and manage these regions in a sustainable manner. In this pilot study, we present what we believe to be a novel mapping technique for shallow-water seafloor habitats: Underwater hyperspectral imaging (UHI) from an unmanned surface vehicle (USV). A USV-based UHI survey was carried out in a sheltered bay close to Trondheim, Norway. In the survey, an area of 176 m2 was covered, and the depth of the surveyed area was approximately 1.5 m. UHI data were initially recorded at a 1-nm spectral resolution within the range of 380–800 nm, but this was reduced to 86 spectral bands between 400-700 nm (3.5-nm spectral resolution) during post-processing. The hyperspectral image acquisition was synchronized with navigation data from the USV, which permitted georeferencing and mosaicking of the imagery at a 0.5-cm spatial resolution. Six spectral classes, including coralline algae, the wrack Fucus serratus, green algal films, and invertebrates, were identified in the georeferenced imagery, and chosen as targets for support vector machine (SVM) classification. Based on confusion matrix analyses, the overall classification accuracy was estimated to be 89%–91%, which suggests that USV-based UHI may serve as a useful tool for high-resolution mapping of shallow-water habitats in the future.},
author = {Mogstad, Aksel Alstad and Johnsen, Geir and Ludvigsen, Martin},
doi = {10.3390/rs11060685},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2019/Mogstad, Johnsen, Ludvigsen_2019_Shallow-Water Habitat Mapping using Underwater Hyperspectral Imaging from an Unmanned Surface Vehicle A.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Shallow-water habitat mapping,Supervised classification,Support vector machine (SVM),Underwater hyperspectral imaging (UHI),Unmanned surface vehicle (USV)},
month = {mar},
number = {6},
pages = {685},
publisher = {Multidisciplinary Digital Publishing Institute},
title = {{Shallow-Water Habitat Mapping using Underwater Hyperspectral Imaging from an Unmanned Surface Vehicle: A Pilot Study}},
url = {https://www.mdpi.com/2072-4292/11/6/685},
volume = {11},
year = {2019}
}
@article{Zhang2015,
abstract = {An Airborne Imaging Spectrometer for Applications (AISA) hyperspectral imager was deployed on a manned aircraft flown at 1305-m altitude to collect data over optically shallow waters in the Florida Keys with the ultimate goal of mapping water quality and benthic habitats. As a first step, we developed a practical atmospheric correction (AC) approach to derive surface remote-sensing reflectance ((Rrs) from AISA measurements using radiative transfer simulations and constraints obtained from field spectral Rrs measurements. Unlike previously published method, the AC approach removes the surface Fresnel reflection and accounts for aircraft altitude and nonzero near-infrared (NIR) reflectance through iteration over the pre-established look-up tables (LUTs) based on MODTRAN calculations. Simulations and comparison with concurrent in situRrs measurements show the feasibility of the approach in deriving surface Rrs with acceptable uncertainties. The possibility of errors in the radiometric calibration of AISA is demonstrated, although a definitive assessment cannot be made due to lack of enough concurrent in situ measurements. The need for noise reduction and the difficulty in carrying out a vicarious calibration are also discussed to help advance the design of future AISA missions.},
author = {Zhang, Minwei and Hu, Chuanmin and English, David and Carlson, Paul and Muller-Karger, Frank E. and Toro-Farmer, Gerardo and Herwitz, Stanley R.},
doi = {10.1109/JSTARS.2015.2437326},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2015/Zhang et al._2015_Atmospheric Correction of AISA Measurements over the Florida Keys Optically Shallow Waters Challenges in Radiometric C.pdf:pdf},
issn = {21511535},
journal = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
keywords = {Airborne Imaging Spectrometer for Applications (AI,MODTRAN,airborne remote sensing,atmospheric correction (AC),noise reduction,ocean color,vicarious calibration},
month = {aug},
number = {8},
pages = {4189--4196},
title = {{Atmospheric Correction of AISA Measurements over the Florida Keys Optically Shallow Waters: Challenges in Radiometric Calibration and Aerosol Selection}},
url = {http://ieeexplore.ieee.org/document/7120080/},
volume = {8},
year = {2015}
}
@article{Lee2015,
abstract = {In 2007, the NASA Hyperspectral InfraRed Imager (HyspIRI) mission was recommended in Earth Science and Applications from Space: National Imperatives for the Next Decade and Beyond (Decadal Survey) to address critical science questions in multiple areas, in particular ecosystems and natural hazards. HyspIRI is comprised of two instruments, a visible to short-wavelength infrared (VSWIR) imaging spectrometer and a thermal infrared (TIR) multispectral imager, together with an Intelligent Payload Module (IPM) for onboard processing and rapid downlink of selected data. The VSWIR instrument will have 10. nm contiguous bands and cover the 380-2500. nm spectral range with 30. m spatial resolution and a revisit of 16 days. The TIR instrument will have 8 discrete bands in the 4-13 $\mu$m range with 60 m spatial resolution and a revisit of 5 days. With these two instruments in low Earth orbit, HyspIRI will be able to address key science and applications questions in a wide array of fields, ranging from ecosystem function and diversity to human health and urbanization.},
author = {Lee, Christine M. and Cable, Morgan L. and Hook, Simon J. and Green, Robert O. and Ustin, Susan L. and Mandl, Daniel J. and Middleton, Elizabeth M.},
doi = {10.1016/j.rse.2015.06.012},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2015/Lee et al._2015_An introduction to the NASA Hyperspectral InfraRed Imager (HyspIRI) mission and preparatory activities.pdf:pdf},
issn = {00344257},
journal = {Remote Sensing of Environment},
keywords = {Aquatic systems,Decadal survey,ECOSTRESS,Hyperspectral imager,Imaging spectroscopy,Intelligent payload module,TIR,Terrestrial ecology,VSWIR},
month = {sep},
pages = {6--19},
publisher = {Elsevier},
title = {{An introduction to the NASA Hyperspectral InfraRed Imager (HyspIRI) mission and preparatory activities}},
url = {https://www.sciencedirect.com/science/article/pii/S0034425715300419},
volume = {167},
year = {2015}
}
@article{Li2017,
abstract = {Recent research has shown that using spectral-spatial information can considerably improve the performance of hyperspectral image (HSI) classification. HSI data is typically presented in the format of 3D cubes. Thus, 3D spatial filtering naturally offers a simple and effective method for simultaneously extracting the spectral-spatial features within such images. In this paper, a 3D convolutional neural network (3D-CNN) framework is proposed for accurate HSI classification. The proposed method views the HSI cube data altogether without relying on any preprocessing or post-processing, extracting the deep spectral-spatial-combined features effectively. In addition, it requires fewer parameters than other deep learning-based methods. Thus, the model is lighter, less likely to over-fit, and easier to train. For comparison and validation, we test the proposed method along with three other deep learning-based HSI classification methods-namely, stacked autoencoder (SAE), deep brief network (DBN), and 2D-CNN-based methods-on three real-world HSI datasets captured by different sensors. Experimental results demonstrate that our 3D-CNN-based method outperforms these state-of-the-art methods and sets a new record.},
author = {Li, Ying and Zhang, Haokui and Shen, Qiang},
doi = {10.3390/rs9010067},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2017/Li, Zhang, Shen_2017_Spectral–Spatial Classification of Hyperspectral Imagery with 3D Convolutional Neural Network.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {2D convolutional neural networks,3D convolutional neural networks,3D structure,Deep learning,Hyperspectral image classification},
month = {jan},
number = {1},
pages = {67},
publisher = {Multidisciplinary Digital Publishing Institute},
title = {{Spectral-spatial classification of hyperspectral imagery with 3D convolutional neural network}},
url = {https://www.mdpi.com/2072-4292/9/1/67/htm https://www.mdpi.com/2072-4292/9/1/67},
volume = {9},
year = {2017}
}
@article{Kemker2017,
abstract = {In this paper, we study self-taught learning for hyperspectral image (HSI) classification. Supervised deep learning methods are currently state of the art for many machine learning problems, but these methods require large quantities of labeled data to be effective. Unfortunately, existing labeled HSI benchmarks are too small to directly train a deep supervised network. Alternatively, we used self-taught learning, which is an unsupervised method to learn feature extracting frameworks from unlabeled hyperspectral imagery. These models learn how to extract generalizable features by training on sufficiently large quantities of unlabeled data that are distinct from the target data set. Once trained, these models can extract features from smaller labeled target data sets. We studied two self-taught learning frameworks for HSI classification. The first is a shallow approach that uses independent component analysis and the second is a three-layer stacked convolutional autoencoder. Our models are applied to the Indian Pines, Salinas Valley, and Pavia University data sets, which were captured by two separate sensors at different altitudes. Despite large variation in scene type, our algorithms achieve state-of-the-art results across all the three data sets.},
author = {Kemker, Ronald and Kanan, Christopher},
doi = {10.1109/TGRS.2017.2651639},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2017/Kemker, Kanan_2017_Self-Taught Feature Learning for Hyperspectral Image Classification.pdf:pdf},
issn = {01962892},
journal = {IEEE Transactions on Geoscience and Remote Sensing},
keywords = {Autoencoder,deep learning,feature learning,hyperspectral imaging,independent component analysis (ICA),self-taught learning},
number = {5},
pages = {2693--2705},
publisher = {IEEE},
title = {{Self-Taught Feature Learning for Hyperspectral Image Classification}},
volume = {55},
year = {2017}
}
@article{Trier2018,
abstract = {This article compares four new automatic methods to discriminate between spruce, pine and birch, which are the dominating tree species in Norwegian forests. Airborne laser scanning and hyperspectral data were used. The laser scanning data was used to mask pixels with low or no vegetation in the hyperspectral data. A green–blue ratio was used to remove shadow areas from tree canopies, and the normalized difference vegetation index to remove dead vegetation and non-vegetation. The best method was hyperspectral pixel classification with 160 spectral channels in the visible and near-infrared spectrum, using a deep neural network. This method achieved 87% correct classification rate. Partial least squares regression for hyperspectral pixel classification achieved 78%. Deep neural network image classification using canopy height blended with three hyperspectral channels achieved 74%. A simple pixel classification method based on two spectral indices resulted in 67% correct classification. A possible future improvement is to find a better way to combine hyperspectral data with canopy height data in a deep neural network.},
author = {Trier, {\O}ivind Due and Salberg, Arnt B{\o}rre and Kermit, Martin and Rudjord, {\O}ystein and Gobakken, Terje and N{\ae}sset, Erik and Aarsten, Dagrun},
doi = {10.1080/22797254.2018.1434424},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2018/Trier et al._2018_Tree species classification in Norway from airborne hyperspectral and airborne laser scanning data.pdf:pdf},
issn = {22797254},
journal = {European Journal of Remote Sensing},
keywords = {Lidar,automatic processing,canopy height model,deep learning,forestry,imaging spectroscopy},
month = {jan},
number = {1},
pages = {336--351},
publisher = {Taylor & Francis},
title = {{Tree species classification in Norway from airborne hyperspectral and airborne laser scanning data}},
url = {https://www.tandfonline.com/doi/abs/10.1080/22797254.2018.1434424},
volume = {51},
year = {2018}
}
@article{Roth2015,
abstract = {Imaging spectroscopy has been used successfully to map species across diverse ecosystems, and with several spaceborne imaging spectrometer missions underway (e.g., Hyperspectral Infrared Imager (HyspIRI), Environmental Mapping and Analysis Program (EnMAP)), these data may soon be available globally. Still, most studies have focused only on single ecosystems, and many different classification strategies have been used, making it difficult to assess the potential for mapping dominant species on a broader scale. Here we compare a number of classification approaches across five contrasting ecosystems containing an expansive diversity of species and plant functional types in an effort to find a robust strategy for discriminating among dominant plant species within and across ecosystems. We evaluated the performance of combinations of methods of training data selection (stratified random selection and iterative endmember selection (IES)), spectral dimension reduction methods (canonical discriminant analysis (CDA) and partial least squares regression (PLSR)) and classification algorithms (linear discriminant analysis (LDA) and Multiple Endmember Spectral Mixture Analysis (MESMA)). Accuracy was assessed using an independent validation data set. Mean kappa coefficients for all strategies ranged from 0.48 to 0.85 for each ecosystem. Maximum kappa values and overall accuracies within each ecosystem ranged from 0.56 to 0.90 and 61-92%, respectively. Our findings show that both LDA and MESMA are able to discriminate among species to a high degree of accuracy in most ecosystems, with LDA performing slightly better. Spectral dimension reduction generally improved these results, particularly in conjunction with MESMA. Within each ecosystem, both the number and identities of functional types present, as well as the spatial distribution of dominant species, played a strong role in classification accuracy. In a pooled ecosystem classification, using CDA and LDA, we discriminated among 65 classes with an overall accuracy of 70% for the validation library, using only a 6% training sample. Our results suggest that a spaceborne imaging spectrometer such as HyspIRI will be able to map dominant plant species on a broader scale.},
author = {Roth, Keely L. and Roberts, Dar A. and Dennison, Philip E. and Alonzo, Michael and Peterson, Seth H. and Beland, Michael},
doi = {10.1016/j.rse.2015.05.007},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2015/Roth et al._2015_Differentiating plant species within and across diverse ecosystems with imaging spectroscopy.pdf:pdf},
issn = {00344257},
journal = {Remote Sensing of Environment},
keywords = {AVIRIS,Discriminant analysis,Hyperspectral,Imaging spectroscopy,MESMA,Plant species classification},
month = {sep},
pages = {135--151},
publisher = {Elsevier},
title = {{Differentiating plant species within and across diverse ecosystems with imaging spectroscopy}},
url = {https://www.sciencedirect.com/science/article/pii/S0034425715300067},
volume = {167},
year = {2015}
}
@article{Parsons2018b,
abstract = {Recent advances in unmanned aerial system (UAS) sensed imagery, sensor quality/size, and geospatial image processing can enable UASs to rapidly and continually monitor coral reefs, to determine the type of coral and signs of coral bleaching. This paper describes an unmanned aerial vehicle (UAV) remote sensing methodology to increase the efficiency and accuracy of existing surveillance practices. The methodology uses a UAV integrated with advanced digital hyperspectral, ultra HD colour (RGB) sensors, and machine learning algorithms. This paper describes the combination of airborne RGB and hyperspectral imagery with in-water survey data of several types in-water survey of coral under diverse levels of bleaching. The paper also describes the technology used, the sensors, the UAS, the flight operations, the processing workflow of the datasets, the methods for combining multiple airborne and in-water datasets, and finally presents relevant results of material classification. The development of the methodology for the collection and analysis of airborne hyperspectral and RGB imagery would provide coral reef researchers, other scientists, and UAV practitioners with reliable data collection protocols and faster processing techniques to achieve remote sensing objectives.},
author = {Parsons, Mark and Bratanov, Dmitry and Gaston, Kevin J and Gonzalez, Felipe},
doi = {10.3390/s18072026},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2018/Parsons et al._2018_UAVs, Hyperspectral Remote Sensing, and Machine Learning Revolutionizing Reef Monitoring.pdf:pdf},
journal = {Sensors},
keywords = {UAS,drones,hyperspectral camera,image segmentation,in-water survey,machine learning,support vector machines (SVM)},
number = {7},
pages = {2026},
title = {{UAVs, Hyperspectral Remote Sensing, and Machine Learning Revolutionizing Reef Monitoring}},
url = {www.mdpi.com/journal/sensors},
volume = {18},
year = {2018}
}
@article{Masarczyk2020,
abstract = {Hyperspectral imaging is a rich source of data, allowing for a multitude of effective applications. However, such imaging remains challenging because of large data dimension and, typically, a small pool of available training examples. While deep learning approaches have been shown to be successful in providing effective classification solutions, especially for high dimensional problems, unfortunately they work best with a lot of labelled examples available. The transfer learning approach can be used to alleviate the second requirement for a particular dataset: first the network is pre-trained on some dataset with large amount of training labels available, then the actual dataset is used to fine-tune the network. This strategy is not straightforward to apply with hyperspectral images, as it is often the case that only one particular image of some type or characteristic is available. In this paper, we propose and investigate a simple and effective strategy of transfer learning that uses unsupervised pre-training step without label information. This approach can be applied to many of the hyperspectral classification problems. The performed experiments show that it is very effective at improving the classification accuracy without being restricted to a particular image type or neural network architecture. The experiments were carried out on several deep neural network architectures and various sizes of labeled training sets. The greatest improvement in overall accuracy on the Indian Pines and Pavia University datasets is over 21 and 13 percentage points, respectively. An additional advantage of the proposed approach is the unsupervised nature of the pre-training step, which can be done immediately after image acquisition, without the need of the potentially costly expert's time.},
archivePrefix = {arXiv},
arxivId = {1909.05507},
author = {Masarczyk, Wojciech and Glomb, Przemyslaw and Grabowski, Bartosz and Ostaszewski, Mateusz},
doi = {10.3390/RS12162653},
eprint = {1909.05507},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2020/Masarczyk et al._2020_Effective training of deep convolutional neural networks for hyperspectral image classification through artificial.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Convolutional neural networks,Deep learning,Hyperspectral image classification,Transfer learning,Unsupervised training sample selection},
month = {aug},
number = {16},
pages = {2653},
publisher = {Multidisciplinary Digital Publishing Institute},
title = {{Effective training of deep convolutional neural networks for hyperspectral image classification through artificial labeling}},
url = {https://www.mdpi.com/2072-4292/12/16/2653/htm https://www.mdpi.com/2072-4292/12/16/2653},
volume = {12},
year = {2020}
}
@misc{Johansen2020,
abstract = {Skin cancer is one of the most common types of cancer. Skin cancers are classified as nonmelanoma and melanoma, with the first type being the most frequent and the second type being the most deadly. The key to effective treatment of skin cancer is early detection. With the recent increase of computational power, the number of algorithms to detect and classify skin lesions has increased. The overall verdict on systems based on clinical and dermoscopic images captured with conventional RGB (red, green, and blue) cameras is that they do not outperform dermatologists. Computer-based systems based on conventional RGB images seem to have reached an upper limit in their performance, while emerging technologies such as hyperspectral and multispectral imaging might possibly improve the results. These types of images can explore spectral regions beyond the human eye capabilities. Feature selection and dimensionality reduction are crucial parts of extracting salient information from this type of data. It is necessary to extend current classification methodologies to use all of the spatiospectral information, and deep learning models should be explored since they are capable of learning robust feature detectors from data. There is a lack of large, high-quality datasets of hyperspectral skin lesion images, and there is a need for tools that can aid with monitoring the evolution of skin lesions over time. To understand the rich information contained in hyperspectral images, further research using data science and statistical methodologies, such as functional data analysis, scale-space theory, machine learning, and so on, are essential. This article is categorized under: Applications of Computational Statistics > Health and Medical Data/Informatics.},
author = {Johansen, Thomas Haugland and M{\o}llersen, Kajsa and Ortega, Samuel and Fabelo, Himar and Garcia, Aday and Callico, Gustavo M. and Godtliebsen, Fred},
booktitle = {Wiley Interdisciplinary Reviews: Computational Statistics},
doi = {10.1002/wics.1465},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2020/Johansen et al._2020_Recent advances in hyperspectral imaging for melanoma detection.pdf:pdf},
issn = {19390068},
keywords = {hyperspectral,machine learning,melanoma,skin cancer},
month = {jan},
number = {1},
pages = {e1465},
publisher = {John Wiley & Sons, Ltd},
title = {{Recent advances in hyperspectral imaging for melanoma detection}},
url = {https://onlinelibrary.wiley.com/doi/full/10.1002/wics.1465 https://onlinelibrary.wiley.com/doi/abs/10.1002/wics.1465 https://wires.onlinelibrary.wiley.com/doi/10.1002/wics.1465},
volume = {12},
year = {2020}
}
@article{Yu2017,
abstract = {As a powerful visual model, convolutional neural networks (CNNs) have demonstrated remarkable performance in various visual recognition problems, and attracted considerable attention in recent years. However, due to the highly correlated bands and insufficient training samples of hyperspectral image data, it still remains a challenging problem to effectively apply the CNN models on hyperspectral images. In this paper, an efficient CNN architecture has been proposed to boost its discriminative capability for hyperspectral image classification, in which the original data is used as the input and the final CNN outputs are the predicted class-related results. The proposed CNN infrastructure has several distinct advantages. Firstly, different from traditional classification methods those need hand-crafted features, the CNN model used here is designed to deal with the problem of hyperspectral image analysis in an end-to-end way. Secondly, the parameters of the CNN model are optimized from a small training set, while the over-fitting problem of the neural network has been alleviated to some extent. Finally, in order to better deal with the hyperspectral image information, 1 × 1 convolutional layers have been adopted, and an average pooling layer and larger dropout rates have also been employed in the whole CNN procedure. The experiments on three benchmark data sets have demonstrated that the proposed CNN architecture considerably outperforms other state-of-the-art methods.},
author = {Yu, Shiqi and Jia, Sen and Xu, Chunyan},
doi = {10.1016/j.neucom.2016.09.010},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Convolutional neural networks,Deep learning,Hyperspectral image classification},
month = {jan},
pages = {88--98},
publisher = {Elsevier B.V.},
title = {{Convolutional neural networks for hyperspectral image classification}},
volume = {219},
year = {2017}
}
@article{Pu2012,
abstract = {Pu, R.; Bell, S.; Baggett, L.; Meyer, C., and Zhao, Y., 2012. Discrimination of seagrass species and cover classes with in situ hyperspectral data. Seagrass habitats support a variety of ecosystem functions and an increasing interest has emerged for utilizing remote sensing to acquire information on the spatial extent and abundance of seagrass vegetation. Here we report on hyperspectral data collected from a combined laboratory and field-based study to examine the spectral qualities of seagrass species and evaluate whether seagrass species and levels of seagrass cover could be distinguished using true in situ hyperspectral data collected by a spectrometer overlying sea-grass-dominated vegetation in a shallow water setting in the central west coast of Florida. We also analyzed hyperspectral data measured in the lab to compare with those from in situ collections. Using a set of 97 field measurements we compared spectra qualities for different seagrass species, levels of seagrass cover, water depths, and substrate types over wavelengths 400-800 nm, using spectral data preprocessing and data transformation. Optimal wavelengths for identifying seagrass species and levels of seagrass cover were determined by two-sample t-tests. We also utilized principal component analysis (PCA) on spectra to evaluate if a set of first five PCs could be used to discriminate effectively among seagrass species and levels of seagrass cover. The experimental results indicate that the best accuracies for identifying species were produced with the data set of the second -derivative normalized spectra. The optimal wavelengths were 450, 500, 520, 550, 600, 620, 680, and 700 nm, most of which are related to the peaks of reflectance and absorption bands by photosynthetic and accessory pigments. A set of five optimal bands produced higher accuracies for identifying seagrass species (overall accuracy = 73% and average accuracy = 75%) compared with those from use of PCA. Data preprocessing techniques were demonstrated to be effective for improving discriminant accuracies of species and levels of seagrass cover. {\textcopyright} Coastal Education & Research Foundation 2012.},
author = {Pu, Ruiliang and Bell, Susan and Baggett, Lesley and Meyer, Cynthia and Zhao, Yongchao},
doi = {10.2112/JCOASTRES-D-11-00229.1},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2012/Pu et al._2012_Discrimination of seagrass species and cover classes with in situ hyperspectral data.pdf:pdf},
issn = {07490208},
journal = {Journal of Coastal Research},
keywords = {Derivative spectra,Remote sensing,Seagrass,Spectral normalization,Submerged aquatic vegetation (SAV)},
number = {6},
pages = {1330--1344},
title = {{Discrimination of seagrass species and cover classes with in situ hyperspectral data}},
volume = {28},
year = {2012}
}
@article{Heia2007a,
abstract = {A promising method for detection of parasites in whitefish fillets has been developed. By use of imaging spectroscopy it is possible to record both spectral and spatial information from an object. In this work it is shown that by applying a white light transmission setup and imaging spectroscopy to cod (Gadus morhua) fillets, it is possible to make spectral images containing information to differentiate between fish muscle and parasites. The spectral images are analyzed by discriminant partial least square regression as well as image-filtering techniques. The method identifies parasites on the surface of the fillets as well as embedded parasites. One parasite was detected at 0.8 cm below the fillet surface, which is 2 to 3 mm deeper than what can be found by manual inspection of fish fillets. The method is nonintrusive and should thus be feasible for industrial purposes.},
author = {Heia, Karsten and Sivertsen, Agnar H and Stormo, Svein K and Elvevoll, Edel and Wold, Jens Petter and Nilsen, Heidi},
doi = {10.1111/j.1750-3841.2006.00212.x},
file = {:C\:/Users/mha114/Dropbox/Litteratur_Mendeley/2007/Heia et al._2007_Detection of nematodes in cod (Gadus morhua) fillets by imaging spectroscopy.pdf:pdf},
issn = {1750-3841},
journal = {Journal of food science},
keywords = {Animals,Consumer Product Safety,Food Contamination,Food Contamination: analysis,Food Parasitology,Gadus morhua,Gadus morhua: parasitology,Humans,Nematoda,Nematoda: isolation & purification,Quality Control,Seafood,Seafood: parasitology,Seafood: standards,Spectrum Analysis,Spectrum Analysis: methods},
month = {jan},
number = {1},
pages = {E011--5},
pmid = {17995879},
title = {{Detection of nematodes in cod (Gadus morhua) fillets by imaging spectroscopy.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17995879},
volume = {72},
year = {2007}
}
@inproceedings{Ziph-Schatzberg2015,
abstract = {Hyperspectral imaging (HSI) is a technology that is rapidly transitioning from laboratory research and field demonstration to real-world deployment for a variety of applications. These applications include precision agriculture, manufacturing process monitoring, mineral and petroleum exploration, environmental management, disaster mitigation, defense intelligence/surveillance/reconnaissance for threat detection and identification, as well as a host of applications within the bio-medical field. Application-specific algorithms are continuously being developed to support the world-wide expanding use of HSI. Corning Incorporated has been developing and manufacturing HSI sensors, sensor systems, and sensor optical engines, as well as HSI sensor components such as gratings and slits for over a decade and a half. Corning's gratings include UV to IR spectral coverage, multiple glass, metallic, and non-metallic substrates, substrate figures from plane to spherical, to biconic aspheres, application optimized groove profiles from triangular to dual blaze to phase stepped, and groove periods from regular to chirped to aberration correcting. This depth of experience and technological breadth has allowed Corning to design and develop unique HSI spectrographs with an unprecedented combination of high performance, low cost and low Size, Weight, and Power (SWaP). These sensors and sensor systems are offered with wavelength coverage ranges from the visible to the Long Wave Infrared (LWIR). The extremely low SWaP of Corning HSI sensors and sensor systems enables their deployment using limited payload platforms such as small unmanned aerial vehicles (UAVs) or human hands. Mobile applications are also facilitated by Corning's built-in miniature scanner that works seamlessly with a compact push-broom HSI sensor using Corning proprietary software to collect complete data cubes. This paper discusses proprietary designs of Corning HSI sensors and systems, as well as the inhouse manufacturing capabilities that enable the cost-effective fabrication of these sensors. Specific designs of Corning HSI visNIR, SWIR and uncooled LWIR systems are presented along with salient performance characteristics. We also discuss the use of Corning HSI sensor systems for real-world applications. &copy; 2015 SPIE.},
author = {Ziph-Schatzberg, Leah and Woodman, Patrick and Nakanishi, Keith and Cornell, Jim and Wiggins, Richard and Swartz, Barry and Holasek, Rick},
booktitle = {Next-Generation Spectroscopic Technologies VIII},
doi = {10.1117/12.2177564},
editor = {Druy, Mark A. and Crocombe, Richard A. and Bannon, David P.},
isbn = {9781628415988},
issn = {1996756X},
keywords = {Solid block Offner,diffraction grating,hyperspectral,imaging spectrometer,monolithic Offner,precision optics manufacturing,spectral imaging},
month = {jun},
pages = {94820W},
publisher = {SPIE},
title = {{Compact, high performance hyperspectral systems design and applications}},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2177564},
volume = {9482},
year = {2015}
}
@article{He2020,
abstract = {We propose a novel method and system that utilizes a popular smartphone to realize hyperspectral imaging for analyzing skin morphological features and monitoring hemodynamics. The imaging system works based on a built-in RGB camera and flashlight on the smartphone. We apply Wiener estimation to transform the acquired RGB-mode images into “pseudo”-hyperspectral images with 16 wavebands, covering a visible range from 470nm to 620nm. The processing method uses weighted subtractions between wavebands to extract absorption information caused by specific chromophores within skin tissue, mainly including hemoglobin and melanin. Based on the extracted absorption information of hemoglobin, we conduct real-time monitoring experiments in the skin to measure heart rate and to observe skin activities during a vascular occlusion event. Compared with expensive hyperspectral imaging systems, the smartphone-based system delivers similar results but with very-high imaging resolution. Besides, it is easy to operate, very cost-effective and has a wider customer base. The use of an unmodified smartphone to realize hyperspectral imaging promises a possibility to bring a hyperspectral analysis of skin out from laboratory and clinical wards to daily life, which may also impact on healthcare in low resource settings and rural areas.},
author = {He, Qinghua and Wang, Ruikang},
doi = {10.1364/boe.378470},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2020/He, Wang_2020_Hyperspectral imaging enabled by an unmodified smartphone for analyzing skin morphological features and monitoring hemodyn.pdf:pdf},
issn = {2156-7085},
journal = {Biomedical Optics Express},
keywords = {Hyperspectral imaging,Imaging systems,Imaging techniques,Liquid crystal filters,Multispectral imaging,Spectral imaging},
month = {feb},
number = {2},
pages = {895},
publisher = {The Optical Society},
title = {{Hyperspectral imaging enabled by an unmodified smartphone for analyzing skin morphological features and monitoring hemodynamics}},
volume = {11},
year = {2020}
}
@article{Volent2007,
abstract = {We present an easy and efficient approach for remote sensing of ocean color, relevant for monitoring and management of kelp forest and bottom substrate with a cheap custom made hyperspectral imager. Remote sensing of ocean color was performed in the Kongsfjord, Spitsbergen (79 deg N and 12 deg E) from an airplane (2950 m altitude) equipped with a hyperspectral imager, giving monochromatic images (425-825 nm) using the push broom technique, captured with custom designed software in 5 nm steps. Synchronously in situ measurements of upwelling spectral irradiance, (Eu($\lambda$))($\lambda$= 350-950 nm) measured at 30 cm depth were performed as a reference for the remotely sensed images. Surface water samples were taken for enumeration and identification of organic (plankton), inorganic particles, and colored dissolved organic matter. For identification and classification of kelp and bottom substrate, Bayesian supervised classification and a differential histogram equalization technique were used and compared. Both techniques gave successful discrimination between kelp and bottom substrate in shallow water above the Secchi depth (},
author = {Volent, Zsolt and Johnsen, Geir and Sigernes, Fred},
doi = {10.1117/1.2822611},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2007/Volent, Johnsen, Sigernes_2007_Kelp forest mapping by use of airborne hyperspectral imager.pdf:pdf},
issn = {1931-3195},
journal = {Journal of Applied Remote Sensing},
keywords = {Arctic fjord water,hyperspectral imaging,kelp forest mapping,ocean color,upwelling spectral irradiance},
month = {dec},
number = {1},
pages = {011503},
publisher = {International Society for Optics and Photonics},
title = {{Kelp forest mapping by use of airborne hyperspectral imager}},
url = {http://remotesensing.spiedigitallibrary.org/article.aspx?doi=10.1117/1.2822611},
volume = {1},
year = {2007}
}
@article{Valle2015,
abstract = {Estuaries and coasts are among the most productive ecosystems and constitute valuable habitats for biodiversity and ecosystem services. Amongst nearshore ecosystems, seagrass beds play a major role enhancing biodiversity and water quality. Consequently, the development of new approaches to create extensive and high-resolution habitat maps is required not only to implement conservation, restoration and management plans, but also to establish adaptation plans to face climate change impacts. This study particularly assesses the capability of hyperspectral airborne imagery acquired with Compact Airborne Spectrographic Imager (CASI) to discriminate and map estuarine habitats, with special focus on Zostera noltii seagrass meadows. To this end, 13 habitats were defined along the supralittoral, intertidal and subtidal zones of an estuary, including Z.noltii seagrass meadows. The CASI sensor was configured to acquire 25 bands in the visible and near infrared wavelengths with a ground sampling distance of 2 m. Spectral bands were selected for species discrimination based on the spectral signature of the different habitat classes. Six different band combinations were tested applying maximum likelihood classification algorithm. The most accurate classification was obtained with 10 band combination (a mean producer accuracy 92% and a mean user accuracy 94%). The classification of Z.noltii beds has been found to be restricted to moderate and high dense meadows, however a vegetation index has been defined which could be applied for mapping Z. noltii meadow cover. These results highlight the value of CASI data to discriminate and map estuarine habitats, providing key information to be used in supporting the implementation of environmental legislation, protection and conservation of coastal habitats.},
author = {Valle, Mireia and Pal{\`{a}}, Vicen{\c{c}} and Lafon, Virgine and Dehouck, Aur{\'{e}}lie and Garmendia, Joxe Mikel and Borja, {\'{A}}ngel and Chust, Guillem},
doi = {10.1016/j.ecss.2015.07.034},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2015/Valle et al._2015_Mapping estuarine habitats using airborne hyperspectral imagery, with special focus on seagrass meadows.pdf:pdf},
issn = {02727714},
journal = {Estuarine, Coastal and Shelf Science},
keywords = {Compact airborne spectrographic imager,Estuaries,Habitat classification,Remote sensing,Zostera noltii},
month = {oct},
pages = {433--442},
publisher = {Academic Press},
title = {{Mapping estuarine habitats using airborne hyperspectral imagery, with special focus on seagrass meadows}},
volume = {164},
year = {2015}
}
@article{Tao2014,
abstract = {Sensor simulators can be used in forecasting the imaging quality of a new hyperspectral imaging spectrometer, and generating simulated data for the development and validation of the data processing algorithms. This paper presents a novel digital sensor simulator for the pushbroom Offner hyperspectral imaging spectrometer, which is widely used in the hyperspectral remote sensing. Based on the imaging process, the sensor simulator consists of a spatial response module, a spectral response module, and a radiometric response module. In order to enhance the simulation accuracy, spatial interpolation-resampling, which is implemented before the spatial degradation, is developed to compromise the direction error and the extra aliasing effect. Instead of using the spectral response function (SRF), the dispersive imaging characteristics of the Offner convex grating optical system is accurately modeled by its configuration parameters. The non-uniformity characteristics, such as keystone and smile effects, are simulated in the corresponding modules. In this work, the spatial, spectral and radiometric calibration processes are simulated to provide the parameters of modulation transfer function (MTF), SRF and radiometric calibration parameters of the sensor simulator. Some uncertainty factors (the stability, band width of the monochromator for the spectral calibration, and the integrating sphere uncertainty for the radiometric calibration) are considered in the simulation of the calibration process. With the calibration parameters, several experiments were designed to validate the spatial, spectral and radiometric response of the sensor simulator, respectively. The experiment results indicate that the sensor simulator is valid.},
author = {Tao, Dongxing and Jia, Guorui and Yuan, Yan and Zhao, Huijie},
doi = {10.3390/s141223822},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2014/Tao et al._2014_A digital sensor simulator of the pushbroom offner hyperspectral imaging spectrometer.pdf:pdf},
issn = {14248220},
journal = {Sensors (Switzerland)},
keywords = {Hyperspectral,Offner,Sensor simulator},
month = {dec},
number = {12},
pages = {23822--23842},
publisher = {Multidisciplinary Digital Publishing Institute},
title = {{A digital sensor simulator of the pushbroom offner hyperspectral imaging spectrometer}},
url = {http://www.mdpi.com/1424-8220/14/12/23822},
volume = {14},
year = {2014}
}
@article{Zhang2016,
abstract = {An atmospheric correction algorithm has been developed for the Airborne Imaging Spectrometer for Applications (AISA) imagery over optically shallow waters in Sugarloaf Key of the Florida Keys. The AISA data were collected repeatedly during several days in May 2012, October 2012, and May 2013. Non-zero near-infrared (NIR) remote-sensing reflectance (Rrs) was accounted for through iterations, based on the relationship of field-measured Rrs between the NIR and red wavelengths. Validation showed mean ratios of 0.94–1.002 between AISA-retrieved and in situ Rrs in the blue to red wavelengths, with uncertainties generally <0.003 sr–1. Such an approach led to observations of short-term changes in AISA-retrieved Rrs from repeated measurements over waters with bottom types of seagrass meadow, sand, and patch reef. Some of these changes are larger than twofold the Rrs uncertainties from AISA retrievals, therefore representing statistically significant changes that can be well observed from airborne measurements. Through radiative transfer modelling, we demonstrated that short-term Rrs changes within 1 hour resulted primarily from sediment resuspension, while tides played a relatively minor role due to the small variation in tidal heights. A sensitivity analysis indicated that although Rrs generally increases with decreasing tide height but increasing suspended sediments, more changes were observed over sandy bottom than over seagrass. The case study suggests that repeated airborne measurements may be used to study short-term changes in shallow-water environments, and such a capacity may be enhanced with future geostationary satellite missions specifically designed to observe coastal ecosystems.},
author = {Zhang, Minwei and English, David and Hu, Chuanmin and Carlson, Paul and Muller-Karger, Frank E. and Toro-Farmer, Gerardo and Herwitz, Stanley R.},
doi = {10.1080/01431161.2016.1159746},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2016/Zhang et al._2016_Short-term changes of remote sensing reflectancein a shallow-water environment observations from repeated airborne hyp.pdf:pdf},
issn = {13665901},
journal = {International Journal of Remote Sensing},
month = {apr},
number = {7},
pages = {1620--1638},
publisher = {Taylor & Francis},
title = {{Short-term changes of remote sensing reflectancein a shallow-water environment: observations from repeated airborne hyperspectral measurements}},
url = {http://www.tandfonline.com/doi/full/10.1080/01431161.2016.1159746},
volume = {37},
year = {2016}
}
@article{Pu2015,
abstract = {Seagrass habitats are characteristic features of shallow waters worldwide and provide a variety of ecosystem functions. To date, few studies have evaluated the efficiency of spectral vegetation indices (VIs) for characterizing aquatic plants. Here we evaluate the use of in situ hyperspectral data and hyperspectral VIs for distinguishing among seagrass species and levels of percentage submerged aquatic vegetation (%SAV) cover in a subtropical shallow water setting. Analysis procedures include (1) retrieving bottom reflectance, (2) calculating correlation matrices of VIs with %SAV cover and F value matrices from analysis of variance among species, (3) testing the difference of VIs between levels of %SAV cover and between species, and (4) discriminating levels of %SAV cover and species by using linear discriminant analysis (LDA) and classification and regression trees (CART) classifiers with selected VIs as input. The experimental results indicated that (1) the best VIs for discriminating the four levels of %SAV cover were simple ratio (SR) VI, normalized difference VI (NDVI), modified simple ratio VI, and NDVI × SR, whereas the best VIs for distinguishing the three seagrass species included the weighted difference VI, soil-adjusted VI (SAVI), SAVI × SR and transformed SAVI; (2) the optimal central wavelengths for constructing the best VIs were 460, 500, 610, 640, 660, and 690 nm with spectral regions ranging from 3 to 20 nm at band width 3 nm, most of which were associated with absorption bands by photosynthetic and other accessory pigments in the visible spectral range. Compared with LDA, CART performed better in discriminating the four levels of %SAV cover and identifying the three seagrass species.},
author = {Pu, Ruiliang and Bell, Susan and English, David},
doi = {10.2112/JCOASTRES-D-12-00272.1},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2015/Pu, Bell, English_2015_Developing Hyperspectral Vegetation Indices for Identifying Seagrass Species and Cover Classes.pdf:pdf},
issn = {15515036},
journal = {Journal of Coastal Research},
keywords = {Seagrass,bottom reflectance retrieval,hyperspectral remote sensing,hyperspectral vegetation index,submerged aquatic vegetation (SAV)},
month = {may},
number = {3},
pages = {595--615},
publisher = {The Coastal Education and Research Foundation},
title = {{Developing Hyperspectral Vegetation Indices for Identifying Seagrass Species and Cover Classes}},
url = {http://www.bioone.org/doi/10.2112/JCOASTRES-D-12-00272.1},
volume = {31},
year = {2015}
}
@article{Zhong2020,
abstract = {Unmanned aerial vehicle (UAV)-borne hyperspectral systems can acquire hyperspectral imagery with a high spatial resolution (which we refer to here as H2 imagery). As a result of the low operating cost, high flexibility, and the ability to achieve real-time data acquisition, UAV-borne hyperspectral systems have become an important data source for remote sensing based agricultural monitoring. However, precise crop classification based on UAV-borne H2 imagery is a challenging task when faced with a number of different crop classes. The traditional hyperspectral classification methods, such as the spectral-based and object-oriented classification methods, have difficulty in classifying H2 imagery, faced with the problems of salt-and-pepper (SP) noise and scale selection. In this article, the deep convolutional neural network with a conditional random field classifier (CNNCRF) framework is proposed for precise crop classification with UAV-borne H2 imagery. In the proposed method, a deep convolutional neural network (CNN) is designed to extract and fuse in-depth spectral and local spatial features, and the conditional random field (CRF) model further incorporates the spatial-contextual information to improve the problem of holes and isolated regions in the classification map. Meanwhile, virtual sample augmentation based on the hyperspectral imaging mechanism is used to lessen the issue of the limited labeled samples. To validate the results, a new dataset—the Wuhan UAV-borne hyperspectral image (WHU-Hi) dataset—has been built for precise crop classification. The experimental results obtained using the WHU-Hi dataset confirm the accuracy and visualization performance of the proposed CNNCRF classification method, which outperforms the previous methods. In addition, the WHU-Hi dataset could serve as a benchmark dataset for hyperspectral image classification studies.},
author = {Zhong, Yanfei and Hu, Xin and Luo, Chang and Wang, Xinyu and Zhao, Ji and Zhang, Liangpei},
doi = {10.1016/j.rse.2020.112012},
issn = {00344257},
journal = {Remote Sensing of Environment},
keywords = {Conditional random fields,Convolutional neural network,Precise crop classification,UAV-borne hyperspectral imagery,WHU-Hi dataset},
month = {dec},
pages = {112012},
publisher = {Elsevier Inc.},
title = {{WHU-Hi: UAV-borne hyperspectral with high spatial resolution (H2) benchmark datasets and classifier for precise crop identification based on deep convolutional neural network with CRF}},
volume = {250},
year = {2020}
}
@article{Dierssen2003,
abstract = {New coastal ocean remote sensing techniques permit benthic habitats to be explored with higher resolution than ever before. A mechanistic radiative transfer approach is developed that first removes the distorting influence of the water column on the remotely sensed signal to retrieve an estimate of the reflectance at the seafloor. The retrieved bottom reflectance is then used to classify the benthos. This spectrally based approach is advantageous because model components are separate and can be evaluated and modified individually for different environments. Here, we applied our approach to quantitatively estimate shallow-water bathymetry and leaf area index (LAI) of the seagrass Thalassia testudinum for a study site near Lee Stocking Island, Bahamas. Two high-resolution images were obtained from the ocean portable hyperspectral imager for low-light spectroscopy (Ocean PHILLS) over the study site in May 1999 and 2000. A combination of in situ observations of seafloor reflectance and radiative transfer modeling was used to develop and test our algorithm. Bathymetry was mapped to meter-scale resolution using a site-specific relationship (r2 = 0.97) derived from spectral ratios of remote sensing reflectance at 555 and 670 nm. Depth-independent bottom reflectance was retrieved from remote sensing reflectance using bathymetry and tables of modeled water column attenuation coefficients. The magnitude of retrieved bottom reflectance was highly correlated to seagrass LAI measured from diver surveys at seven stations within the image (r2 = 0.88-0.98). Mapped turtlegrass LAI was remarkably stable over a 2-yr period at our study site, even though Hurricane Floyd swept over the study site in September 1999.},
author = {Dierssen, Heidi M. and Zimmerman, Richard C. and Leathers, Robert A. and Downes, T. Valerie and Davis, Curtiss O.},
doi = {10.4319/lo.2003.48.1_part_2.0444},
issn = {00243590},
journal = {Limnology and Oceanography},
month = {jan},
number = {1 II},
pages = {444--455},
publisher = {American Society of Limnology and Oceanography Inc.},
title = {{Ocean color remote sensing of seagrass and bathymetry in the Bahamas Banks by high-resolution airborne imagery}},
url = {http://doi.wiley.com/10.4319/lo.2003.48.1_part_2.0444},
volume = {48},
year = {2003}
}
@inproceedings{Holasek2017,
abstract = {Hyperspectral imaging (HSI) has been used for over two decades in laboratory research, academic, environmental and defense applications. In more recent time, HSI has started to be adopted for commercial applications in machine vision, conservation, resource exploration, and precision agriculture, to name just a few of the economically viable uses for the technology. Corning Incorporated (Corning) has been developing and manufacturing HSI sensors, sensor systems, and sensor optical engines, as well as HSI sensor components such as gratings and slits for over a decade and a half. This depth of experience and technological breadth has allowed Corning to design and develop unique HSI spectrometers with an unprecedented combination of high performance, low cost and low Size, Weight, and Power (SWaP). These sensors and sensor systems are offered with wavelength coverage ranges from the visible to the Long Wave Infrared (LWIR). The extremely low SWaP of Corning's HSI sensors and sensor systems enables their deployment using limited payload platforms such as small unmanned aerial vehicles (UAVs). This paper discusses use of the Corning patented monolithic design Offner spectrometer, the microHSI™, to build a highly compact 400-1000 nm HSI sensor in combination with a small Inertial Navigation System (INS) and micro-computer to make a complete turn-key airborne remote sensing payload. This Selectable Hyperspectral Airborne Remote sensing Kit (SHARK) has industry leading SWaP (1.5 lbs) at a disruptively low price due, in large part, to Corning's ability to manufacture the monolithic spectrometer out of polymers (i.e. plastic) and therefore reduce manufacturing costs considerably. The other factor in lowering costs is Corning's well established in house manufacturing capability in optical components and sensors that further enable cost-effective fabrication. The competitive SWaP and low cost of the microHSI™ sensor is approaching, and in some cases less than the price point of Multi Spectral Imaging (MSI) sensors. Specific designs of the Corning microHSI™ SHARK visNIR turn-key system are presented along with salient performance characteristics. Initial focus market areas include precision agriculture and historic and recent microHSI™ SHARK prototype test results are presented.},
author = {Holasek, Rick and Nakanishi, Keith and Ziph-Schatzberg, Leah and Santman, Jeff and Woodman, Patrick and Zacaroli, Richard and Wiggins, Richard},
booktitle = {AUVSI XPONENTIAL 2017},
doi = {10.1117/12.2267856},
editor = {Bannon, David P.},
keywords = {algorithms,hyperspectral,precision agriculture,remote sensing,spectral imaging},
month = {may},
pages = {1021304},
publisher = {Association for Unmanned Vehicle Systems International},
title = {{The selectable hyperspectral airborne remote sensing kit (SHARK) as an enabler for precision agriculture}},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2267856},
volume = {10213},
year = {2017}
}
@article{Garcia2018,
abstract = {Hyperspectral remote sensing inversion models utilize spectral information over optically shallow waters to retrieve optical properties of the water column, bottom depth and reflectance, with the latter used in benthic classification. Accuracy of these retrievals is dependent on the spectral endmember(s) used to model the bottom reflectance during the inversion. Without prior knowledge of these endmember(s) current approaches must iterate through a list of endmember-a computationally demanding task. To address this, a novel lookup table classification approach termed HOPE-LUT was developed for selecting the likely benthic endmembers of any hyperspectral image pixel. HOPE-LUT classifies a pixel as sand, mixture or non-sand, then the latter two are resolved into the three most likely classes. Optimization subsequently selects the class (out of the three) that generated the best fit to the remote sensing reflectance. For a coral reef case, modeling results indicate very high benthic classification accuracy (> 90%) for depths less than 4 m of common coral reef benthos. These accuracies decrease substantially with increasing depth due to the loss of bottom information, especially the spectral signatures. We applied this technique to hyperspectral airborne imagery of Heron Reef, Great Barrier Reef and generated benthic habitat maps with higher classification accuracy compared to standard inversion models.},
author = {Garcia, Rodrigo A. and Lee, Zhongping and Hochberg, Eric J.},
doi = {10.3390/rs10010147},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2018/Garcia, Lee, Hochberg_2018_Hyperspectral shallow-water remote sensing with an enhanced benthic classifier.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Benthic classification,Coral reef,Heron reef,Hyperspectral,Remote sensing},
number = {1},
title = {{Hyperspectral shallow-water remote sensing with an enhanced benthic classifier}},
volume = {10},
year = {2018}
}
@inproceedings{Johnsen2016,
abstract = {Currently a new underwater hyperspectral imager (UHI) have been deployed on Remotely Operated Vehicles (ROV) for a more automated identification, mapping and monitoring of bio-geo-chemical objects of interest (OOI). Sea floor maps based on UHI can be used to classify 001 based on specific optical fingerprints providing spectral upwelling radiance or reflectance with up to 1 nm spectral resolution in the visible range for each image pixel. Different habitats comprising soft bottom, deep and cold water coral reefs, sponge habitats, pipeline monitoring and kelp forest maps are examples for UHI-based mapping. Characterising material surface on man-made objects such as corrosion on pipelines and subsea structures and archaeological objects are other examples. The overall image quality and identification success of OOI can be optimized if movements of the ROV is controlled by a dynamic position (DP) system and corresponding speed, altitude, pitch, roll and yaw control. Likewise, illumination control is important to provide proper light intensity, spectral composition and illumination evenness of OOI to enhance data quality. The benefits of using UHI for seafloor habitat mapping can be evaluated by four categories of resolution. These are A) spatial resolution (image pixel size), B) spectral resolution (1-10 nm, 400-800 nm), C) radiometric resolution (dynamic range, bits per pixel), and D) temporal resolution for time-series and monitoring. These categories of resolution are discussed with respect to OOI identification and mapping using different case examples.},
author = {Johnsen, Geir and Ludvigsen, Martin and S{\o}rensen, Asgeir and {Sandvik Aas}, Lars Martin},
booktitle = {IFAC-PapersOnLine},
doi = {10.1016/j.ifacol.2016.10.451},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2016/Johnsen et al._2016_The use of underwater hyperspectral imaging deployed on remotely operated vehicles - methods and applications.pdf:pdf},
issn = {24058963},
keywords = {Remotely Operated Vehicle (ROV),Underwater Hyperspectral Imager (UHI),decision making,ecosystem management,habitat mapping,habitat monitoring,mapping of seafloor},
month = {jan},
number = {23},
pages = {476--481},
publisher = {Elsevier},
title = {{The use of underwater hyperspectral imaging deployed on remotely operated vehicles - methods and applications}},
url = {https://www.sciencedirect.com/science/article/pii/S2405896316320390},
volume = {49},
year = {2016}
}
@article{Chen2014,
abstract = {Classification is one of the most popular topics in hyperspectral remote sensing. In the last two decades, a huge number of methods were proposed to deal with the hyperspectral data classification problem. However, most of them do not hierarchically extract deep features. In this paper, the concept of deep learning is introduced into hyperspectral data classification for the first time. First, we verify the eligibility of stacked autoencoders by following classical spectral information-based classification. Second, a new way of classifying with spatial-dominated information is proposed. We then propose a novel deep learning framework to merge the two features, from which we can get the highest classification accuracy. The framework is a hybrid of principle component analysis (PCA), deep learning architecture, and logistic regression. Specifically, as a deep learning architecture, stacked autoencoders are aimed to get useful high-level features. Experimental results with widely-used hyperspectral data indicate that classifiers built in this deep learning-based framework provide competitive performance. In addition, the proposed joint spectral-spatial deep neural network opens a new window for future research, showcasing the deep learning-based methods' huge potential for accurate hyperspectral data classification. {\textcopyright} 2014 IEEE.},
author = {Chen, Yushi and Lin, Zhouhan and Zhao, Xing and Wang, Gang and Gu, Yanfeng},
doi = {10.1109/JSTARS.2014.2329330},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2014/Chen et al._2014_Deep Learning-Based Classification of Hyperspectral Data.pdf:pdf},
issn = {21511535},
journal = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
keywords = {Autoencoder (AE),deep learning,feature extraction,hyperspectral data classification,logistic regression,stacked autoencoder (SAE),support vector machine (SVM)},
month = {jun},
number = {6},
pages = {2094--2107},
title = {{Deep learning-based classification of hyperspectral data}},
url = {http://ieeexplore.ieee.org/document/6844831/},
volume = {7},
year = {2014}
}
@article{Lee1999,
abstract = {In earlier studies of passive remote sensing of shallow-water bathymetry, bottom depths were usually derived by empirical regression. This approach provides rapid data processing, but it requires knowledge of a few true depths for the regression parameters to be determined, and it cannot reveal in-water constituents. In this study a newly developed hyperspectral, remote-sensing reflectance model for shallow water is applied to data from computer simulations and field measurements. In the process, a remote-sensing reflectance spectrum is modeled by a set of values of absorption, backscattering, bottom albedo, and bottom depth; then it is compared with the spectrum from measurements. The difference between the two spectral curves is minimized by adjusting the model values in a predictor-corrector scheme. No information in addition to the measured reflectance is required. When the difference reaches a minimum, or the set of variables is optimized, absorption coefficients and bottom depths along with other properties are derived simultaneously. For computer-simulated data at a wind speed of 5 m/s the retrieval error was 5.3% for depths ranging from 2.0 to 20.0 m and 7.0% for total absorption coefficients at 440 nm ranging from 0.04 to 0.24 m(-1). At a wind speed of 10 m/s the errors were 5.1% for depth and 6.3% for total absorption at 440 nm. For field data with depths ranging from 0.8 to 25.0 m the difference was 10.9% (R2 = 0.96, N = 37) between inversion-derived and field-measured depth values and just 8.1% (N = 33) for depths greater than 2.0 m. These results suggest that the model and the method used in this study, which do not require in situ calibration measurements, perform very well in retrieving in-water optical properties and bottom depths from above-surface hyperspectral measurements.},
author = {Lee, Zhongping and Carder, Kendall L. and Mobley, Curtis D. and Steward, Robert G. and Patch, Jennifer S.},
doi = {10.1364/ao.38.003831},
file = {:C\:/Users/mha114/Dropbox/Litteratur/1999/Lee et al._1999_Hyperspectral remote sensing for shallow waters 2 Deriving bottom depths and water properties by optimization.pdf:pdf},
issn = {0003-6935},
journal = {Applied Optics},
number = {18},
pages = {3831},
pmid = {18319990},
title = {{Hyperspectral remote sensing for shallow waters: 2 Deriving bottom depths and water properties by optimization}},
volume = {38},
year = {1999}
}
@article{Kay2009,
abstract = {Sun glint, the specular reflection of light from water surfaces, is a serious confounding factor for remote sensing of water column properties and benthos. This paper reviews current techniques to estimate and remove the glint radiance component from imagery. Methods for processing of ocean color images use statistical sea surface models to predict the glint from the sun and sensor positions and wind data. Methods for higher resolution imaging, used in coastal and shallow water mapping, estimate the glint radiance from the near-infrared signal. The effects of some current methods are demonstrated and possibilities for future techniques are briefly addressed. {\textcopyright} 2009 by the authors; licensee Molecular Diversity Preservation International, Basel, Switzerland.},
author = {Kay, Susan and Hedley, John and Lavender, Samantha},
doi = {10.3390/rs1040697},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2009/Kay, Hedley, Lavender_2009_Sun Glint Correction of High and Low Spatial Resolution Images of Aquatic Scenes a Review of Methods for Visi.pdf:pdf},
issn = {2072-4292},
journal = {Remote Sensing},
keywords = {Bathymetry,Coral reef,Ocean color,Shallow water,Sun glint,Sun glitter},
month = {oct},
number = {4},
pages = {697--730},
publisher = {Molecular Diversity Preservation International},
title = {{Sun Glint Correction of High and Low Spatial Resolution Images of Aquatic Scenes: a Review of Methods for Visible and Near-Infrared Wavelengths}},
url = {http://www.mdpi.com/2072-4292/1/4/697},
volume = {1},
year = {2009}
}
@article{Verrelst2013,
abstract = {Precise and spatially-explicit knowledge of leaf chlorophyll content (Chl) is crucial to adequately interpret the chlorophyll fluorescence (ChF) signal from space. Accompanying information about the reliability of the Chl estimation becomes more important than ever. Recently, a new statistical method was proposed within the family of nonparametric Bayesian statistics, namely Gaussian Processes regression (GPR). GPR is simpler and more robust than their machine learning family members while maintaining very good numerical performance and stability. Other features include: i) GPR requires a relatively small training data set and can adopt very flexible kernels, ii) GPR identifies the relevant bands and observations in establishing relationships with a variable, and finally iii) along with pixelwise estimations GPR provides accompanying confidence intervals. We used GPR to retrieve Chl from hyperspectral reflectance data and evaluated the portability of the regression model to other images. Based on field Chl measurements from the SPARC dataset and corresponding spaceborne CHRIS spectra (acquired in 2003, Barrax, Spain), GPR developed a regression model that was excellently validated (r2: 0.96, RMSE: 3.82 \mu{\rm g/cm}2 ). The SPARC-trained GPR model was subsequently applied to CHRIS images (Barrax, 2003, 2009) and airborne CASI flightlines (Barrax 2009) to generate Chl maps. The accompanying confidence maps provided insight in the robustness of the retrievals. Similar confidences were achieved by both sensors, which is encouraging for upscaling Chl estimates from field to landscape scale. Because of its robustness and ability to deliver confidence intervals, GPR is evaluated as a promising candidate for implementation into ChF processing chains. {\textcopyright} 2008-2012 IEEE.},
author = {Verrelst, Jochem and Alonso, Luis and {Rivera Caicedo}, Juan Pablo and Moreno, Jose and Camps-Valls, Gustavo},
doi = {10.1109/JSTARS.2012.2222356},
issn = {19391404},
journal = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
keywords = {CASI,CHRIS,Gaussian processes,chlorophyll content,confidence,hyperspectral,retrieval},
month = {apr},
number = {2},
pages = {867--874},
title = {{Gaussian process retrieval of chlorophyll content from imaging spectroscopy data}},
url = {http://ieeexplore.ieee.org/document/6365271/},
volume = {6},
year = {2013}
}
@article{Bunting2006a,
abstract = {In mixed-species forests of complex structure, the delineation of tree crowns is problematic because of their varying dimensions and reflectance characteristics, the existence of several layers of canopy (including understorey), and shadowing within and between crowns. To overcome this problem, an algorithm for delineating tree crowns has been developed using eCognition Expert and hyperspectral Compact Airborne Spectrographic Imager (CASI-2) data acquired over a forested landscape near Injune, central east Queensland, Australia. The algorithm has six components: 1) the differentiation of forest, non-forest and understorey; 2) initial segmentation of the forest area and allocation of segments (objects) to larger objects associated with forest spectral types (FSTs); 3) initial identification of object maxima as seeds within these larger objects and their expansion to the edges of crowns or clusters of crowns; 4) subsequent classification-based separation of the resulting objects into crown or cluster classes; 5) further iterative splitting of the cluster classes to delineate more crowns; and 6) identification and subsequent merging of oversplit objects into crowns or clusters. In forests with a high density of individuals (e.g., regrowth), objects associated with tree clusters rather than crowns are delineated and local maxima counted to approximate density. With reference to field data, the delineation process provided accuracies > ∼70% (range 48-88%) for individuals or clusters of trees of the same species with diameter at breast height (DBH) exceeding 10 cm (senescent and dead trees excluded), with lower accuracies associated with dense stands containing several canopy layers, as many trees were obscured from the view of the CASI sensor. Although developed using 1-m spatial resolution CASI data acquired over Australian forests, the algorithm has application elsewhere and is currently being considered for integration into the Definiens product portfolio for use by the wider community. {\textcopyright} 2006 Elsevier Inc. All rights reserved.},
author = {Bunting, Peter and Lucas, Richard},
doi = {10.1016/j.rse.2005.12.015},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2006/Bunting, Lucas_2006_The delineation of tree crowns in Australian mixed species forests using hyperspectral Compact Airborne Spectrograph.pdf:pdf},
issn = {00344257},
journal = {Remote Sensing of Environment},
keywords = {Australia,CASI,Classification,Crown delineation,Forests,Hyperspectral,Image segmentation,Queensland,eCognition},
number = {2},
pages = {230--248},
title = {{The delineation of tree crowns in Australian mixed species forests using hyperspectral Compact Airborne Spectrographic Imager (CASI) data}},
volume = {101},
year = {2006}
}
@article{HyspIRIMissionConceptTeam2018,
address = {Pasadena, California},
author = {{HyspIRI Mission Concept Team}},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2018/HyspIRI Mission Concept Team_2018_HyspIRI Final Report.pdf:pdf},
institution = {Jet Propulsion Laboratory},
journal = {NASA HyspIRI Final Report},
title = {{HyspIRI Final Report}},
url = {https://hyspiri.jpl.nasa.gov/downloads/reports_whitepapers/HyspIRI_FINAL_Report_1October2018_20181005a.pdf},
year = {2018}
}
@article{Rashid2020,
abstract = {This paper describes a large dataset of underwater hyperspectral imagery that can be used by researchers in the domains of computer vision, machine learning, remote sensing, and coral reef ecology. We present the details of underwater data acquisition, processing and curation to create this large dataset of coral reef imagery annotated for habitat mapping. A diver-operated hyperspectral imaging system (HyperDiver) was used to survey 147 transects at 8 coral reef sites around the Caribbean island of Cura{\c{c}}ao. The underwater proximal sensing approach produced fine-scale images of the seafloor, with more than 2.2 billion points of detailed optical spectra. Of these, more than 10 million data points have been annotated for habitat descriptors or taxonomic identity with a total of 47 class labels up to genus-and species-levels. In addition to HyperDiver survey data, we also include images and annotations from traditional (color photo) quadrat surveys conducted along 23 of the 147 transects, which enables comparative reef description between two types of reef survey methods. This dataset promises benefits for efforts in classification algorithms, hyperspectral image segmentation and automated habitat mapping.},
author = {Rashid, Ahmad Rafiuddin and Chennu, Arjun},
doi = {10.3390/data5010019},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2020/Rashid, Chennu_2020_A trillion coral reef colors Deeply annotated underwater hyperspectral images for automated classification and habit.pdf:pdf},
issn = {23065729},
journal = {Data},
keywords = {Biodiversity,Classification,Coral reef,Habitat mapping,Hierarchical learning,Hyperspectral imaging,Image segmentation,Machine learning,Proximal sensing},
month = {feb},
number = {1},
pages = {19},
publisher = {MDPI AG},
title = {{A trillion coral reef colors: Deeply annotated underwater hyperspectral images for automated classification and habitat mapping}},
url = {https://www.mdpi.com/2306-5729/5/1/19},
volume = {5},
year = {2020}
}
@article{Hedley2005,
abstract = {Specular reflection of solar radiation on non-flat water surfaces is a serious confounding factor for benthic remote sensing in shallow-water environments. This problem was recently overcome by Hochberg et al., who provided an effective method for the removal of 'sun glint' from remotely sensed images by utilization of the brightness in a near-infrared (NIR) band. Application of the technique was shown to give an increase in the accuracy of benthic habitat classification. However, as presented, the method is sensitive to outlier pixels, requires a time-consuming masking of land and cloud, and is not formulated in a manner leading to ease of implementation. We present a revised version of the method, which is more robust, does not require masking and can be implemented very simply. The practical approach described here will hopefully expedite the routine adoption of this effective and simple technique throughout the aquatic remote sensing community. {\textcopyright} 2005 Taylor & Francis Group Ltd.},
author = {Hedley, J. D. and Harborne, A. R. and Mumby, P. J.},
doi = {10.1080/01431160500034086},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2005/Hedley, Harborne, Mumby_2005_Technical note Simple and robust removal of sun glint for mapping shallow‐water benthos.pdf:pdf},
issn = {13665901},
journal = {International Journal of Remote Sensing},
month = {may},
number = {10},
pages = {2107--2112},
publisher = {Taylor and Francis Ltd.},
title = {{Simple and robust removal of sun glint for mapping shallow-water benthos}},
url = {https://www.tandfonline.com/doi/full/10.1080/01431160500034086},
volume = {26},
year = {2005}
}
@article{Bradley2018,
abstract = {In this paper, we investigate the potential of unsupervised feature selection techniques for classification tasks, where only sparse training data are available. This is motivated by the fact that unsupervised feature selection techniques combine the advantages of standard dimensionality reduction techniques (which only rely on the given feature vectors and not on the corresponding labels) and supervised feature selection techniques (which retain a subset of the original set of features). Thus, feature selection becomes independent of the given classification task and, consequently, a subset of generally versatile features is retained. We present different techniques relying on the topology of the given sparse training data. Thereby, the topology is described with an ultrametricity index. For the latter, we take into account the Murtagh Ultrametricity Index (MUI) which is defined on the basis of triangles within the given data and the Topological Ultrametricity Index (TUI) which is defined on the basis of a specific graph structure. In a case study addressing the classification of high-dimensional hyperspectral data based on sparse training data, we demonstrate the performance of the proposed unsupervised feature selection techniques in comparison to standard dimensionality reduction and supervised feature selection techniques on four commonly used benchmark datasets. The achieved classification results reveal that involving supervised feature selection techniques leads to similar classification results as involving unsupervised feature selection techniques, while the latter perform feature selection independently from the given classification task and thus deliver generally versatile features.},
author = {Bradley, Patrick Erik and Keller, Sina and Weinmann, Martin},
doi = {10.3390/rs10101564},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2018/Bradley, Keller, Weinmann_2018_Unsupervised feature selection based on ultrametricity and sparse training data A case study for the clas.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {AVIRIS data,Classification,EnMAP data,Hyperspectral imagery,Land cover,Land use,ROSIS data,Sparse training data,Ultrametricity,Unsupervised feature selection},
month = {sep},
number = {10},
pages = {1564},
publisher = {MDPI AG},
title = {{Unsupervised feature selection based on ultrametricity and sparse training data: A case study for the classification of high-dimensional hyperspectral data}},
url = {http://www.mdpi.com/2072-4292/10/10/1564},
volume = {10},
year = {2018}
}
@article{Holden2002,
abstract = {Much attention has been given to hyperspectral remote sensing of benthic habitat recently to quantify spectral signatures, examine linear mixing, map geomorphic zonation, or identify temporal change with varying degrees of confidence and success. Relatively less attention has been given to the effects of the water column on the hyperspectral signal given various water depths and bottom types. Hyperspectral in situ reflectance was measured at both the top and bottom of the water column to examine the effects of the intervening water layer. A radiative transfer model was used to predict the top-of-the-water column reflectance from a large number of close-range measured bottom spectra. The measured and modeled hyperspectral reflectance spectra were examined separately to compare the degree to which different substrate types can be discriminated once the water column is "added" to the spectra. The classification accuracy assessment indicated that the ability to discriminate benthic habitat based on hyperspectral characteristics is limited when the effects of the water column are included as the kappa statistic drops from 0.70 to 0.49. {\textcopyright} 2002 Elsevier Science Inc. All rights reserved.},
author = {Holden, Heather and LeDrew, Ellsworth},
doi = {10.1016/S0034-4257(02)00007-X},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2002/Holden, LeDrew_2002_Measuring and modeling water column effects on hyperspectral reflectance in a coral reef environment.pdf:pdf},
issn = {00344257},
journal = {Remote Sensing of Environment},
number = {2-3},
pages = {300--308},
title = {{Measuring and modeling water column effects on hyperspectral reflectance in a coral reef environment}},
volume = {81},
year = {2002}
}
@article{Inamdar2022,
abstract = {Our article describes a data processing workflow for hyperspectral imaging data to compensate for the water column in shallow, clear to moderate optical water types. We provide a MATLAB script that can be readily used to implement the described workflow. We break down each code segment of this script so that it is more approachable for use and modification by end users and data providers. The workflow initially implements the method for water column compensation described in Lyzenga (1978) and Lyzenga (1981), generating depth invariant indices from spectral band pairs. Given the high dimensionality of hyperspectral imaging data, an overwhelming number of depth invariant indices are generated in the workflow. As such, a correlation based feature selection methodology is applied to remove redundant depth invariant indices. In a post-processing step, a principal component transformation is applied, extracting features that account for a substantial amount of the variance from the non-redundant depth invariant indices while reducing dimensionality. To fully showcase the developed methodology and its potential for extracting bottom type information, we provide an example output of the water column compensation workflow using hyperspectral imaging data collected over the coast of Philpott's Island in Long Sault Parkway provincial park, Ontario, Canada. • Workflow calculates depth invariant indices for hyperspectral imaging data to compensate for the water column in shallow, clear to moderate optical water types. • The applied principal component transformation generates features that account for a substantial amount of the variance from the depth invariant indices while reducing dimensionality. • The output (both depth invariant index image and principal component image) allows for the analysis of bottom type in shallow, clear to moderate optical water types.},
author = {Inamdar, Deep and Rowan, Gillian S.L. and Kalacska, Margaret and Arroyo-Mora, J. Pablo},
doi = {10.1016/j.mex.2021.101601},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2022/Inamdar et al._2022_Water column compensation workflow for hyperspectral imaging data.pdf:pdf},
issn = {22150161},
journal = {MethodsX},
keywords = {Depth invariant index (DII),Hyperspectral Depth Invariant Index,Hyperspectral imaging,Principal component analysis (PCA),Water column compensation},
month = {jan},
pages = {101601},
publisher = {Elsevier},
title = {{Water column compensation workflow for hyperspectral imaging data}},
volume = {9},
year = {2022}
}
@inproceedings{Makantasis2015,
abstract = {Spectral observations along the spectrum in many narrow spectral bands through hyperspectral imaging provides valuable information towards material and object recognition, which can be consider as a classification task. Most of the existing studies and research efforts are following the conventional pattern recognition paradigm, which is based on the construction of complex handcrafted features. However, it is rarely known which features are important for the problem at hand. In contrast to these approaches, we propose a deep learning based classification method that hierarchically constructs high-level features in an automated way. Our method exploits a Convolutional Neural Network to encode pixels' spectral and spatial information and a Multi-Layer Perceptron to conduct the classification task. Experimental results and quantitative validation on widely used datasets showcasing the potential of the developed approach for accurate hyperspectral data classification.},
author = {Makantasis, Konstantinos and Karantzalos, Konstantinos and Doulamis, Anastasios and Doulamis, Nikolaos},
booktitle = {International Geoscience and Remote Sensing Symposium (IGARSS)},
doi = {10.1109/IGARSS.2015.7326945},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2015/Makantasis et al._2015_Deep supervised learning for hyperspectral data classification through convolutional neural networks.pdf:pdf},
isbn = {9781479979295},
keywords = {Earth observation,Imaging spectroscopy,Machine learning,Object Recognition},
month = {jul},
pages = {4959--4962},
publisher = {IEEE},
title = {{Deep supervised learning for hyperspectral data classification through convolutional neural networks}},
url = {https://ieeexplore.ieee.org/document/7326945/},
volume = {2015-Novem},
year = {2015}
}
@techreport{Schmiel2023a,
author = {Schmiel, Alexandre C. G. and Thormar, Jonas and Oveland, Ivar and Thorsnes, Terje and Elvenes, Sigrid and Kurz, Tobias and Welde, Helge},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2023/Schmiel et al._2023_Summary report of datasets acquired for the purpose of method development within the Marine Base Maps for the Coasta.pdf:pdf},
title = {{Summary report of datasets acquired for the purpose of method development within the Marine Base Maps for the Coastal Zone (Marine grunnkart i kystsonen) project at Fj{\o}l{\o}y and Kloster{\o}y, Stavanger, Norway}},
year = {2023}
}
@article{Bell2015,
abstract = {This study examines the potential of the Hyperspectral Infrared Imager (HyspIRI) mission for monitoring the biomass and physiological condition of giant kelp forests on local to global scales. Giant kelp is a highly dynamic foundation species that supports an ecologically and economically important ecosystem found throughout the globe. Satellite, airborne, and field data are used to evaluate the suitability of HyspIRI's spatial, temporal, and spectral coverage for capturing variability in giant kelp biomass and physiological state. We analyze a 28-year time series of giant kelp biomass derived from Landsat satellite imagery in order to identify the dominant temporal modes of variability in giant kelp biomass using the California coast as a model region likely to be relevant to other regions of the globe. Temporal variability in California kelp canopy biomass is compared to the expected availability of cloud-free HyspIRI Visible Shortwave Infrared (VSWIR) views for regions of the world that contain giant kelp populations. Spectral variability is explored by assessing how changes in the physiological condition of giant kelp canopy are exhibited in the reflectance and transmittance of kelp fronds. We compare chlorophyll a to carbon ratios (Chl:C) of kelp fronds collected off the coast of California to laboratory and airborne measurements of hyperspectral reflectance in order to develop metrics of kelp physiological condition.The seasonal cycle dominates giant kelp canopy biomass temporal variability. However, the strength and timing of this cycle varies in both space and time. Our projections of cloud-free HyspIRI coverage indicate that the sensor will be able to capture at least 1 cloud free view each season for nearly all of the global giant kelp habitats, thereby illustrating that HyspIRI will resolve the dominant seasonal cycles in giant kelp biomass. A novel spectral index developed here from field observations explained 76% of the variance in Chl:C and was applied to hyperspectral aircraft observations. These results demonstrate that the spatial, temporal, and spectral coverage provided by HyspIRI has the potential to provide new insights into the ecology and biophysiology of giant kelp.},
author = {Bell, Tom W. and Cavanaugh, Kyle C. and Siegel, David A.},
doi = {10.1016/j.rse.2015.05.003},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2015/Bell, Cavanaugh, Siegel_2015_Remote monitoring of giant kelp biomass and physiological condition An evaluation of the potential for the.pdf:pdf},
issn = {00344257},
journal = {Remote Sensing of Environment},
keywords = {AVIRIS,Coastal ecology,Giant kelp,Hyperspectral,HyspIRI,Landsat,Macrophyte,Wavelet analysis},
month = {sep},
pages = {218--228},
publisher = {Elsevier},
title = {{Remote monitoring of giant kelp biomass and physiological condition: An evaluation of the potential for the Hyperspectral Infrared Imager (HyspIRI) mission}},
url = {https://www.sciencedirect.com/science/article/pii/S0034425715300031},
volume = {167},
year = {2015}
}
@article{Zoffoli2014,
abstract = {Human activity and natural climate trends constitute a major threat to coral reefs worldwide. Models predict a significant reduction in reef spatial extension together with a decline in biodiversity in the relatively near future. In this context, monitoring programs to detect changes in reef ecosystems are essential. In recent years, coral reef mapping using remote sensing data has benefited from instruments with better resolution and computational advances in storage and processing capabilities. However, the water column represents an additional complexity when extracting information from submerged substrates by remote sensing that demands a correction of its effect. In this article, the basic concepts of bottom substrate remote sensing and water column interference are presented. A compendium of methodologies developed to reduce water column effects in coral ecosystems studied by remote sensing that include their salient features, advantages and drawbacks is provided. Finally, algorithms to retrieve the bottom reflectance are applied to simulated data and actual remote sensing imagery and their performance is compared. The available methods are not able to completely eliminate the water column effect, but they can minimize its influence. Choosing the best method depends on the marine environment, available input data and desired outcome or scientific application.},
author = {Zoffoli, Maria Laura and Frouin, Robert and Kampel, Milton},
doi = {10.3390/s140916881},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2014/Zoffoli, Frouin, Kampel_2014_Water column correction for coral reef studies by remote sensing.pdf:pdf},
issn = {14248220},
journal = {Sensors (Switzerland)},
keywords = {Attenuation coefficient,Bottom reflectance,Remote sensing,Submerse substrate,Water column constituents},
month = {sep},
number = {9},
pages = {16881--16931},
pmid = {25215941},
publisher = {MDPI AG},
title = {{Water column correction for coral reef studies by remote sensing}},
url = {http://www.mdpi.com/1424-8220/14/9/16881},
volume = {14},
year = {2014}
}
@article{Zhao2016,
abstract = {In this paper, we propose a spectral-spatial feature based classification (SSFC) framework that jointly uses dimension reduction and deep learning techniques for spectral and spatial feature extraction, respectively. In this framework, a balanced local discriminant embedding algorithm is proposed for spectral feature extraction from high-dimensional hyperspectral data sets. In the meantime, convolutional neural network is utilized to automatically find spatial-related features at high levels. Then, the fusion feature is extracted by stacking spectral and spatial features together. Finally, the multiple-feature-based classifier is trained for image classification. Experimental results on well-known hyperspectral data sets show that the proposed SSFC method outperforms other commonly used methods for hyperspectral image classification.},
author = {Zhao, Wenzhi and Du, Shihong},
doi = {10.1109/TGRS.2016.2543748},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2016/Zhao, Du_2016_Spectral–Spatial Feature Extraction for Hyperspectral Image Classification A Dimension Reduction and Deep Learning Approac.pdf:pdf},
issn = {01962892},
journal = {IEEE Transactions on Geoscience and Remote Sensing},
keywords = {Balanced local discriminant embedding (BLDE),Feature extraction,convolutional neural network (CNN),deep learning (DL),dimension reduction (DR)},
month = {aug},
number = {8},
pages = {4544--4554},
title = {{Spectral-Spatial Feature Extraction for Hyperspectral Image Classification: A Dimension Reduction and Deep Learning Approach}},
url = {http://ieeexplore.ieee.org/document/7450160/},
volume = {54},
year = {2016}
}
@article{Baumgardner2015,
abstract = {This publication includes the AVIRIS hyperspectral image data for Indian Pine Test Site 3 along with the reference data for this site including observation notes and photos for the fields within the approximately 2 mile by 2 mile area.},
author = {Baumgardner, Marion F. and Biehl, Larry L. and Landgrebe, David A.},
doi = {10.4231/R7RX991C},
journal = {Purdue University Research Repository},
keywords = {HUBzero,Purdue University,collaboration,data,data management plan,dataset,publishing data,repository,research,sharing data},
month = {sep},
number = {7},
title = {{220 band aviris hyperspectral image data set: June 12, 1992 indian pine test site 3}},
url = {https://doi.org/10.4231/R7RX991C},
volume = {10},
year = {2015}
}
@article{Clarke2021,
abstract = {Seagrasses are regarded as indicators and first line of impact for anthropogenic activities affecting the coasts. The underlying mechanisms driving seagrass cover however have been mostly studied on small scales, making it difficult to establish the connection to seagrass dynamics in an impacted seascape. In this study, hyperspectral airborne imagery, trained from field surveys, was used to investigate broadscale seagrass cover and genus distribution along the coast of Adelaide, South Australia. Overall mapping accuracy was high for both seagrass cover (98%, Kappa = 0.93), and genus level classification (85%, Kappa = 0.76). Spectral separability allowed confident genus mapping in waters up to 10 m depth, revealing a 3.5 ratio between the cover of the dominant Posidonia and Amphibolis. The work identified the absence of Amphibolis in areas historically affected by anthropogenic discharges, which occasionally contained Posidonia and might be recovering. The results suggest hyperspectral imagery as a useful tool to investigate the interplay between seagrass cover and genus distribution at large spatial scales.},
author = {Clarke, Kenneth and Hennessy, Andrew and McGrath, Andrew and Daly, Robert and Gaylard, Sam and Turner, Alison and Cameron, James and Lewis, Megan and Fernandes, Milena B},
doi = {10.1038/s41598-021-83728-6},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2021/Clarke et al._2021_Using hyperspectral imagery to investigate large-scale seagrass cover and genus distribution in a temperate coast.pdf:pdf},
isbn = {4159802183728},
issn = {20452322},
journal = {Scientific Reports},
number = {1},
pages = {1--9},
pmid = {33603192},
publisher = {Nature Publishing Group UK},
title = {{Using hyperspectral imagery to investigate large-scale seagrass cover and genus distribution in a temperate coast}},
url = {https://doi.org/10.1038/s41598-021-83728-6},
volume = {11},
year = {2021}
}
@article{Fauvel2013,
author = {Fauvel, M. and Tarabalka, Y. and Benediktsson, J. A. and Chanussot, J. and Tilton, J. C.},
doi = {10.1109/JPROC.2012.2197589},
issn = {0018-9219},
journal = {Proceedings of the IEEE},
month = {mar},
number = {3},
pages = {652--675},
title = {{Advances in Spectral-Spatial Classification of Hyperspectral Images}},
url = {http://ieeexplore.ieee.org/document/6297992/},
volume = {101},
year = {2013}
}
@article{Dierssen2015a,
abstract = {Floating mats of vegetation serve to transfer biomass, nutrients and energy across marine habitats and alter the spectral properties of the sea surface. Here, spectral measurements from the airborne Portable Remote Imaging Spectrometer (PRISM) imagery at 1-m resolution and experimental mesocosms were used to assess the hyperspectral properties of the macroalgae Sargassum and aggregations of the seagrass Syringodium filiforme wrack in Greater Florida Bay. A simple Normalized Difference Vegetative Index (NDVI) effectively discriminated the presence of vegetation floating on the sea surface. The Sargassum Index derived from reflectance ratios at 650 and 630. nm was used to effectively discriminate Sargassum from Syringodium wrack. Mesocosm spectral measurements revealed an initial lowering of wrack reflectance over the first 3. days followed by a subsequent increase in reflectance over the next 8. days. The age of the wrack estimated from 2 to 5. days was best characterized using narrowband indices of the water absorption feature at 930 and 990. nm potentially from increasing water content in wrack leaves over time. Hyperspectral imagery (<10 nm) was necessary to differentiate between these two types of floating vegetation and assess age of the wrack. PRISM imagery revealed seagrass wrack organized in 5-35. m spaced windrows caused by Langmuir circulation. Wrack was only detectable at 60. m. pixel resolution when densities were high and individual windrows were in close proximity.},
author = {Dierssen, H. M. and Chlus, A. and Russell, B.},
doi = {10.1016/j.rse.2015.01.027},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2015/Dierssen, Chlus, Russell_2015_Hyperspectral discrimination of floating mats of seagrass wrack and the macroalgae Sargassum in coastal wa.pdf:pdf},
issn = {00344257},
journal = {Remote Sensing of Environment},
keywords = {Airborne imaging spectroscopy,Beach wrack,Floating algae,Hyperspectral,Langmuir,Ocean color,PRISM,Remote sensing,Sargassum,Seagrass,Syringodium filiforme,Wrack},
month = {sep},
pages = {247--258},
publisher = {Elsevier},
title = {{Hyperspectral discrimination of floating mats of seagrass wrack and the macroalgae Sargassum in coastal waters of Greater Florida Bay using airborne remote sensing}},
url = {https://www.sciencedirect.com/science/article/pii/S0034425715000450},
volume = {167},
year = {2015}
}
@article{Oppelt2012,
abstract = {Analysis of coastal marine algae communities enables us to adequately estimate the state of coastal marine environments and provides evidence for environmental changes. Hyperspectral remote sensing provides a tool for mapping macroalgal habitats if the algal communities are spectrally resolvable. We compared the performance of three classification approaches to determine the distribution of macroalgae communities in the rocky intertidal zone of Heligoland, Germany, using airborne hyperspectral (AISA eagle ) data. The classification results of two supervised approaches (maximum likelihood classifier and spectral angle mapping) are compared with an approach combining k-Means classification of derivative measures. We identified regions of different slopes between main pigment absorption features of macroalgae and classified the resulting slope bands. The maximum likelihood classifier gained the best results (Cohan's kappa = 0.81), but the new approach turned out as a time-effective possibility to identify the dominating macroalgae species with sufficient accuracy (Cohan's kappa = 0.77), even in the heterogeneous and patchy coverage of the study area. {\textcopyright} 2012 Society of Photo-Optical Instrumentation Engineers (SPIE).},
author = {Oppelt, Natascha},
doi = {10.1117/1.oe.51.11.111703},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2012/Oppelt et al._2012_Hyperspectral classification approaches for intertidal macroalgae habitat mapping a case study in Heligoland.pdf:pdf},
issn = {0091-3286},
journal = {Optical Engineering},
month = {jun},
number = {11},
pages = {111703},
publisher = {International Society for Optics and Photonics},
title = {{Hyperspectral classification approaches for intertidal macroalgae habitat mapping: a case study in Heligoland}},
url = {http://opticalengineering.spiedigitallibrary.org/article.aspx?doi=10.1117/1.OE.51.11.111703},
volume = {51},
year = {2012}
}
@article{Green1998,
abstract = {Imaging spectroscopy is of growing interest as a new approach to Earth remote sensing. The Airborne Visible/Infrared Imaging Spectrometer (AVIRIS) was the first imaging sensor to measure the solar reflected spectrum from 400 nm to 2500 nm at 10 nm intervals. The calibration accuracy and signal-to-noise of AVIRIS remain unique. The AVIRIS system as well as the science research and applications have evolved significantly in recent years. The initial design and upgraded characteristics of the AVIRIS system are described in terms of the sensor, calibration, data system, and flight operation. This update on the characteristics of AVIRIS provides the context for the science research and applications that use AVIRIS data acquired in the past several years. Recent science research and applications are reviewed spanning investigations of atmospheric correction, ecology and vegetation, geology and soils, inland and coastal waters, the atmosphere, snow and ice hydrology, biomass burning, environmental hazards, satellite simulation and calibration, commercial applications, spectral algorithms, human infrastructure, as well as spectral modeling.},
author = {Green, Robert O and Eastwood, Michael L and Sarture, Charles M and Chrien, Thomas G and Aronsson, Mikael and Chippendale, Bruce J and Faust, Jessica A and Pavri, Betina E and Chovit, Christopher J and Solis, Manuel and Olah, Martin R and Williams, Orlesa},
doi = {10.1016/S0034-4257(98)00064-9},
file = {:C\:/Users/mha114/Dropbox/Litteratur/1998/Green et al._1998_Imaging Spectroscopy and the Airborne VisibleInfrared Imaging Spectrometer (AVIRIS).pdf:pdf},
issn = {0034-4257},
journal = {Remote Sensing of Environment},
month = {sep},
number = {3},
pages = {227--248},
publisher = {Elsevier},
title = {{Imaging Spectroscopy and the Airborne Visible/Infrared Imaging Spectrometer (AVIRIS)}},
url = {https://www.sciencedirect.com/science/article/pii/S0034425798000649},
volume = {65},
year = {1998}
}
@article{LeBris2016,
abstract = {The invasion of the wild oyster Crassostrea gigas along the western European Atlantic coast has generated changes in the structure and functioning of intertidal ecosystems. Considered as an invasive species and a trophic competitor of the cultivated conspecific oyster, it is now seen as a resource by oyster farmers following recurrent mass summer mortalities of oyster spat since 2008. Spatial distribution maps of wild oyster reefs are required by local authorities to help define management strategies. In this work, visible-near infrared (VNIR) hyperspectral and multispectral remote sensing was investigated to map two contrasted intertidal reef structures: clusters of vertical oysters building three-dimensional dense reefs in muddy areas and oysters growing horizontally creating large flat reefs in rocky areas. A spectral library, collected in situ for various conditions with an ASD spectroradiometer, was used to run Spectral Angle Mapper classifications on airborne data obtained with an HySpex sensor (160 spectral bands) and SPOT satellite HRG multispectral data (3 spectral bands). With HySpex spectral/spatial resolution, horizontal oysters in the rocky area were correctly classified but the detection was less efficient for vertical oysters in muddy areas. Poor results were obtained with the multispectral image and from spatially or spectrally degraded HySpex data, it was clear that the spectral resolution was more important than the spatial resolution. In fact, there was a systematic mud deposition on shells of vertical oyster reefs explaining the misclassification of 30% of pixels recognized as mud or microphytobenthos. Spatial distribution maps of oyster reefs were coupled with in situ biomass measurements to illustrate the interest of a remote sensing product to provide stock estimations of wild oyster reefs to be exploited by oyster producers. This work highlights the interest of developing remote sensing techniques for aquaculture applications in coastal areas.},
author = {{Le Bris}, Anthony and Rosa, Philippe and Lerouxel, Astrid and Cognie, Bruno and Gernez, Pierre and Launeau, Patrick and Robin, Marc and Barill{\'{e}}, Laurent},
doi = {10.1016/j.ecss.2016.01.039},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2016/Le Bris et al._2016_Hyperspectral remote sensing of wild oyster reefs.pdf:pdf},
issn = {02727714},
journal = {Estuarine, Coastal and Shelf Science},
keywords = {Benthos,Crassostrea gigas,Hyperspectral,Oyster reefs,Remote sensing,Tidal flats},
pages = {1--12},
title = {{Hyperspectral remote sensing of wild oyster reefs}},
volume = {172},
year = {2016}
}
@article{Zhong2018b,
abstract = {In recent years, with the rapid development of unmanned aerial vehicles (UAVs) and lightweight hyperspectral imaging (HSI) sensors, mini-UAV-borne hyperspectral remote sensing (HRS) systems have been developed and demonstrate great value and application potential. Compared to spaceborne and airborne HSI systems, mini-UAV-borne HSI systems come with relatively low manufacturing and running costs and have thus become a new research focus in the field of HRS.},
author = {Zhong, Yanfei and Wang, Xinyu and Xu, Yao and Wang, Shaoyu and Jia, Tianyi and Hu, Xin and Zhao, Ji and Wei, Lifei and Zhang, Liangpei},
doi = {10.1109/MGRS.2018.2867592},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2018/Zhong et al._2018_Mini-UAV-Borne Hyperspectral Remote Sensing From Observation and Processing to Applications.pdf:pdf},
issn = {21686831},
journal = {IEEE Geoscience and Remote Sensing Magazine},
month = {dec},
number = {4},
pages = {46--62},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Mini-UAV-Borne Hyperspectral Remote Sensing: From Observation and Processing to Applications}},
volume = {6},
year = {2018}
}
@article{Mount2005,
abstract = {The behavior of light at the air/water interface has substantial effects on the quality of vertical, or nadir-looking imagery used to interpret subsurface features for purposes such as marine habitat mapping. Reflection of the direct solar beam into the sensor by waves on the surface of the water creates bright glints, which obscure bottom features of interest. Sun angle, refraction, and reflection of the direct solar beam affect the amount of subsurface illumination and shadowing of bottom features. Simple interpretations of these sea surface effects are made with sufficient accuracy to improve planning for airborne, vertical image capture, particularly aerial photography or video imagery. The time available for image capture over shallow water is typically limited to a short period in the morning. The start time is controlled by subsurface illumination levels, which are determined by sun angle and locally variable factors, such as light attenuation by the water column, rather than surface reflection or subsurface shadowing. The end time is determined by sun glitter effects, which in this case study, are predictable from sun angle, camera field of view, and wind speed with an R2 value of 0.9554. {\textcopyright} 2005 American Society for Photogrammetry and Remote Sensing.},
author = {Mount, Richard},
doi = {10.14358/PERS.71.12.1407},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2005/Mount_2005_Acquisition of through-water aerial survey images Surface effects and the prediction of sun glitter and subsurface illuminati.pdf:pdf},
issn = {00991112},
journal = {Photogrammetric Engineering and Remote Sensing},
number = {12},
pages = {1407--1415},
publisher = {American Society for Photogrammetry and Remote Sensing},
title = {{Acquisition of through-water aerial survey images: Surface effects and the prediction of sun glitter and subsurface illumination}},
volume = {71},
year = {2005}
}
@article{Audebert2019,
abstract = {In recent years, deep-learning techniques revolutionized the way remote sensing data are processed. The classification of hyperspectral data is no exception to the rule, but it has intrinsic specificities that make the application of deep learning less straightforward than with other optical data. This article presents the state of the art of previous machine-learning approaches, reviews the various deeplearning approaches currently proposed for hyperspectral classification, and identifies the problems and difficulties that arise in the implementation of deep neural networks for this task. In particular, the issues of spatial and spectral resolution, data volume, and transfer of models from multimedia images to hyperspectral data are addressed. Additionally, a comparative study of various families of network architectures is provided, and a software toolbox is publicly released to allow experimenting with these methods (https://github.com/nshaud/DeepHyperX). This article is intended for both data scientists with interest in hyperspectral data and remote sensing experts eager to apply deeplearning techniques to their own data set.},
archivePrefix = {arXiv},
arxivId = {1904.10674},
author = {Audebert, Nicolas and {Le Saux}, Bertrand and Lefevre, Sebastien},
doi = {10.1109/MGRS.2019.2912563},
eprint = {1904.10674},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2019/Audebert, Le Saux, Lefevre_2019_Deep learning for classification of hyperspectral data A comparative review.pdf:pdf},
issn = {21686831},
journal = {IEEE Geoscience and Remote Sensing Magazine},
month = {jun},
number = {2},
pages = {159--173},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Deep learning for classification of hyperspectral data: A comparative review}},
volume = {7},
year = {2019}
}
@article{Tait2019,
abstract = {Developments in the capabilities and affordability of unmanned aerial vehicles (UAVs) have led to an explosion in their use for a range of ecological and agricultural remote sensing applications. However, the ubiquity of visible light cameras aboard readily available UAVs may be limiting the application of these devices for fine-scale, high taxonomic resolution monitoring. Here we compare the use of RGB and multispectral cameras deployed aboard UAVs for assessing intertidal and shallow subtidal marine macroalgae to a high taxonomic resolution. Our results show that the diverse spectral profiles of marine macroalgae naturally lend themselves to remote sensing and habitat classification. Furthermore, we show that biodiversity assessments, particularly in shallow subtidal habitats, are enhanced using six-band discrete wavelength multispectral sensors (81% accuracy, Cohen's Kappa) compared to three-band broad channel RGB sensors (79% accuracy, Cohen's Kappa) for 10 habitat classes. Combining broad band RGB signals and narrow band multispectral sensing further improved the accuracy of classification with a combined accuracy of 90% (Cohen's Kappa). Despite notable improvements in accuracy with multispectral imaging, RGB sensors were highly capable of broad habitat classification and rivaled multispectral sensors for classifying intertidal habitats. High spatial scale monitoring of turbid exposed rocky reefs presents a unique set of challenges, but the limitations of more traditional methods can be overcome by targeting ideal conditions with UAVs.},
author = {Tait, Leigh and Bind, Jochen and Charan-Dixon, Hannah and Hawes, Ian and Pirker, John and Schiel, David},
doi = {10.3390/rs11192332},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2019/Tait et al._2019_Unmanned Aerial Vehicles (UAVs) for Monitoring Macroalgal Biodiversity Comparison of RGB and Multispectral Imaging Sens.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Biodiversity,Classification,Drones,Habitat,Macroalgae,Multispectral,Unmanned aerial vehicles (UAVs)},
month = {oct},
number = {19},
pages = {2332},
publisher = {Multidisciplinary Digital Publishing Institute},
title = {{Unmanned aerial vehicles (UAVs) for monitoring macroalgal biodiversity: Comparison of RGB and multispectral imaging sensors for biodiversity assessments}},
url = {https://www.mdpi.com/2072-4292/11/19/2332/htm https://www.mdpi.com/2072-4292/11/19/2332},
volume = {11},
year = {2019}
}
@misc{Guanter2015,
abstract = {Imaging spectroscopy, also known as hyperspectral remote sensing, is based on the characterization of Earth surface materials and processes through spectrally-resolved measurements of the light interacting with matter. The potential of imaging spectroscopy for Earth remote sensing has been demonstrated since the 1980s. However, most of the developments and applications in imaging spectroscopy have largely relied on airborne spectrometers, as the amount and quality of space-based imaging spectroscopy data remain relatively low to date. The upcoming Environmental Mapping and Analysis Program (EnMAP) German imaging spectroscopy mission is intended to fill this gap. An overview of the main characteristics and current status of the mission is provided in this contribution. The core payload of EnMAP consists of a dual-spectrometer instrument measuring in the optical spectral range between 420 and 2450 nm with a spectral sampling distance varying between 5 and 12 nm and a reference signal-to-noise ratio of 400:1 in the visible and near-infrared and 180:1 in the shortwave-infrared parts of the spectrum. EnMAP images will cover a 30 km-wide area in the across-track direction with a ground sampling distance of 30 m. An across-track tilted observation capability will enable a target revisit time of up to four days at the Equator and better at high latitudes. EnMAP will contribute to the development and exploitation of spaceborne imaging spectroscopy applications by making high-quality data freely available to scientific users worldwide.},
author = {Guanter, Luis and Kaufmann, Hermann and Segl, Karl and Foerster, Saskia and Rogass, Christian and Chabrillat, Sabine and Kuester, Theres and Hollstein, Andr{\'{e}} and Rossner, Godela and Chlebek, Christian and Straif, Christoph and Fischer, Sebastian and Schrader, Stefanie and Storch, Tobias and Heiden, Uta and Mueller, Andreas and Bachmann, Martin and M{\"{u}}hle, Helmut and M{\"{u}}ller, Rupert and Habermeyer, Martin and Ohndorf, Andreas and Hill, Joachim and Buddenbaum, Henning and Hostert, Patrick and {Van Der Linden}, Sebastian and Leit{\~{a}}o, Pedro J. and Rabe, Andreas and Doerffer, Roland and Krasemann, Hajo and Xi, Hongyan and Mauser, Wolfram and Hank, Tobias and Locherer, Matthias and Rast, Michael and Staenz, Karl and Sang, Bernhard},
booktitle = {Remote Sensing},
doi = {10.3390/rs70708830},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2015/Guanter et al._2015_The EnMAP Spaceborne Imaging Spectroscopy Mission for Earth Observation.pdf:pdf},
issn = {20724292},
keywords = {Earth observation,EnMAP,Environmental applications,Hyperspectral remote sensing,Imaging spectroscopy},
month = {jul},
number = {7},
pages = {8830--8857},
publisher = {Multidisciplinary Digital Publishing Institute},
title = {{The EnMAP spaceborne imaging spectroscopy mission for earth observation}},
url = {http://www.mdpi.com/2072-4292/7/7/8830},
volume = {7},
year = {2015}
}
@article{Sivertsen2011a,
abstract = {Traditional quality control of cod fillets is currently made by manual inspection on candling tables. This is a time consuming and expensive operation, contributing to a significant share of the cost with cod fillet production. In this study, transillumination hyperspectral imaging was implemented as a method for automatic nematode detection in cod fillets moving on a conveyer belt, and evaluated on industrially processed cod fillets. An overall detection rate of 58% of all nematodes (N= 922), with detection rate of 71% and 46% for dark and pale nematodes, respectively, is reported. This is comparable, or better, than what is reported for manual inspection under industrial conditions. The false alarm rate was high, with 60% of the fillets reported with one or more false alarms. These results show that the method is promising, but needs further refinements to reduce the false alarm rate and increase the imaging speed from 25 to 400 mm/s. Practical Application: Manual inspection of cod fillets is a huge bottleneck for the industry, accounting for half the production cost with cod fillet processing and reducing the processing speed. Transillumination hyperspectral imaging has the potential to reduce the manual labor required for cod fillet inspection and hence reduce the cost and increase the end product quality.},
author = {Sivertsen, Agnar Holten and Heia, Karsten and Stormo, Svein Kristian and Elvevoll, Edel and Nilsen, Heidi},
doi = {10.1111/j.1750-3841.2010.01928.x},
file = {:C\:/Users/mha114/Dropbox/Litteratur_Mendeley/2011/Sivertsen et al._2011_Automatic Nematode Detection in Cod Fillets (Gadus Morhua) by Transillumination Hyperspectral Imaging.pdf:pdf},
issn = {00221147},
journal = {Journal of Food Science},
keywords = {Animals,Artifacts,Computer-Assisted,Fiber Optic Technology,Food Inspection,Food Inspection: instrumentation,Food Inspection: methods,Gadus morhua,Gadus morhua: parasitology,Image Enhancement,Image Processing,Imaging,Nematoda,Nematoda: growth & development,Nematoda: isolation & purification,Pigmentation,Pilot Projects,Quality Control,Seafood,Seafood: parasitology,Tail,Three-Dimensional,Transillumination},
month = {jan},
number = {1},
pages = {S77--S83},
pmid = {21535719},
title = {{Automatic Nematode Detection in Cod Fillets (Gadus Morhua) by Transillumination Hyperspectral Imaging}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21535719 http://doi.wiley.com/10.1111/j.1750-3841.2010.01928.x},
volume = {76},
year = {2011}
}
