Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Fallati2020,
abstract = {Coral reefs are declining worldwide as a result of the effects of multiple natural and anthropogenic stressors, including regional-scale temperature-induced coral bleaching. Such events have caused significant coral mortality, leading to an evident structural collapse of reefs and shifts in associated benthic communities. In this scenario, reasonable mapping techniques and best practices are critical to improving data collection to describe spatial and temporal patterns of coral reefs after a significant bleaching impact. Our study employed the potential of a consumer-grade drone, coupled with structure from motion and object-based image analysis to investigate for the first time a tool to monitor changes in substrate composition and the associated deterioration in reef environments in a Maldivian shallow-water coral reef. Three key substrate types (hard coral, coral rubble and sand) were detected with high accuracy on high-resolution orthomosaics collected from four sub-areas. Multi-temporal acquisition of UAV data allowed us to compare the classified maps over time (February 2017, November 2018) and obtain evidence of the relevant deterioration in structural complexity of flat reef environments that occurred after the 2016 mass bleaching event. We believe that our proposed methodology offers a cost-effective procedure that is well suited to generate maps for the long-term monitoring of changes in substrate type and reef complexity in shallow water},
author = {Fallati, Luca and Saponari, Luca and Savini, Alessandra and Marchese, Fabio and Corselli, Cesare and Galli, Paolo},
doi = {10.3390/rs12132093},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2020/Fallati et al._2020_Multi-temporal UAV data and object-based image analysis (OBIA) for estimation of substrate changes in a post-bleachi.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Coral bleaching,Coral reefs,Object-based image analysis (OBIA),Republic of Maldives,Structure from motion (SfM),Unmanned aerial vehicles (UAV)},
month = {jul},
number = {13},
pages = {2093},
publisher = {MDPI AG},
title = {{Multi-temporal UAV data and object-based image analysis (OBIA) for estimation of substrate changes in a post-bleaching scenario on a Maldivian reef}},
url = {www.mdpi.com/journal/remotesensing},
volume = {12},
year = {2020}
}
@phdthesis{Simmons2021,
author = {Simmons, Henry},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2021/Simmons_2021_Machine Learning Algorithms for Habitat Type Prediction from Drone-Based multispectral Imagery A Comparison of Classifiers.pdf:pdf},
school = {University of Plymouth},
title = {{Machine Learning Algorithms for Habitat Type Prediction from Drone-Based multispectral Imagery : A Comparison of Classifiers}},
year = {2021}
}
@article{Schlapfer2020,
abstract = {Remote sensing with unmanned aerial vehicles (UAVs) is a fast and cost-efficient tool for mapping and environmental monitoring. The sensors are operated at low flight altitudes, usually below 500 m above ground, leading to spatial resolutions up to the centimeter range. This type of data causes new challenges in atmospheric compensation and surface reflectance retrieval. Based on these specific boundary conditions, a new drone based atmospheric correction concept (DROACOR) is proposed, which is designed for currently available UAV based sensors. It is suited for multispectral visible/near infrared sensors as well as hyperspectral instruments covering the 400-1000&thinsp;nm spectral region or the 400-2500&thinsp;nm spectrum. The goal of the development is a fully automatic processor which dynamically adjusts to the given instrument and the atmospheric conditions. Optionally, irradiance measurements from simultaneously measured cosine receptors or from in-field reference panels can be taken into account to improve the processing quality by adjusting the irradiance parameter or by performing an in-flight vicarious calibration. Examples of DROACOR processing results are presented for a multispectral image data set and a hyperspectral data set, both acquired at variable flight altitudes. The resulting spectra show the applicability of the methods for both sensor types and an accuracy level below 2.5% reflectance units.},
author = {Schl{\"{a}}pfer, D. and Popp, C. and Richter, R.},
doi = {10.5194/isprs-archives-XLIII-B3-2020-473-2020},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2020/Schl{\"{a}}pfer, Popp, Richter_2020_Drone data atmospheric correction concept for multi-and hyperspectral imagery-The droacor model.pdf:pdf},
issn = {16821750},
journal = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
keywords = {Atmospheric Correction,Drone data processing,Reflectance Retrieval,irradiance correction},
number = {B3},
pages = {473--478},
title = {{Drone data atmospheric correction concept for multi-and hyperspectral imagery-The droacor model}},
volume = {43},
year = {2020}
}
@inproceedings{Liu2022,
author = {Liu, Yi and Liu, Qinghui and Sample, James Edward and Hancke, Kasper and Salberg, Arnt-B{\o}rre},
booktitle = {ISPRS},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2022/Liu et al._2022_COASTAL HABITAT MAPPING WITH UAV MULTI-SENSOR DATA AN EXPERIMENT AMONG DCNN-BASED APPROACHES.pdf:pdf},
keywords = {data fusion,deep learning,environmental monitoring,multi-sensor data,semantic segmentation,uav},
title = {{COASTAL HABITAT MAPPING WITH UAV MULTI-SENSOR DATA : AN EXPERIMENT AMONG DCNN-BASED APPROACHES}},
year = {2022}
}
@article{Ventura2023,
abstract = {Accurate data on community structure is a priority issue in studying coastal habitats facing human pressures. The recent development of remote sensing tools has offered a ground-breaking way to collect ecological information at a very fine scale, especially using low-cost aerial photogrammetry. Although coastal mapping is carried out using Unmanned Aerial Vehicles (UAVs or drones), they can provide limited information regarding underwater benthic habitats. To achieve a precise characterisation of underwater habitat types and species assemblages, new imagery acquisition instruments become necessary to support accurate mapping programmes. Therefore, this study aims to evaluate an integrated approach based on Structure from Motion (SfM) photogrammetric acquisition using low-cost Unmanned Aerial (UAV) and Surface (USV) Vehicles to finely map shallow benthic communities, which determine the high complexity of coastal environments. The photogrammetric outputs, including both UAV-based high (sub-meter) and USV-based ultra-high (sub-centimetre) raster products such as orthophoto mosaics and Digital Surface Models (DSMs), were classified using Object-Based Image Analysis (OBIA) approach. The application of a supervised learning method based on Support Vector Machines (SVM) classification resulted in good overall classification accuracies > 70%, proving to be a practical and feasible tool for analysing both aerial and underwater ultra-high spatial resolution imagery. The detected seabed cover classes included above and below-water key coastal features of ecological interest such as seagrass beds, “banquettes” deposits and hard bottoms. Using USV-based imagery can considerably improve the identification of specific organisms with a critical role in benthic communities, such as photophilous macroalgal beds. We conclude that the integrated use of low-cost unmanned aerial and surface vehicles and GIS processing is an effective strategy for allowing fully remote detailed data on shallow water benthic communities.},
author = {Ventura, Daniele and Grosso, Luca and Pensa, Davide and Casoli, Edoardo and Mancini, Gianluca and Valente, Tommaso and Scardi, Michele and Rakaj, Arnold},
doi = {10.3389/fmars.2022.1096594},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2023/Ventura et al._2023_Coastal benthic habitat mapping and monitoring by integrating aerial and water surface low-cost drones.pdf:pdf},
issn = {22967745},
journal = {Frontiers in Marine Science},
keywords = {GIS,OBIA,SfM photogrammetry,algal assemblages,cartography,seagrass,unmanned aerial vehicles (UAV),unmanned surface vehicles (USV)},
number = {January},
pages = {1--15},
title = {{Coastal benthic habitat mapping and monitoring by integrating aerial and water surface low-cost drones}},
volume = {9},
year = {2023}
}
@article{Martin2021,
abstract = {Beach litter assessments rely on time inefficient and high human cost protocols, mining the attainment of global beach litter estimates. Here we show the application of an emerging technique, the use of drones for acquisition of high-resolution beach images coupled with machine learning for their automatic processing, aimed at achieving the first national-scale beach litter survey completed by only one operator. The aerial survey had a time efficiency of 570 ± 40 m2 min−1 and the machine learning reached a mean (±SE) detection sensitivity of 59 ± 3% with high resolution images. The resulting mean (±SE) litter density on Saudi Arabian shores of the Red Sea is of 0.12 ± 0.02 litter items m−2, distributed independently of the population density in the area around the sampling station. Instead, accumulation of litter depended on the exposure of the beach to the prevailing wind and litter composition differed between islands and the main shore, where recreational activities are the major source of anthropogenic debris. A national-scale monitoring of beach litter along the Red Sea coast of Saudi Arabia, conducted by a single drone operator, shows that litter distributes according to wind exposure.},
author = {Martin, Cecilia and Zhang, Qiannan and Zhai, Dongjun and Zhang, Xiangliang and Duarte, Carlos M.},
doi = {10.1016/j.envpol.2021.116730},
issn = {18736424},
journal = {Environmental Pollution},
keywords = {Beach litter,Deep neural network,Marine debris,Plastic,Unmanned aerial vehicles},
month = {feb},
pages = {116730},
pmid = {33652184},
publisher = {Elsevier},
title = {{Enabling a large-scale assessment of litter along Saudi Arabian red sea shores by combining drones and machine learning}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0269749121003109},
volume = {277},
year = {2021}
}
@article{Rossiter2020,
abstract = {Intertidal macroalgal communities mark the boundary of the marine realm and are faced with many direct and indirect anthropogenic pressures. The effective and sustainable management of these resources must be underpinned by accurate, efficient and cost-effective environmental data collection. Traditional field survey methods, whilst accurate, are time-consuming and limited in the area that can be covered. Remote sensing permits large areas to be rapidly surveyed but the effectiveness of satellites and aircraft for mapping fine-scale intertidal macroalgal mapping is limited by their coarse spatial resolution and restricted operational flexibility. The rapid development of unoccupied aerial vehicle (UAV) and sensor technology can address these issues and provide a potential alternative to established remote sensing platforms. Here, a detailed methodology is presented for the assessment of the commercially and ecologically important intertidal brown macroalga Ascophyllum nodosum using a multirotor UAV and pushbroom hyperspectral sensor. Two different classifiers, Maximum Likelihood Classifier (MLC) and Spectral Angle Mapper (SAM), were compared along with two different sources of spectral profiles, one collected in-situ with a spectral radiometer and the other derived from hyperspectral imagery. Of the classifiers compared, both trained using image-derived spectra, MLC more accurately classified A. nodosum, and other common intertidal species and substratum (Overall Accuracy (OA) 94.7%) than SAM (OA 81.1%). In addition, SAM, trained using in-situ spectra, was the least accurate of the three classifier workflows used (OA 71.4%). The low accuracy of the spectral radiometer approach was likely due to high levels of noise present in the hyperspectral data, a result of the relative instability of the UAV platform causing vibration. The accurate mapping of non-target species also highlights the applicability of this methodology for a broader range of intertidal macroalgal species and communities. This research clearly demonstrates the potential of UAV-mounted hyperspectral remote sensing for mapping the spatially and spectral complex macroalgal habitats found within the intertidal zone.},
author = {Rossiter, Thomas and Furey, Thomas and McCarthy, Tim and Stengel, Dagmar B.},
doi = {10.1016/j.ecss.2020.106789},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2020/Rossiter et al._2020_UAV-mounted hyperspectral mapping of intertidal macroalgae.pdf:pdf},
issn = {02727714},
journal = {Estuarine, Coastal and Shelf Science},
keywords = {Ascophyllum nodosum,Hyperspectral,Intertidal,Macroalgae,Remote sensing,UAVs},
number = {August 2019},
pages = {106789},
publisher = {Elsevier Ltd},
title = {{UAV-mounted hyperspectral mapping of intertidal macroalgae}},
url = {https://doi.org/10.1016/j.ecss.2020.106789},
volume = {242},
year = {2020}
}
@article{Christiansen2017,
abstract = {A Light Detection and Ranging (LiDAR) sensor mounted on an Unmanned Aerial Vehicle (UAV) can map the overflown environment in point clouds. Mapped canopy heights allow for the estimation of crop biomass in agriculture. The work presented in this paper contributes to sensory UAV setup design for mapping and textual analysis of agricultural fields. LiDAR data are combined with data from Global Navigation Satellite System (GNSS) and Inertial Measurement Unit (IMU) sensors to conduct environment mapping for point clouds. The proposed method facilitates LiDAR recordings in an experimental winter wheat field. Crop height estimates ranging from 0.35-0.58 m are correlated to the applied nitrogen treatments of 0-300 kg (Formula Presented). The LiDAR point clouds are recorded, mapped, and analysed using the functionalities of the Robot Operating System (ROS) and the Point Cloud Library (PCL). Crop volume estimation is based on a voxel grid with a spatial resolution of 0.04 × 0.04 × 0.001 m. Two different flight patterns are evaluated at an altitude of 6 m to determine the impacts of the mapped LiDAR measurements on crop volume estimations.},
author = {Christiansen, Martin and Laursen, Morten and J{\o}rgensen, Rasmus and Skovsen, S{\o}ren and Gislum, Ren{\'{e}}},
doi = {10.3390/s17122703},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2017/Christiansen et al._2017_Designing and Testing a UAV Mapping System for Agricultural Field Surveying.pdf:pdf},
issn = {1424-8220},
journal = {Sensors},
keywords = {Aerial robotics,Canopy estimation,Crop monitoring,Point cloud,Winter wheat mapping},
month = {nov},
number = {12},
pages = {2703},
publisher = {MDPI AG},
title = {{Designing and Testing a UAV Mapping System for Agricultural Field Surveying}},
url = {http://www.mdpi.com/1424-8220/17/12/2703},
volume = {17},
year = {2017}
}
@article{Murfitt2017,
abstract = {Monitoring of intertidal reefs is traditionally undertaken by on-ground survey methods which have assisted in understanding these complex habitats; however, often only a small spatial footprint of the reef is observed. Recent developments in unmanned aerial vehicles (UAVs) provide new opportunities for monitoring broad scale coastal ecosystems through the ability to capture centimetre resolution imagery and topographic data not possible with conventional approaches. This study compares UAV remote sensing of intertidal reefs to traditional on-ground monitoring surveys, and investigates the role of UAV derived geomorphological variables in explaining observed intertidal algal and invertebrate assemblages. A multirotor UAV was used to capture <1 cm resolution data from intertidal reefs, with on-ground quadrat surveys of intertidal biotic data for comparison. UAV surveys provided reliable estimates of dominant canopy-forming algae, however, understorey species were obscured and often underestimated. UAV derived geomorphic variables showed elevation and distance to seaward reef edge explained 19.7% and 15.9% of the variation in algal and invertebrate assemblage structure respectively. The findings of this study demonstrate benefits of low-cost UAVs for intertidal monitoring through rapid data collection, full coverage census, identification of dominant canopy habitat and generation of geomorphic derivatives for explaining biological variation.},
author = {Murfitt, Sarah L. and Allan, Blake M. and Bellgrove, Alecia and Rattray, Alex and Young, Mary A. and Ierodiaconou, Daniel},
doi = {10.1038/s41598-017-10818-9},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2017/Murfitt et al._2017_Applications of unmanned aerial vehicles in intertidal reef monitoring.pdf:pdf},
issn = {20452322},
journal = {Scientific Reports},
number = {1},
pages = {1--11},
pmid = {28860645},
publisher = {Springer US},
title = {{Applications of unmanned aerial vehicles in intertidal reef monitoring}},
url = {http://dx.doi.org/10.1038/s41598-017-10818-9},
volume = {7},
year = {2017}
}
@article{Joyce2018,
abstract = {With almost limitless applications across marine and freshwater environments, the number of people using, and wanting to use, remotely piloted aircraft systems (or drones) is increasing exponentially. However, successfully using drones for data collection and mapping is often preceded by hours of researching drone capabilities and functionality followed by numerous limited-success flights as users tailor their approach to data collection through trial and error. Working over water can be particularly complex and the published research using drones rarely documents the methodology and practical information in sufficient detail to allow others, with little remote pilot experience, to replicate them or to learn from their mistakes. This can be frustrating and expensive, particularly when working in remote locations where the window of access is small. The aim of this paper is to provide a practical guide to drone-based data acquisition considerations. We hope to minimise the amount of trial and error required to obtain high-quality, map-ready data by outlining the principles and practice of data collection using drones, particularly in marine and freshwater environments. Importantly, our recommendations are grounded in remote sensing and photogrammetry theory so that the data collected are appropriate for making measurements and conducting quantitative data analysis.},
author = {Joyce, K. E. and Duce, S. and Leahy, S. M. and Leon, J. and Maier, S. W.},
doi = {10.1071/MF17380},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2019/Joyce et al._2019_Principles and practice of acquiring drone-based image data in marine environments.pdf:pdf},
issn = {13231650},
journal = {Marine and Freshwater Research},
keywords = {UAS,UAV,high resolution,thermal,three-dimensional mapping,unmanned aerial system,unmanned aerial vehicle},
month = {jul},
number = {7},
pages = {952--963},
publisher = {CSIRO PUBLISHING},
title = {{Principles and practice of acquiring drone-based image data in marine environments}},
url = {https://www.publish.csiro.au/mf/MF17380},
volume = {70},
year = {2019}
}
@inproceedings{Liu2022a,
abstract = {With recent abundant availability of high resolution multi-sensor UAV data and rapid development of deep learning models, efficient automatic mapping using deep neural network is becoming a common approach. However, with the ever-expanding inventories of both data and deep neural network models, it can be confusing to know how to choose. Most models expect input as conventional RGB format, but that can be extended to incorporate multi-sensor data. In this study, we re-implement and modify three deep neural network models of various complexities, namely UNET, DeepLabv3+ and Dense Dilated Convolutions Merging Network to use both RGB and near infrared (NIR) data from a multi-sensor UAV dataset over a Norwegian coastal area. The dataset has been carefully annotated by marine experts for coastal habitats. We find that the NIR channel increases UNET performance significantly but has mixed effects on DeepLabv3+ and DDCM. The latter two are capable of achieving best performance with RGB-only. The class-wise evaluation shows that the NIR channel greatly increases the performance in UNET for green, red algae, vegetation and rock. However, the purpose of the study is not to merely compare the models or to achieve the best performance, but to gain more insights on the compatibility between various models and data types. And as there is an ongoing effort in acquiring and annotating more data, we aim to include them in the coming year.},
author = {Liu, Y. and Liu, Q. and Sample, J. E. and Hancke, K. and Salberg, A. B.},
booktitle = {ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
doi = {10.5194/isprs-Annals-V-3-2022-439-2022},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2022/Liu et al._2022_COASTAL HABITAT MAPPING WITH UAV MULTI-SENSOR DATA AN EXPERIMENT AMONG DCNN-BASED APPROACHES(2).pdf:pdf},
issn = {21949050},
keywords = {UAV,data fusion,deep learning,environmental monitoring,multi-sensor data,semantic segmentation},
month = {may},
number = {3},
pages = {439--445},
title = {{Coastal habitat mapping with uav multi-sensor data: An experiment among dcnn-based approaches}},
url = {https://www.isprs-ann-photogramm-remote-sens-spatial-inf-sci.net/V-3-2022/439/2022/},
volume = {5},
year = {2022}
}
@article{Muslim2019,
abstract = {Although methods were proposed for eliminating sun glint effects from airborne and satellite images over coral reef environments, a method was not proposed previously for unmanned aerial vehicle (UAV) image data. De-glinting in UAV image analysis may improve coral distribution mapping accuracy result compared with an uncorrected image classification technique. The objective of this research was to determine accuracy of coral reef habitat classification maps based on glint correction methods proposed by Lyzenga et al., Joyce, Hedley et al., and Goodman et al. The UAV imagery collected from the coral-dominated Pulau Bidong (Peninsular Malaysia) on 20 April 2016 was analyzed in this study. Images were pre-processed with the following two strategies: Strategy-1 was the glint removal technique applied to the whole image, while Strategy-2 used only the regions impacted by glint instead of the whole image. Accuracy measures for the glint corrected images showed that the method proposed by Lyzenga et al. following Strategy-2 could eliminate glints over the branching coral-Acropora (BC), tabulate coral-Acropora + Montipora (TC), patch coral (PC), coral rubble (R), and sand (S) with greater accuracy than the other four methods using Strategy-1. Tested in two different coral environments (Site-1: Pantai Pasir Cina and Site-2: Pantai Vietnam), the glint-removed UAV imagery produced reliable maps of coral habitat distribution with finer details. The proposed strategies can potentially be used to remove glint from UAV imagery and may improve usability of glint-affected imagery, for analyzing spatiotemporal changes of coral habitats from multi-temporal UAV imagery.},
author = {Muslim, Aidy M. and Chong, Wei Sheng and Safuan, Che Din Mohd and Khalil, Idham and Hossain, Mohammad Shawkat},
doi = {10.3390/rs11202422},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Benthic habitat,Coral,Glint correction,Malaysia,South China Sea,UAV},
month = {oct},
number = {20},
publisher = {MDPI AG},
title = {{Coral reef mapping of UAV: A comparison of sun glint correction methods}},
volume = {11},
year = {2019}
}
@article{Fraser2019,
abstract = {Thematic mapping provides today's analysts with an essential geospatial science tool for conveying spatial information. The advancement of remote sensing and computer science technologies has provided classification methods for mapping at both pixel-based and object-based analysis, for increasingly complex environments. These thematic maps then serve as vital resources for a variety of research and management needs. However, to properly use the resulting thematic map as a decision-making support tool, an assessment of map accuracy must be performed. The methods for assessing thematic accuracy have coalesced into a site-specific multivariate analysis of error, measuring uncertainty in relation to an established reality known as reference data. Ensuring statistical validity, access and time constraints, and immense costs limit the collection of reference data in many projects. Therefore, this research proposes evaluating the feasibility of adopting the low-cost, flexible, high-resolution sensor-capable Unmanned Aerial Systems (UAS, UAV, or Drone) platform for collecting reference data to use in thematic map accuracy assessments for complex environments. This pilot study analyzed 377.57 ha of New England forests, over six University of New Hampshire woodland properties, to compare the similarity between UAS-derived orthomosaic samples and ground-based continuous forest inventory (CFI) plot classifications of deciduous, mixed, and coniferous forest cover types. Using an eBee Plus fixed-wing UAS, 9173 images were acquired and used to create six comprehensive orthomosaics. Agreement between our UAS orthomosaics and ground-based sampling forest compositions reached 71.43% for pixel-based classification and 85.71% for object-based classification reference data methods. Despite several documented sources of uncertainty or error, this research demonstrated that UAS are capable of highly efficient and effective thematic map accuracy assessment reference data collection. As UAS hardware, software, and implementation policies continue to evolve, the potential to meet the challenges of accurate and timely reference data collection will only increase.},
author = {Fraser, Benjamin T. and Congalton, Russell G.},
doi = {10.3390/f10010024},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2019/Fraser, Congalton_2019_Evaluating the effectiveness of Unmanned Aerial Systems (UAS) for collecting thematic map accuracy assessment ref.pdf:pdf},
issn = {19994907},
journal = {Forests},
keywords = {Accuracy assessment,Forest sampling,Photogrammetry,Reference data,Remote sensing,Structure from motion (SfM),Thematic mapping,Unmanned Aerial Systems (UAS),Unmanned Aerial Vehicles (UAV)},
month = {jan},
number = {1},
pages = {24},
publisher = {Multidisciplinary Digital Publishing Institute},
title = {{Evaluating the effectiveness of Unmanned Aerial Systems (UAS) for collecting thematic map accuracy assessment reference data in New England forests}},
url = {http://www.mdpi.com/1999-4907/10/1/24},
volume = {10},
year = {2019}
}
@article{McKenzie2022,
abstract = {Seagrass meadows are a key ecosystem of the Great Barrier Reef World Heritage Area, providing one of the natural heritage attributes underpinning the reef's outstanding universal value. We reviewed approaches employed to date to create maps of seagrass meadows in the optically complex waters of the Great Barrier Reef and explored enhanced mapping approaches with a focus on emerging technologies, and key considerations for future mapping. Our review showed that field-based mapping of seagrass has traditionally been the most common approach in the GBR-WHA, with few attempts to adopt remote sensing approaches and emerging technologies. Using a series of case studies to harness the power of machine-and deep-learning, we mapped seagrass cover with PlanetScope and UAV-captured imagery in a variety of settings. Using a machine-learn-ing pixel-based classification coupled with a bootstrapping process, we were able to significantly improve maps of seagrass, particularly in low cover, fragmented and complex habitats. We also used deep-learning models to derive enhanced maps from UAV imagery. Combined, these lessons and emerging technologies show that more accurate and efficient seagrass mapping approaches are possible, producing maps of higher confidence for users and enabling the upscaling of seagrass mapping into the future.},
author = {McKenzie, Len J. and Langlois, Lucas A. and Roelfsema, Chris M.},
doi = {10.3390/rs14112604},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2022/McKenzie, Langlois, Roelfsema_2022_Improving Approaches to Mapping Seagrass within the Great Barrier Reef From Field to Spaceborne Earth.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Great Barrier Reef,UAV,deep-learning,earth observing,machine-learning,map confidence,mapping,seagrass,spaceborne},
month = {may},
number = {11},
pages = {2604},
title = {{Improving Approaches to Mapping Seagrass within the Great Barrier Reef: From Field to Spaceborne Earth Observation}},
url = {https://www.mdpi.com/2072-4292/14/11/2604},
volume = {14},
year = {2022}
}
@article{Gaston2018a,
abstract = {The monitoring of invasive grasses and vegetation in remote areas is challenging, costly, and on the ground sometimes dangerous. Satellite and manned aircraft surveys can assist but their use may be limited due to the ground sampling resolution or cloud cover. Straightforward and accurate surveillance methods are needed to quantify rates of grass invasion, offer appropriate vegetation tracking reports, and apply optimal control methods. This paper presents a pipeline process to detect and generate a pixel-wise segmentation of invasive grasses, using buffel grass (Cenchrus ciliaris) and spinifex (Triodia sp.) as examples. The process integrates unmanned aerial vehicles (UAVs) also commonly known as drones, high-resolution red, green, blue colour model (RGB) cameras, and a data processing approach based on machine learning algorithms. The methods are illustrated with data acquired in Cape Range National Park, Western Australia (WA), Australia, orthorectified in Agisoft Photoscan Pro, and processed in Python programming language, scikit-learn, and eXtreme Gradient Boosting (XGBoost) libraries. In total, 342,626 samples were extracted from the obtained data set and labelled into six classes. Segmentation results provided an individual detection rate of 97% for buffel grass and 96% for spinifex, with a global multiclass pixel-wise detection rate of 97%. Obtained results were robust against illumination changes, object rotation, occlusion, background cluttering, and floral density variation.},
author = {Gaston, Kevin J.},
doi = {10.3390/s18020605},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2018/Gaston_2018_UAVs and Machine Learning Revolutionising Invasive Grass and Vegetation Surveys in Remote Arid Lands.pdf:pdf},
issn = {1424-8220},
journal = {Sensors},
keywords = {Biosecurity,Buffel grass,Cenchrus ciliaris,Drones,Remote surveillance,Spinifex,Triodia sp,Unmanned aerial vehicles (UAV),Vegetation assessments,Xgboost},
month = {feb},
number = {2},
pages = {605},
publisher = {MDPI AG},
title = {{UAVs and Machine Learning Revolutionising Invasive Grass and Vegetation Surveys in Remote Arid Lands}},
url = {http://www.mdpi.com/1424-8220/18/2/605},
volume = {18},
year = {2018}
}
@article{Pajares2015,
abstract = {Remotely Piloted Aircraft (RPA) is presently in continuous development at a rapid pace. Unmanned Aerial Vehicles (UAVs) or more extensively Unmanned Aerial Systems (UAS) are platforms considered under the RPAs paradigm. Simulta-neously, the development of sensors and instruments to be installed onboard such platforms is growing exponentially. These two factors together have led to the increasing use of these platforms and sensors for remote sensing applications with new potential. Thus, the overall goal of this paper is to provide a panoramic overview about the current status of remote sensing applications based on unmanned aerial platforms equipped with a set of specific sensors and instru-ments. First, some examples of typical platforms used in remote sensing are provided. Second, a description of sensors and technologies is explored which are onboard instruments specifically intended to capture data for remote sensing ap-plications. Third, multi-UAVs in collaboration, coordination, and cooperation in remote sensing are considered. Finally, a collection of applications in several areas are proposed, where the combination of unmanned platforms and sensors, together with methods, algorithms, and procedures provide the overview in very different remote sensing applications. This paper presents an overview of different areas, each inde-pendent from the others, so that the reader does not need to read the full paper when a specific application is of interest.},
author = {Pajares, Gonzalo},
doi = {10.14358/PERS.81.4.281},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2015/Pajares_2015_Overview and Current Status of Remote Sensing Applications Based on Unmanned Aerial Vehicles (UAVs).pdf:pdf},
issn = {00991112},
journal = {Photogrammetric Engineering and Remote Sensing},
month = {apr},
number = {4},
pages = {281--329},
title = {{Overview and current status of remote sensing applications based on unmanned aerial vehicles (UAVs)}},
url = {http://openurl.ingenta.com/content/xref?genre=article&issn=0099-1112&volume=81&issue=4&spage=281},
volume = {81},
year = {2015}
}
@article{Sandino2017,
abstract = {The increased technological developments in Unmanned Aerial Vehicles (UAVs) combined with artificial intelligence and Machine Learning (ML) approaches have opened the possibility of remote sensing of extensive areas of arid lands. In this paper, a novel approach towards the detection of termite mounds with the use of a UAV, hyperspectral imagery, ML and digital image processing is intended. A new pipeline process is proposed to detect termite mounds automatically and to reduce, consequently, detection times. For the classification stage, several ML classification algorithms' outcomes were studied, selecting support vector machines as the best approach for their role in image classification of pre-existing termite mounds. Various test conditions were applied to the proposed algorithm, obtaining an overall accuracy of 68%. Images with satisfactory mound detection proved that the method is “resolution-dependent”. These mounds were detected regardless of their rotation and position in the aerial image. However, image distortion reduced the number of detected mounds due to the inclusion of a shape analysis method in the object detection phase, and image resolution is still determinant to obtain accurate results. Hyperspectral imagery demonstrated better capabilities to classify a huge set of materials than implementing traditional segmentation methods on RGB images only.},
author = {Sandino, Juan and Wooler, Adam and Gonzalez, Felipe},
doi = {10.3390/s17102196},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2017/Sandino, Wooler, Gonzalez_2017_Towards the Automatic Detection of Pre-Existing Termite Mounds through UAS and Hyperspectral Imagery.pdf:pdf},
issn = {14248220},
journal = {Sensors (Switzerland)},
keywords = {Hyperspectral camera,Image segmentation,Machine learning,Pre-existing termite mounds,Support vector machines,UAV},
month = {sep},
number = {10},
pages = {2196},
pmid = {28946639},
publisher = {MDPI AG},
title = {{Towards the automatic detection of pre-existing termite mounds through UAS and hyperspectral imagery}},
url = {http://www.mdpi.com/1424-8220/17/10/2196},
volume = {17},
year = {2017}
}
@techreport{Schmiel2023a,
author = {Schmiel, Alexandre C. G. and Thormar, Jonas and Oveland, Ivar and Thorsnes, Terje and Elvenes, Sigrid and Kurz, Tobias and Welde, Helge},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2023/Schmiel et al._2023_Summary report of datasets acquired for the purpose of method development within the Marine Base Maps for the Coasta.pdf:pdf},
title = {{Summary report of datasets acquired for the purpose of method development within the Marine Base Maps for the Coastal Zone (Marine grunnkart i kystsonen) project at Fj{\o}l{\o}y and Kloster{\o}y, Stavanger, Norway}},
year = {2023}
}
@article{Norris2024,
abstract = {Monitoring salt marshes with remote sensing is necessary to evaluate their state and restoration. Determining appropriate techniques for this can be overwhelming. Our study provides insight into whether a pixel- or object-based Random Forest classification approach is best for mapping vegetation in north temperate salt marshes. We used input variables from drone images (raw reflectances, vegetation indices, and textural features) acquired in June, July, and August 2021 of a salt marsh restoration and reference site in Aulac, New Brunswick, Canada. We also investigated the importance of input variables and whether using landcover classes representing areas of change was a practical way to evaluate variation in the monthly images. Our results indicated that (1) the classifiers achieved overall validation accuracies of 91.1–95.2%; (2) pixel-based classifiers outperformed object-based classifiers by 1.3–2.0%; (3) input variables extracted from the August images were more important than those extracted from the June and July images; (4) certain raw reflectances, vegetation indices, and textural features were among the most important variables; and (5) classes that changed temporally were mapped with user's and producer's validation accuracies of 86.7–100.0%. Knowledge gained during this study will inform assessments of salt marsh restoration trajectories spanning multiple years.},
author = {Norris, Gregory S. and LaRocque, Armand and Leblon, Brigitte and Barbeau, Myriam A. and Hanson, Alan R.},
doi = {10.3390/rs16061049},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2024/Norris et al._2024_Comparing Pixel- and Object-Based Approaches for Classifying Multispectral Drone Imagery of a Salt Marsh Restoration.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Bay of Fundy,Random Forest,ecological restoration,image classification,object-based image analysis,pixel-based image analysis,wetland},
month = {mar},
number = {6},
pages = {1049},
publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
title = {{Comparing Pixel- and Object-Based Approaches for Classifying Multispectral Drone Imagery of a Salt Marsh Restoration and Reference Site}},
url = {https://www.mdpi.com/2072-4292/16/6/1049/htm https://www.mdpi.com/2072-4292/16/6/1049},
volume = {16},
year = {2024}
}
@article{Joyce2019,
abstract = {With almost limitless applications across marine and freshwater environments, the number of people using, and wanting to use, remotely piloted aircraft systems (or drones) is increasing exponentially. However, successfully using drones for data collection and mapping is often preceded by hours of researching drone capabilities and functionality followed by numerous limited-success flights as users tailor their approach to data collection through trial and error. Working over water can be particularly complex and the published research using drones rarely documents the methodology and practical information in sufficient detail to allow others, with little remote pilot experience, to replicate them or to learn from their mistakes. This can be frustrating and expensive, particularly when working in remote locations where the window of access is small. The aim of this paper is to provide a practical guide to drone-based data acquisition considerations. We hope to minimise the amount of trial and error required to obtain high-quality, map-ready data by outlining the principles and practice of data collection using drones, particularly in marine and freshwater environments. Importantly, our recommendations are grounded in remote sensing and photogrammetry theory so that the data collected are appropriate for making measurements and conducting quantitative data analysis.},
author = {Joyce, K. E. and Duce, S. and Leahy, S. M. and Leon, J. and Maier, S. W.},
doi = {10.1071/MF17380},
issn = {13231650},
journal = {Marine and Freshwater Research},
keywords = {UAS,UAV,high resolution,thermal,three-dimensional mapping,unmanned aerial system,unmanned aerial vehicle},
number = {7},
pages = {952--963},
publisher = {CSIRO},
title = {{Principles and practice of acquiring drone-based image data in marine environments}},
volume = {70},
year = {2019}
}
@article{Ortega-Terol2017,
abstract = {Last advances in sensors, photogrammetry and computer vision have led to high-automation levels of 3D reconstruction processes for generating dense models and multispectral orthoimages from Unmanned Aerial Vehicle (UAV) images. However, these cartographic products are sometimes blurred and degraded due to sun reflection effects which reduce the image contrast and colour fidelity in photogrammetry and the quality of radiometric values in remote sensing applications. This paper proposes an automatic approach for detecting sun reflections problems (hotspot and sun glint) in multispectral images acquired with an Unmanned Aerial Vehicle (UAV), based on a photogrammetric strategy included in a flight planning and control software developed by the authors. In particular, two main consequences are derived from the approach developed: (i) different areas of the images can be excluded since they contain sun reflection problems; (ii) the cartographic products obtained (e.g., digital terrain model, orthoimages) and the agronomical parameters computed (e.g., normalized vegetation index-NVDI) are improved since radiometric defects in pixels are not considered. Finally, an accuracy assessment was performed in order to analyse the error in the detection process, getting errors around 10 pixels for a ground sample distance (GSD) of 5 cm which is perfectly valid for agricultural applications. This error confirms that the precision in the detection of sun reflections can be guaranteed using this approach and the current low-cost UAV technology.},
author = {Ortega-Terol, Damian and Hernandez-Lopez, David and Ballesteros, Rocio and Gonzalez-Aguilera, Diego},
doi = {10.3390/s17102352},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2017/Ortega-Terol et al._2017_Automatic Hotspot and Sun Glint Detection in UAV Multispectral Images.pdf:pdf},
issn = {1424-8220},
journal = {Sensors},
keywords = {Flight planning and control,Hotspot,Image preprocessing,Photogrammetry,Remote sensing,Software development,Sun glint,UAV},
month = {oct},
number = {10},
pages = {2352},
publisher = {MDPI AG},
title = {{Automatic Hotspot and Sun Glint Detection in UAV Multispectral Images}},
url = {http://www.mdpi.com/1424-8220/17/10/2352},
volume = {17},
year = {2017}
}
@article{Ventura2018,
abstract = {Nowadays, emerging technologies, such as long-range transmitters, increasingly miniaturized components for positioning, and enhanced imaging sensors, have led to an upsurge in the availability of new ecological applications for remote sensing based on unmanned aerial vehicles (UAVs), sometimes referred to as "drones". In fact, structure-from-motion (SfM) photogrammetry coupled with imagery acquired by UAVs offers a rapid and inexpensive tool to produce high-resolution orthomosaics, giving ecologists a new way for responsive, timely, and cost-effective monitoring of ecological processes. Here, we adopted a lightweight quadcopter as an aerial survey tool and object-based image analysis (OBIA) workflow to demonstrate the strength of such methods in producing very high spatial resolution maps of sensitive marine habitats. Therefore, three different coastal environments were mapped using the autonomous flight capability of a lightweight UAV equipped with a fully stabilized consumer-grade RGB digital camera. In particular we investigated a Posidonia oceanica seagrass meadow, a rocky coast with nurseries for juvenile fish, and two sandy areas showing biogenic reefs of Sabelleria alveolata. We adopted, for the first time, UAV-based raster thematic maps of these key coastal habitats, produced after OBIA classification, as a new method for fine-scale, low-cost, and time saving characterization of sensitive marine environments which may lead to a more effective and efficient monitoring and management of natural resources.},
author = {Ventura, Daniele and Bonifazi, Andrea and Gravina, Maria Flavia and Belluscio, Andrea and Ardizzone, Giandomenico},
doi = {10.3390/rs10091331},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2018/Ventura et al._2018_Mapping and classification of ecologically sensitive marine habitats using unmanned aerial vehicle (UAV) imagery and.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Aerial mapping,Image classification,Mapping,Marine coastal habitats,Mediterranean Sea,Object-based image analysis (OBIA),Structure from Motion (SfM),Unmanned aerial systems/vehicles (UAS/UAV)},
month = {aug},
number = {9},
pages = {1331},
publisher = {Multidisciplinary Digital Publishing Institute},
title = {{Mapping and classification of ecologically sensitive marine habitats using unmanned aerial vehicle (UAV) imagery and Object-Based Image Analysis (OBIA)}},
url = {https://www.mdpi.com/2072-4292/10/9/1331/htm https://www.mdpi.com/2072-4292/10/9/1331},
volume = {10},
year = {2018}
}
