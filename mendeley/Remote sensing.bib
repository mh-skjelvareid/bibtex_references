Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Casal2012,
abstract = {R{\'{i}}a de Vigo and R{\'{i}}a de Ald{\'{a}}n have high biological richness that is reflected in the number of environmental protection areas like the Atlantic Islands National Park and five places of community interest. Benthic algal communities play an important role in these ecosystems due to their ecological functions and support a great part of this biological richness. We tested by means of bio-optical modelling and Airborne Hyperspectral Scanner (AHS) images to what extent remote sensing could be used to map these communities in R{\'{i}}a de Vigo and R{\'{i}}a de Ald{\'{a}}n (NW Spain). Reflectance spectra of dominating macroalgae groups were modelled for different water depths in order to estimate the separability of different bottom types based on their spectral signatures and the spectral characteristics of the AHS. Our results indicate that separation between three macroalgae groups (green, brown and red) as well as sand is possible when the bottoms are emerged during low tide. The spectra differences decrease rapidly with increasing water depth. Two types of classifications were carried out with the three AHS images: maximum likelihood and spectral angle mapper (SAM). Maximum likelihood showed positive results reaching overall accuracy percentages higher than 95 % and kappa coefficients higher than 0. 90 for the bottom classes: shallow sand, deep sand, emerged rock, emerged macroalgae and submerged macroalgae. Sand and algae substrates were then separately analysed with SAM. These classifications showed positive results for differentiation between green and brown macroalgae until 5 m depth and high differences between all macroalgae and sandy substrate. However, differences between red and brown macroalgae are only detectable when the algae are emerged. {\textcopyright} 2012 Springer-Verlag.},
author = {Casal, G. and S{\'{a}}nchez-Carnero, N. and Dom{\'{i}}nguez-G{\'{o}}mez, J. A. and Kutser, T. and Freire, J.},
doi = {10.1007/s00227-012-1987-5},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2012/Casal et al._2012_Assessment of AHS (Airborne Hyperspectral Scanner) sensor to map macroalgal communities on the R{\'{i}}a de vigo and R{\'{i}}a de.pdf:pdf},
issn = {00253162},
journal = {Marine Biology},
keywords = {Freshwater & Marine Ecology,Marine & Freshwater Sciences,Microbiology,Oceanography,Zoology},
month = {sep},
number = {9},
pages = {1997--2013},
publisher = {Springer},
title = {{Assessment of AHS (Airborne Hyperspectral Scanner) sensor to map macroalgal communities on the R{\'{i}}a de vigo and R{\'{i}}a de Ald{\'{a}}n coast (NW Spain)}},
url = {https://link.springer.com/article/10.1007/s00227-012-1987-5},
volume = {159},
year = {2012}
}
@article{Traganos2018,
abstract = {In the epoch of the human-induced climate change, seagrasses can mitigate the resulting negative impacts due to their carbon sequestration ability. The endemic and dominant in the Mediterranean Posidonia oceanica seagrass contains the largest stocks of organic carbon among all seagrass species, yet it undergoes a significant regression in its extent. Therefore, suitable quantitative assessment of its extent and optically shallow environment are required to allow good conservation and management practices. Here, we parameterise a semi-analytical inversion model which employs above-surface remote sensing reflectance of Sentinel-2A to derive water column and bottom properties in the Thermaikos Gulf, NW Aegean Sea, Greece (eastern Mediterranean). In the model, the diffuse attenuation coefficients are expressed as functions of absorption and backscattering coefficients. We apply a comprehensive pre-processing workflow which includes atmospheric correction using C2RCC (Case 2 Regional CoastColour) neural network, resampling of the lower spatial resolution Sentinel-2A bands to 10m/pixel, as well as empirical derivation of water bathymetry and machine learning-based classification of the resulting bottom properties using the Support Vector Machines. SVM-based classification of benthic reflectance reveals $\sim$300 ha of P. oceanica seagrass between 2 and 16 m of depth, and yields very high producer and user accuracies of 95.3% and 99.5%, respectively. Sources of errors and uncertainties are discussed. All in all, recent advances in Earth Observation in terms of optical satellite technology, cloud computing and machine learning algorithms have created the perfect storm which could aid high spatio-temporal, large-scale seagrass habitat mapping and monitoring, allowing for its integration to the Analysis Ready Data era and ultimately enabling more efficient management and conservation in the epoch of climate change.},
author = {Traganos, Dimosthenis and Reinartz, Peter},
doi = {10.1080/01431161.2018.1519289},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2018/Traganos, Reinartz_2018_Machine learning-based retrieval of benthic reflectance and Posidonia oceanica seagrass extent using a semi-anal.pdf:pdf},
issn = {13665901},
journal = {International Journal of Remote Sensing},
number = {24},
pages = {9428--9452},
publisher = {Taylor & Francis},
title = {{Machine learning-based retrieval of benthic reflectance and Posidonia oceanica seagrass extent using a semi-analytical inversion of Sentinel-2 satellite data}},
url = {https://doi.org/10.1080/01431161.2018.1519289},
volume = {39},
year = {2018}
}
@article{Douay2022,
abstract = {The recent development and miniaturization of hyperspectral sensors embedded in drones has allowed the acquisition of hyperspectral images with high spectral and spatial resolution. The characteristics of both the embedded sensors and drones (viewing angle, flying altitude, resolution) create opportunities to consider the use of hyperspectral imagery to map and monitor macroalgae communities. In general, the overflight of the areas to be mapped is conconmittently associated accompanied with measurements carried out in the field to acquire the spectra of previously identified objects. An alternative to these simultaneous acquisitions is to use a hyperspectral library made up of pure spectra of the different species in place, that would spare field acquisition of spectra during each flight. However, the use of such a technique requires developed appropriate procedure for testing the level of species classification that can be achieved, as well as the reproducibility of the classification over time. This study presents a novel classification approach based on the use of reflectance spectra of macroalgae acquired in controlled conditions. This overall approach developed is based on both the use of the spectral angle mapper (SAM) algorithm applied on first derivative hyperspectral data. The efficiency of this approach has been tested on a hyperspectral library composed of 16 macroalgae species, and its temporal reproducibility has been tested on a monthly survey of the spectral response of different macro-algae species. In addition, the classification results obtained with this new approach were also compared to the results obtained through the use of the most recent and robust procedure published. The classification obtained shows that the developed approach allows to perfectly discriminate the different phyla, whatever the period. At the species level, the classification approach is less effective when the individuals studied belong to phylogenetically close species (i.e., Fucus spiralis and Fucus serratus).},
author = {Douay, Florian and Verpoorter, Charles and Duong, Gwendoline and Spilmont, Nicolas and Gevaert, Fran{\c{c}}ois},
doi = {10.3390/rs14020346},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2022/Douay et al._2022_New Hyperspectral Procedure to Discriminate Intertidal Macroalgae.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Hyperspectral library,Intertidal macroalgae,Photosynthetic pigments,Spectral classification},
number = {2},
title = {{New Hyperspectral Procedure to Discriminate Intertidal Macroalgae}},
volume = {14},
year = {2022}
}
@article{Thompson2017,
abstract = {Remote imaging spectroscopy from 400 to 800 nm can use benthic reflectance signatures to map the composition and condition of shallow water ecosystems. We present a novel probabilistic approach to jointly estimate the seafloor reflectance and water properties while flexibly incorporating varied domain knowledge and in situ measurements. The inversion transforms remote radiance data with an atmospheric correction followed by a water column correction. Benthic reflectance and water optical properties are both represented by linear mixtures of endmember spectra. We combine remote measurements, prior knowledge and field data using a flexible Bayesian optimal estimation, solving for the Maximum A Posteriori (MAP) combination of water column properties, seafloor reflectance, and depth. We then demonstrate performance in controlled simulations and in overflights of a coral reef in Hawaii with coincident in situ measurements. The measurement approach helps lay a foundation for wide-area airborne mapping of the condition of threatened coastal ecosystems such as coral reefs.},
author = {Thompson, David R. and Hochberg, Eric J. and Asner, Gregory P. and Green, Robert O. and Knapp, David E. and Gao, Bo Cai and Garcia, Rodrigo and Gierach, Michelle and Lee, Zhongping and Maritorena, Stephane and Fick, Ronald},
doi = {10.1016/j.rse.2017.07.030},
issn = {00344257},
journal = {Remote Sensing of Environment},
keywords = {Atmospheric correction,Coral reefs,Imaging spectroscopy,Remote sensing},
month = {oct},
pages = {18--30},
publisher = {Elsevier Inc.},
title = {{Airborne mapping of benthic reflectance spectra with Bayesian linear mixtures}},
volume = {200},
year = {2017}
}
@article{Mobley1999a,
abstract = {The remote-sensing reflectance R(rs) is not directly measurable, and various methodologies have been employed in its estimation. I review the radiative transfer foundations of several commonly used methods for estimating R(rs), and errors associated with estimating R(rs) by removal of surface-reflected sky radiance are evaluated using the Hydrolight radiative transfer numerical model. The dependence of the sea surface reflectance factor rho, which is not an inherent optical property of the surface, on sky conditions, wind speed, solar zenith angle, and viewing geometry is examined. If rho is not estimated accurately, significant errors can occur in the estimated R(rs) for near-zenith Sun positions and for high wind speeds, both of which can give considerable Sun glitter effects. The numerical simulations suggest that a viewing direction of 40 deg from the nadir and 135 deg from the Sun is a reasonable compromise among conflicting requirements. For this viewing direction, a value of rho approximately 0.028 is acceptable only for wind speeds less than 5 m s(-1). For higher wind speeds, curves are presented for the determination of rho as a function of solar zenith angle and wind speed. If the sky is overcast, a value of rho approximately 0.028 is used at all wind speeds.},
author = {Mobley, Curtis D.},
doi = {10.1364/ao.38.007442},
file = {:C\:/Users/mha114/Dropbox/Litteratur/1999/Mobley_1999_Estimation of the remote-sensing reflectance from above-surface measurements(2).pdf:pdf},
issn = {0003-6935},
journal = {Applied Optics},
number = {36},
pages = {7442},
pmid = {18324298},
title = {{Estimation of the remote-sensing reflectance from above-surface measurements}},
volume = {38},
year = {1999}
}
@article{Benz2004,
abstract = {Remote sensing from airborne and spaceborne platforms provides valuable data for mapping, environmental monitoring, disaster management and civil and military intelligence. However, to explore the full value of these data, the appropriate information has to be extracted and presented in standard format to import it into geo-information systems and thus allow efficient decision processes. The object-oriented approach can contribute to powerful automatic and semi-automatic analysis for most remote sensing applications. Synergetic use to pixel-based or statistical signal processing methods explores the rich information contents. Here, we explain principal strategies of object-oriented analysis, discuss how the combination with fuzzy methods allows implementing expert knowledge and describe a representative example for the proposed workflow from remote sensing imagery to GIS. The strategies are demonstrated using the first object-oriented image analysis software on the market, eCognition, which provides an appropriate link between remote sensing imagery and GIS. {\textcopyright} 2003 Elsevier B.V. All rights reserved.},
author = {Benz, Ursula C. and Hofmann, Peter and Willhauck, Gregor and Lingenfelder, Iris and Heynen, Markus},
doi = {10.1016/j.isprsjprs.2003.10.002},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2004/Benz et al._2004_Multi-resolution, object-oriented fuzzy analysis of remote sensing data for GIS-ready information.pdf:pdf},
issn = {09242716},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
keywords = {Fuzzy classification,GIS,Multi-resolution segmentation,Object-oriented image analysis,Remote sensing},
number = {3-4},
pages = {239--258},
title = {{Multi-resolution, object-oriented fuzzy analysis of remote sensing data for GIS-ready information}},
volume = {58},
year = {2004}
}
@article{Su2006,
abstract = {Eelgrass (Zostera marina) can provide vital ecological functions in stabilizing sediments, influencing current dynamics, and contributing significant amounts of biomass to numerous food webs in coastal ecosystems. Mapping eelgrass beds is important for coastal water and nearshore estuarine monitoring, management, and planning. This study demonstrated the possible use of high spatial (approximately 5 m) and temporal (maximum low tide) resolution airborne multispectral scanner on mapping eelgrass beds in Northern Puget Sound, Washington. A combination of supervised and unsupervised classification approaches were performed on the multispectral scanner imagery. A normalized difference vegetation index (NDVI) derived from the red and near-infrared bands and ancillary spatial information, were used to extract and mask eelgrass beds and other submerged aquatic vegetation (SAV) in the study area. We evaluated the resulting thematic map (geocoded, classified image) against a conventional aerial photograph interpretation using 260 point locations randomly stratified over five defined classes from the thematic map. We achieved an overall accuracy of 92 percent with 0.92 Kappa Coefficient in the study area. This study demonstrates that the airborne multispectral scanner can be useful for mapping eelgrass beds in a local or regional scale, especially in regions for which optical remote sensing from space is constrained by climatic and tidal conditions. {\textcopyright} 2006 American Society for Photogrammetry and Remote Sensing.},
author = {Su, Haiping and Karna, Duane and Fraim, Eric and Fitzgerald, Michael and Dominguez, Rose and Myers, Jeffrey S. and Coffland, Bruce and Handley, Lawrence R. and Mace, Thomas},
doi = {10.14358/PERS.72.7.789},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2006/Su et al._2006_Evaluation of eelgrass beds mapping using a high-resolution airborne multispectral scanner.pdf:pdf},
issn = {00991112},
journal = {Photogrammetric Engineering and Remote Sensing},
month = {jul},
number = {7},
pages = {789--797},
title = {{Evaluation of eelgrass beds mapping using a high-resolution airborne multispectral scanner}},
url = {http://openurl.ingenta.com/content/xref?genre=article&issn=0099-1112&volume=72&issue=7&spage=789},
volume = {72},
year = {2006}
}
@incollection{Stekoll2006,
abstract = {Regulations of the Alaska Department of Fish and Game require that all fisheries in the state have a harvest management plan. In southeast Alaska two species of floating kelps, Nereocystis luetkeana and Alaria fistulosa, have been commercially harvested since 1992 for use as agrochemicals by the Alaska Kelp Company. However, there is currently no harvest management plan for this fishery. The lack of a formalized management plan is one factor that has kept the kelp industry from expanding in the state. We have employed an aerial digital multispectral imaging system (DMSC) calibrated with ground truthing for performing such an assessment. The system can be flown at varying altitudes to achieve spatial resolutions ranging from 0.5 to 2 m. Rapid ground truthing techniques were developed using morphometric measurements to predict biomass. Analysis of the DMSC imagery showed that good correlations could be developed between the multispectral imagery and kelp biomass estimates collected at the ground-truth sites. Repeatable estimates of kelp bed area derived from the multispectral imagery could be made at varying tidal levels. However, broad scale maps of kelp biomass suitable for estimating harvest rates could not be made at different tide levels. Multispectral imagery suitable for this purpose must be collected at a standard tidal level.},
address = {Dordrecht},
author = {Stekoll, M. S. and Deysher, L. E. and Hess, M.},
booktitle = {Eighteenth International Seaweed Symposium},
doi = {10.1007/978-1-4020-5670-3_13},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2006/Stekoll, Deysher, Hess_2006_A remote sensing approach to estimating harvestable kelp biomass.pdf:pdf},
pages = {97--108},
publisher = {Springer Netherlands},
title = {{A remote sensing approach to estimating harvestable kelp biomass}},
url = {http://link.springer.com/10.1007/978-1-4020-5670-3_13},
year = {2008}
}
@article{Schlapfer2020,
abstract = {Remote sensing with unmanned aerial vehicles (UAVs) is a fast and cost-efficient tool for mapping and environmental monitoring. The sensors are operated at low flight altitudes, usually below 500 m above ground, leading to spatial resolutions up to the centimeter range. This type of data causes new challenges in atmospheric compensation and surface reflectance retrieval. Based on these specific boundary conditions, a new drone based atmospheric correction concept (DROACOR) is proposed, which is designed for currently available UAV based sensors. It is suited for multispectral visible/near infrared sensors as well as hyperspectral instruments covering the 400-1000&thinsp;nm spectral region or the 400-2500&thinsp;nm spectrum. The goal of the development is a fully automatic processor which dynamically adjusts to the given instrument and the atmospheric conditions. Optionally, irradiance measurements from simultaneously measured cosine receptors or from in-field reference panels can be taken into account to improve the processing quality by adjusting the irradiance parameter or by performing an in-flight vicarious calibration. Examples of DROACOR processing results are presented for a multispectral image data set and a hyperspectral data set, both acquired at variable flight altitudes. The resulting spectra show the applicability of the methods for both sensor types and an accuracy level below 2.5% reflectance units.},
author = {Schl{\"{a}}pfer, D. and Popp, C. and Richter, R.},
doi = {10.5194/isprs-archives-XLIII-B3-2020-473-2020},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2020/Schl{\"{a}}pfer, Popp, Richter_2020_Drone data atmospheric correction concept for multi-and hyperspectral imagery-The droacor model.pdf:pdf},
issn = {16821750},
journal = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
keywords = {Atmospheric Correction,Drone data processing,Reflectance Retrieval,irradiance correction},
number = {B3},
pages = {473--478},
title = {{Drone data atmospheric correction concept for multi-and hyperspectral imagery-The droacor model}},
volume = {43},
year = {2020}
}
@inproceedings{Liu2022,
author = {Liu, Yi and Liu, Qinghui and Sample, James Edward and Hancke, Kasper and Salberg, Arnt-B{\o}rre},
booktitle = {ISPRS},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2022/Liu et al._2022_COASTAL HABITAT MAPPING WITH UAV MULTI-SENSOR DATA AN EXPERIMENT AMONG DCNN-BASED APPROACHES.pdf:pdf},
keywords = {data fusion,deep learning,environmental monitoring,multi-sensor data,semantic segmentation,uav},
title = {{COASTAL HABITAT MAPPING WITH UAV MULTI-SENSOR DATA : AN EXPERIMENT AMONG DCNN-BASED APPROACHES}},
year = {2022}
}
@article{Kutser2020a,
abstract = {Technical advancements have widened the limits of remote sensing in mapping shallow water benthic habitats and bathymetry over the last decades. On the other hand, the needs of shallow water remote sensing have pushed instrument development. In this manuscript we provide 50-year retrospective of the developments in the field in terms of both instrumentation and methods. We also show that spectral features characteristic of the main benthic groups in shallow water are consistent from the tropics to sub-arctic regions and from salty to freshwaters. The fundamental limiting factor in both benthic mapping and bathymetry is absorption of light by water molecules. However, spectral absorption by water molecules is the key to bathymetry derivation. Variable backscattering by particles and absorption by dissolved organic matter is a confounding factor for all objectives. The combination of using the spectral and textural characteristics of bottom features and our knowledge about these features have now resulted in the ability to map habitats over large coastal systems. This manuscript has shown that optically shallow water remote sensing has reached levels where the satellite derived bathymetry and habitat maps are accepted by different end users (including the International Maritime Organisation) and are routinely used in ecological studies, monitoring and management of coastal environments.},
author = {Kutser, Tiit and Hedley, John and Giardino, Claudia and Roelfsema, Chris and Brando, Vittorio E.},
doi = {10.1016/j.rse.2019.111619},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2020/Kutser et al._2020_Remote sensing of shallow waters – A 50 year retrospective and future directions.pdf:pdf},
issn = {00344257},
journal = {Remote Sensing of Environment},
month = {apr},
pages = {111619},
publisher = {Elsevier Inc.},
title = {{Remote sensing of shallow waters – A 50 year retrospective and future directions}},
volume = {240},
year = {2020}
}
@phdthesis{Grue2021,
author = {Grue, Silje B S},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2021/Grue_2021_Evaluation of Chlorophyll-a Retrieval Algorithms from Satellite Data at High Latitude Norwegian Waters.pdf:pdf},
pages = {1--32},
school = {UiT The Arctic University of Norway},
title = {{Evaluation of Chlorophyll-a Retrieval Algorithms from Satellite Data at High Latitude Norwegian Waters}},
year = {2021}
}
@article{Zhang2015,
abstract = {An Airborne Imaging Spectrometer for Applications (AISA) hyperspectral imager was deployed on a manned aircraft flown at 1305-m altitude to collect data over optically shallow waters in the Florida Keys with the ultimate goal of mapping water quality and benthic habitats. As a first step, we developed a practical atmospheric correction (AC) approach to derive surface remote-sensing reflectance ((Rrs) from AISA measurements using radiative transfer simulations and constraints obtained from field spectral Rrs measurements. Unlike previously published method, the AC approach removes the surface Fresnel reflection and accounts for aircraft altitude and nonzero near-infrared (NIR) reflectance through iteration over the pre-established look-up tables (LUTs) based on MODTRAN calculations. Simulations and comparison with concurrent in situRrs measurements show the feasibility of the approach in deriving surface Rrs with acceptable uncertainties. The possibility of errors in the radiometric calibration of AISA is demonstrated, although a definitive assessment cannot be made due to lack of enough concurrent in situ measurements. The need for noise reduction and the difficulty in carrying out a vicarious calibration are also discussed to help advance the design of future AISA missions.},
author = {Zhang, Minwei and Hu, Chuanmin and English, David and Carlson, Paul and Muller-Karger, Frank E. and Toro-Farmer, Gerardo and Herwitz, Stanley R.},
doi = {10.1109/JSTARS.2015.2437326},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2015/Zhang et al._2015_Atmospheric Correction of AISA Measurements over the Florida Keys Optically Shallow Waters Challenges in Radiometric C.pdf:pdf},
issn = {21511535},
journal = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
keywords = {Airborne Imaging Spectrometer for Applications (AI,MODTRAN,airborne remote sensing,atmospheric correction (AC),noise reduction,ocean color,vicarious calibration},
month = {aug},
number = {8},
pages = {4189--4196},
title = {{Atmospheric Correction of AISA Measurements over the Florida Keys Optically Shallow Waters: Challenges in Radiometric Calibration and Aerosol Selection}},
url = {http://ieeexplore.ieee.org/document/7120080/},
volume = {8},
year = {2015}
}
@article{Li2017,
abstract = {Recent research has shown that using spectral-spatial information can considerably improve the performance of hyperspectral image (HSI) classification. HSI data is typically presented in the format of 3D cubes. Thus, 3D spatial filtering naturally offers a simple and effective method for simultaneously extracting the spectral-spatial features within such images. In this paper, a 3D convolutional neural network (3D-CNN) framework is proposed for accurate HSI classification. The proposed method views the HSI cube data altogether without relying on any preprocessing or post-processing, extracting the deep spectral-spatial-combined features effectively. In addition, it requires fewer parameters than other deep learning-based methods. Thus, the model is lighter, less likely to over-fit, and easier to train. For comparison and validation, we test the proposed method along with three other deep learning-based HSI classification methods-namely, stacked autoencoder (SAE), deep brief network (DBN), and 2D-CNN-based methods-on three real-world HSI datasets captured by different sensors. Experimental results demonstrate that our 3D-CNN-based method outperforms these state-of-the-art methods and sets a new record.},
author = {Li, Ying and Zhang, Haokui and Shen, Qiang},
doi = {10.3390/rs9010067},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2017/Li, Zhang, Shen_2017_Spectral–Spatial Classification of Hyperspectral Imagery with 3D Convolutional Neural Network.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {2D convolutional neural networks,3D convolutional neural networks,3D structure,Deep learning,Hyperspectral image classification},
month = {jan},
number = {1},
pages = {67},
publisher = {Multidisciplinary Digital Publishing Institute},
title = {{Spectral-spatial classification of hyperspectral imagery with 3D convolutional neural network}},
url = {https://www.mdpi.com/2072-4292/9/1/67/htm https://www.mdpi.com/2072-4292/9/1/67},
volume = {9},
year = {2017}
}
@article{Trier2018,
abstract = {This article compares four new automatic methods to discriminate between spruce, pine and birch, which are the dominating tree species in Norwegian forests. Airborne laser scanning and hyperspectral data were used. The laser scanning data was used to mask pixels with low or no vegetation in the hyperspectral data. A green–blue ratio was used to remove shadow areas from tree canopies, and the normalized difference vegetation index to remove dead vegetation and non-vegetation. The best method was hyperspectral pixel classification with 160 spectral channels in the visible and near-infrared spectrum, using a deep neural network. This method achieved 87% correct classification rate. Partial least squares regression for hyperspectral pixel classification achieved 78%. Deep neural network image classification using canopy height blended with three hyperspectral channels achieved 74%. A simple pixel classification method based on two spectral indices resulted in 67% correct classification. A possible future improvement is to find a better way to combine hyperspectral data with canopy height data in a deep neural network.},
author = {Trier, {\O}ivind Due and Salberg, Arnt B{\o}rre and Kermit, Martin and Rudjord, {\O}ystein and Gobakken, Terje and N{\ae}sset, Erik and Aarsten, Dagrun},
doi = {10.1080/22797254.2018.1434424},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2018/Trier et al._2018_Tree species classification in Norway from airborne hyperspectral and airborne laser scanning data.pdf:pdf},
issn = {22797254},
journal = {European Journal of Remote Sensing},
keywords = {Lidar,automatic processing,canopy height model,deep learning,forestry,imaging spectroscopy},
month = {jan},
number = {1},
pages = {336--351},
publisher = {Taylor & Francis},
title = {{Tree species classification in Norway from airborne hyperspectral and airborne laser scanning data}},
url = {https://www.tandfonline.com/doi/abs/10.1080/22797254.2018.1434424},
volume = {51},
year = {2018}
}
@article{Huber2021,
abstract = {According to the EU Habitats directive, the Water Framework Directive, and the Marine Strategy Framework Directive, member states are required to map, monitor, and evaluate changes in quality and areal distribution of different marine habitats and biotopes to protect the marine environment more effectively. Submerged aquatic vegetation (SAV) is a key indicator of the ecological status of coastal ecosystems and is therefore widely used in reporting related to these directives. Environmental monitoring of the areal distribution of SAV is lacking in Sweden due to the challenges of large-scale monitoring using traditional small-scale methods. To address this gap, in 2020, we embarked on a project to combine Copernicus Sentinel-2 satellite imagery, novel machine learning (ML) techniques, and advanced data processing in a cloud-based web application that enables users to create up-to-date SAV classifications. At the same time, the approach was used to derive the first high-resolution SAV map for the entire coastline of Sweden, where an area of 1550 km2 was mapped as SAV. Quantitative evaluation of the accuracy of the classification using independent field data from three different regions along the Swedish coast demonstrated relative high accuracy within shallower areas, particularly where water transparency was high (average total accuracy per region 0.60–0.77). However, the classification missed large proportions of vegetation growing in deeper water (on average 31%–50%) and performed poorly in areas with fragmented or mixed vegetation and poor water quality, challenges that should be addressed in the development of the mapping methods towards integration into monitoring frameworks such as the EU directives. In this article, we present the results of the first satellite-derived SAV classification for the entire Swedish coast and show the implementation of a cloud-based SAV mapping application (prototype) developed within the frame of the project. Integr Environ Assess Manag 2022;18:909–920. {\textcopyright} 2021 The Authors. Integrated Environmental Assessment and Management published by Wiley Periodicals LLC on behalf of Society of Environmental Toxicology & Chemistry (SETAC).},
author = {Huber, Silvia and Hansen, Lars B. and Nielsen, Lisbeth T. and Rasmussen, Mikkel L. and S{\o}lvsteen, Jonas and Berglund, Johnny and {Paz von Friesen}, Carlos and Danbolt, Magnus and Envall, Mats and Infantes, Eduardo and Moksnes, Per},
doi = {10.1002/ieam.4493},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2021/Huber et al._2021_Novel approach to large-scale monitoring of submerged aquatic vegetation A nationwide example from Sweden.pdf:pdf},
issn = {15513793},
journal = {Integrated Environmental Assessment and Management},
keywords = {Ecological status,Environmental monitoring,Machine learning,Sentinel-2},
month = {aug},
number = {4},
pages = {909--920},
pmid = {34270169},
publisher = {John Wiley & Sons, Ltd},
title = {{Novel approach to large-scale monitoring of submerged aquatic vegetation: A nationwide example from Sweden}},
url = {https://setac.onlinelibrary.wiley.com/doi/full/10.1002/ieam.4493 https://setac.onlinelibrary.wiley.com/doi/abs/10.1002/ieam.4493 https://setac.onlinelibrary.wiley.com/doi/10.1002/ieam.4493},
volume = {18},
year = {2022}
}
@article{Masarczyk2020,
abstract = {Hyperspectral imaging is a rich source of data, allowing for a multitude of effective applications. However, such imaging remains challenging because of large data dimension and, typically, a small pool of available training examples. While deep learning approaches have been shown to be successful in providing effective classification solutions, especially for high dimensional problems, unfortunately they work best with a lot of labelled examples available. The transfer learning approach can be used to alleviate the second requirement for a particular dataset: first the network is pre-trained on some dataset with large amount of training labels available, then the actual dataset is used to fine-tune the network. This strategy is not straightforward to apply with hyperspectral images, as it is often the case that only one particular image of some type or characteristic is available. In this paper, we propose and investigate a simple and effective strategy of transfer learning that uses unsupervised pre-training step without label information. This approach can be applied to many of the hyperspectral classification problems. The performed experiments show that it is very effective at improving the classification accuracy without being restricted to a particular image type or neural network architecture. The experiments were carried out on several deep neural network architectures and various sizes of labeled training sets. The greatest improvement in overall accuracy on the Indian Pines and Pavia University datasets is over 21 and 13 percentage points, respectively. An additional advantage of the proposed approach is the unsupervised nature of the pre-training step, which can be done immediately after image acquisition, without the need of the potentially costly expert's time.},
archivePrefix = {arXiv},
arxivId = {1909.05507},
author = {Masarczyk, Wojciech and Glomb, Przemyslaw and Grabowski, Bartosz and Ostaszewski, Mateusz},
doi = {10.3390/RS12162653},
eprint = {1909.05507},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2020/Masarczyk et al._2020_Effective training of deep convolutional neural networks for hyperspectral image classification through artificial.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Convolutional neural networks,Deep learning,Hyperspectral image classification,Transfer learning,Unsupervised training sample selection},
month = {aug},
number = {16},
pages = {2653},
publisher = {Multidisciplinary Digital Publishing Institute},
title = {{Effective training of deep convolutional neural networks for hyperspectral image classification through artificial labeling}},
url = {https://www.mdpi.com/2072-4292/12/16/2653/htm https://www.mdpi.com/2072-4292/12/16/2653},
volume = {12},
year = {2020}
}
@techreport{Haarpaintner2021,
author = {Haarpaintner, J{\"{o}}rg and Davids, Corine and Hindberg, Heidi and Arntzen, Ingar and Borch, Nj{\aa}l},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2021/Haarpaintner et al._2021_Satellite-Based National Intertidal-Zone Mapping of Continental Norway with Sentinel-1&2.pdf:pdf},
institution = {NORCE},
isbn = {9788284081472},
number = {April},
title = {{Satellite-Based National Intertidal-Zone Mapping of Continental Norway with Sentinel-1&2}},
url = {https://www.miljodirektoratet.no/publikasjoner/2021/mai-2021/satellite-based-national-intertidal-zone-mapping-of-continental-norway-with-sentinel-12/},
year = {2021}
}
@article{Hochberg2003,
abstract = {Coral reef benthic communities are mosaics of individual bottom-types that are distinguished by their taxonomic composition and functional roles in the ecosystem. Knowledge of community structure is essential to understanding many reef processes. To develop techniques for identification and mapping of reef bottom-types using remote sensing, we measured 13,100 in situ optical reflectance spectra (400-700 nm, 1-nm intervals) of 12 basic reef bottom-types in the Atlantic, Pacific, and Indian Oceans: fleshy (1) brown, (2) green, and (3) red algae; non-fleshy (4) encrusting calcareous and (5) turf algae; (6) bleached, (7) blue, and (8) brown hermatypic coral; (9) soft/gorgonian coral; (10) seagrass; (11) terrigenous mud; and (12) carbonate sand. Each bottom-type exhibits characteristic spectral reflectance features that are conservative across biogeographic regions. Most notable are the brightness of carbonate sand and local extrema near 570 nm in blue (minimum) and brown (maximum) corals. Classification function analyses for the 12 bottom-types achieve mean accuracies of 83%, 76%, and 71% for full-spectrum data (301-wavelength), 52-wavelength, and 14-wavelength subsets, respectively. The distinguishing spectral features for the 12 bottom-types exist in well-defined, narrow (10-20 nm) wavelength ranges and are ubiquitous throughout the world. We reason that spectral reflectance features arise primarily as a result of spectral absorption processes. Radiative transfer modeling shows that in typically clear coral reef waters, dark substrates such as corals have a depth-of-detection limit on the order of 10-20 m. Our results provide the foundation for design of a sensor with the purpose of assessing the global status of coral reefs.},
author = {Hochberg, Eric J. and Atkinson, Marlin J. and Andr{\'{e}}fou{\"{e}}t, Serge},
doi = {10.1016/S0034-4257(02)00201-8},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2003/Hochberg, Atkinson, Andr{\'{e}}fou{\"{e}}t_2003_Spectral reflectance of coral reef bottom-types worldwide and implications for coral reef remote sen.pdf:pdf},
issn = {00344257},
journal = {Remote Sensing of Environment},
keywords = {Coral reef,Radiative transfer,Remote sensing,Spectral reflectance},
number = {2},
pages = {159--173},
title = {{Spectral reflectance of coral reef bottom-types worldwide and implications for coral reef remote sensing}},
volume = {85},
year = {2003}
}
@inproceedings{Liu2022a,
abstract = {With recent abundant availability of high resolution multi-sensor UAV data and rapid development of deep learning models, efficient automatic mapping using deep neural network is becoming a common approach. However, with the ever-expanding inventories of both data and deep neural network models, it can be confusing to know how to choose. Most models expect input as conventional RGB format, but that can be extended to incorporate multi-sensor data. In this study, we re-implement and modify three deep neural network models of various complexities, namely UNET, DeepLabv3+ and Dense Dilated Convolutions Merging Network to use both RGB and near infrared (NIR) data from a multi-sensor UAV dataset over a Norwegian coastal area. The dataset has been carefully annotated by marine experts for coastal habitats. We find that the NIR channel increases UNET performance significantly but has mixed effects on DeepLabv3+ and DDCM. The latter two are capable of achieving best performance with RGB-only. The class-wise evaluation shows that the NIR channel greatly increases the performance in UNET for green, red algae, vegetation and rock. However, the purpose of the study is not to merely compare the models or to achieve the best performance, but to gain more insights on the compatibility between various models and data types. And as there is an ongoing effort in acquiring and annotating more data, we aim to include them in the coming year.},
author = {Liu, Y. and Liu, Q. and Sample, J. E. and Hancke, K. and Salberg, A. B.},
booktitle = {ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
doi = {10.5194/isprs-Annals-V-3-2022-439-2022},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2022/Liu et al._2022_COASTAL HABITAT MAPPING WITH UAV MULTI-SENSOR DATA AN EXPERIMENT AMONG DCNN-BASED APPROACHES(2).pdf:pdf},
issn = {21949050},
keywords = {UAV,data fusion,deep learning,environmental monitoring,multi-sensor data,semantic segmentation},
month = {may},
number = {3},
pages = {439--445},
title = {{Coastal habitat mapping with uav multi-sensor data: An experiment among dcnn-based approaches}},
url = {https://www.isprs-ann-photogramm-remote-sens-spatial-inf-sci.net/V-3-2022/439/2022/},
volume = {5},
year = {2022}
}
@article{Valle2015,
abstract = {Estuaries and coasts are among the most productive ecosystems and constitute valuable habitats for biodiversity and ecosystem services. Amongst nearshore ecosystems, seagrass beds play a major role enhancing biodiversity and water quality. Consequently, the development of new approaches to create extensive and high-resolution habitat maps is required not only to implement conservation, restoration and management plans, but also to establish adaptation plans to face climate change impacts. This study particularly assesses the capability of hyperspectral airborne imagery acquired with Compact Airborne Spectrographic Imager (CASI) to discriminate and map estuarine habitats, with special focus on Zostera noltii seagrass meadows. To this end, 13 habitats were defined along the supralittoral, intertidal and subtidal zones of an estuary, including Z.noltii seagrass meadows. The CASI sensor was configured to acquire 25 bands in the visible and near infrared wavelengths with a ground sampling distance of 2 m. Spectral bands were selected for species discrimination based on the spectral signature of the different habitat classes. Six different band combinations were tested applying maximum likelihood classification algorithm. The most accurate classification was obtained with 10 band combination (a mean producer accuracy 92% and a mean user accuracy 94%). The classification of Z.noltii beds has been found to be restricted to moderate and high dense meadows, however a vegetation index has been defined which could be applied for mapping Z. noltii meadow cover. These results highlight the value of CASI data to discriminate and map estuarine habitats, providing key information to be used in supporting the implementation of environmental legislation, protection and conservation of coastal habitats.},
author = {Valle, Mireia and Pal{\`{a}}, Vicen{\c{c}} and Lafon, Virgine and Dehouck, Aur{\'{e}}lie and Garmendia, Joxe Mikel and Borja, {\'{A}}ngel and Chust, Guillem},
doi = {10.1016/j.ecss.2015.07.034},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2015/Valle et al._2015_Mapping estuarine habitats using airborne hyperspectral imagery, with special focus on seagrass meadows.pdf:pdf},
issn = {02727714},
journal = {Estuarine, Coastal and Shelf Science},
keywords = {Compact airborne spectrographic imager,Estuaries,Habitat classification,Remote sensing,Zostera noltii},
month = {oct},
pages = {433--442},
publisher = {Academic Press},
title = {{Mapping estuarine habitats using airborne hyperspectral imagery, with special focus on seagrass meadows}},
volume = {164},
year = {2015}
}
@article{Zhang2016,
abstract = {An atmospheric correction algorithm has been developed for the Airborne Imaging Spectrometer for Applications (AISA) imagery over optically shallow waters in Sugarloaf Key of the Florida Keys. The AISA data were collected repeatedly during several days in May 2012, October 2012, and May 2013. Non-zero near-infrared (NIR) remote-sensing reflectance (Rrs) was accounted for through iterations, based on the relationship of field-measured Rrs between the NIR and red wavelengths. Validation showed mean ratios of 0.94–1.002 between AISA-retrieved and in situ Rrs in the blue to red wavelengths, with uncertainties generally <0.003 sr–1. Such an approach led to observations of short-term changes in AISA-retrieved Rrs from repeated measurements over waters with bottom types of seagrass meadow, sand, and patch reef. Some of these changes are larger than twofold the Rrs uncertainties from AISA retrievals, therefore representing statistically significant changes that can be well observed from airborne measurements. Through radiative transfer modelling, we demonstrated that short-term Rrs changes within 1 hour resulted primarily from sediment resuspension, while tides played a relatively minor role due to the small variation in tidal heights. A sensitivity analysis indicated that although Rrs generally increases with decreasing tide height but increasing suspended sediments, more changes were observed over sandy bottom than over seagrass. The case study suggests that repeated airborne measurements may be used to study short-term changes in shallow-water environments, and such a capacity may be enhanced with future geostationary satellite missions specifically designed to observe coastal ecosystems.},
author = {Zhang, Minwei and English, David and Hu, Chuanmin and Carlson, Paul and Muller-Karger, Frank E. and Toro-Farmer, Gerardo and Herwitz, Stanley R.},
doi = {10.1080/01431161.2016.1159746},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2016/Zhang et al._2016_Short-term changes of remote sensing reflectancein a shallow-water environment observations from repeated airborne hyp.pdf:pdf},
issn = {13665901},
journal = {International Journal of Remote Sensing},
month = {apr},
number = {7},
pages = {1620--1638},
publisher = {Taylor & Francis},
title = {{Short-term changes of remote sensing reflectancein a shallow-water environment: observations from repeated airborne hyperspectral measurements}},
url = {http://www.tandfonline.com/doi/full/10.1080/01431161.2016.1159746},
volume = {37},
year = {2016}
}
@inproceedings{Penatti2015,
abstract = {In this paper, we evaluate the generalization power of deep features (ConvNets) in two new scenarios: aerial and remote sensing image classification. We evaluate experimentally ConvNets trained for recognizing everyday objects for the classification of aerial and remote sensing images. ConvNets obtained the best results for aerial images, while for remote sensing, they performed well but were outperformed by low-level color descriptors, such as BIC. We also present a correlation analysis, showing the potential for combining/fusing different ConvNets with other descriptors or even for combining multiple ConvNets. A preliminary set of experiments fusing ConvNets obtains state-of-the-art results for the well-known UCMerced dataset.},
author = {Penatti, Otavio A.B. and Nogueira, Keiller and {Dos Santos}, Jefersson A.},
booktitle = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
doi = {10.1109/CVPRW.2015.7301382},
isbn = {9781467367592},
issn = {21607516},
keywords = {Accuracy,Correlation,Feature extraction,Histograms,Image color analysis,Remote sensing,Visualization},
pages = {44--51},
title = {{Do deep features generalize from everyday objects to remote sensing and aerial scenes domains?}},
url = {https://www.cv-foundation.org/openaccess/content_cvpr_workshops_2015/W13/html/Penatti_Do_Deep_Features_2015_CVPR_paper.html},
volume = {2015-Octob},
year = {2015}
}
@article{Brodie2018,
abstract = {Habitat-forming seaweeds are vital components of marine ecosystems, supporting immense diversity and providing ecosystem services. Reports of major changes in the distribution and abundance of large brown seaweeds in the north-east Atlantic are an increasing cause for concern, but a lack of consistent monitoring over time is a key impediment in obtaining reliable evidence of change. There is an urgent need to recognize change rapidly and efficiently in marine communities, which are increasingly affected by pressures of human population growth, climate change, and ocean acidification. Here, the potential for remote monitoring of seaweed habitats is investigated using freely available, high-resolution aerial and satellite imagery. Three sources of imagery were used: (i) Channel Coastal Observatory (CCO) aerial imagery; (ii) aerial images from the Bing webmap server; and (iii) RapidEye multispectral satellite data. The study area, the Thanet Coast, is an area of chalk outcrop in south-east England of high conservation status, and includes three Marine Conservation Zones. Eight habitat classes, including brown, red, and green algal zones, were recognized based on ground-truthing surveys. A multi-class classification model was developed to predict habitat classes based on the chromatic signature derived from the aerial images. The model based on the high-resolution CCO imagery gave the best outcome (with a kappa value of 0.89). Comparing predictions for images in 2001 and 2013 revealed habitat changes, but it is unclear as to what extent these are natural variability or real trends. This study demonstrates the potential value for long-term monitoring with remote-sensing data. Repeated, standardized coastal aerial imaging surveys, such as those performed by CCO, permit the rapid assessment and re-assessment of habitat extent and change. This is of value to the conservation management of protected areas, particularly those defined by the presence or extent of specific habitats.},
author = {Brodie, Juliet and Ash, Lauren V. and Tittley, Ian and Yesson, Chris},
doi = {10.1002/aqc.2905},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2018/Brodie et al._2018_A comparison of multispectral aerial and satellite imagery for mapping intertidal seaweed communities.pdf:pdf},
issn = {10990755},
journal = {Aquatic Conservation: Marine and Freshwater Ecosystems},
keywords = {Fucus,Marine Conservation Zones,aerial imagery,coastal habitats,macroalgae,remote sensing,satellite imagery},
month = {aug},
number = {4},
pages = {872--881},
publisher = {John Wiley & Sons, Ltd},
title = {{A comparison of multispectral aerial and satellite imagery for mapping intertidal seaweed communities}},
url = {https://onlinelibrary.wiley.com/doi/full/10.1002/aqc.2905 https://onlinelibrary.wiley.com/doi/abs/10.1002/aqc.2905 https://onlinelibrary.wiley.com/doi/10.1002/aqc.2905},
volume = {28},
year = {2018}
}
@article{Garcia2018,
abstract = {Hyperspectral remote sensing inversion models utilize spectral information over optically shallow waters to retrieve optical properties of the water column, bottom depth and reflectance, with the latter used in benthic classification. Accuracy of these retrievals is dependent on the spectral endmember(s) used to model the bottom reflectance during the inversion. Without prior knowledge of these endmember(s) current approaches must iterate through a list of endmember-a computationally demanding task. To address this, a novel lookup table classification approach termed HOPE-LUT was developed for selecting the likely benthic endmembers of any hyperspectral image pixel. HOPE-LUT classifies a pixel as sand, mixture or non-sand, then the latter two are resolved into the three most likely classes. Optimization subsequently selects the class (out of the three) that generated the best fit to the remote sensing reflectance. For a coral reef case, modeling results indicate very high benthic classification accuracy (> 90%) for depths less than 4 m of common coral reef benthos. These accuracies decrease substantially with increasing depth due to the loss of bottom information, especially the spectral signatures. We applied this technique to hyperspectral airborne imagery of Heron Reef, Great Barrier Reef and generated benthic habitat maps with higher classification accuracy compared to standard inversion models.},
author = {Garcia, Rodrigo A. and Lee, Zhongping and Hochberg, Eric J.},
doi = {10.3390/rs10010147},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2018/Garcia, Lee, Hochberg_2018_Hyperspectral shallow-water remote sensing with an enhanced benthic classifier.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Benthic classification,Coral reef,Heron reef,Hyperspectral,Remote sensing},
number = {1},
title = {{Hyperspectral shallow-water remote sensing with an enhanced benthic classifier}},
volume = {10},
year = {2018}
}
@article{Lee1999,
abstract = {In earlier studies of passive remote sensing of shallow-water bathymetry, bottom depths were usually derived by empirical regression. This approach provides rapid data processing, but it requires knowledge of a few true depths for the regression parameters to be determined, and it cannot reveal in-water constituents. In this study a newly developed hyperspectral, remote-sensing reflectance model for shallow water is applied to data from computer simulations and field measurements. In the process, a remote-sensing reflectance spectrum is modeled by a set of values of absorption, backscattering, bottom albedo, and bottom depth; then it is compared with the spectrum from measurements. The difference between the two spectral curves is minimized by adjusting the model values in a predictor-corrector scheme. No information in addition to the measured reflectance is required. When the difference reaches a minimum, or the set of variables is optimized, absorption coefficients and bottom depths along with other properties are derived simultaneously. For computer-simulated data at a wind speed of 5 m/s the retrieval error was 5.3% for depths ranging from 2.0 to 20.0 m and 7.0% for total absorption coefficients at 440 nm ranging from 0.04 to 0.24 m(-1). At a wind speed of 10 m/s the errors were 5.1% for depth and 6.3% for total absorption at 440 nm. For field data with depths ranging from 0.8 to 25.0 m the difference was 10.9% (R2 = 0.96, N = 37) between inversion-derived and field-measured depth values and just 8.1% (N = 33) for depths greater than 2.0 m. These results suggest that the model and the method used in this study, which do not require in situ calibration measurements, perform very well in retrieving in-water optical properties and bottom depths from above-surface hyperspectral measurements.},
author = {Lee, Zhongping and Carder, Kendall L. and Mobley, Curtis D. and Steward, Robert G. and Patch, Jennifer S.},
doi = {10.1364/ao.38.003831},
file = {:C\:/Users/mha114/Dropbox/Litteratur/1999/Lee et al._1999_Hyperspectral remote sensing for shallow waters 2 Deriving bottom depths and water properties by optimization.pdf:pdf},
issn = {0003-6935},
journal = {Applied Optics},
number = {18},
pages = {3831},
pmid = {18319990},
title = {{Hyperspectral remote sensing for shallow waters: 2 Deriving bottom depths and water properties by optimization}},
volume = {38},
year = {1999}
}
@article{Bunting2006a,
abstract = {In mixed-species forests of complex structure, the delineation of tree crowns is problematic because of their varying dimensions and reflectance characteristics, the existence of several layers of canopy (including understorey), and shadowing within and between crowns. To overcome this problem, an algorithm for delineating tree crowns has been developed using eCognition Expert and hyperspectral Compact Airborne Spectrographic Imager (CASI-2) data acquired over a forested landscape near Injune, central east Queensland, Australia. The algorithm has six components: 1) the differentiation of forest, non-forest and understorey; 2) initial segmentation of the forest area and allocation of segments (objects) to larger objects associated with forest spectral types (FSTs); 3) initial identification of object maxima as seeds within these larger objects and their expansion to the edges of crowns or clusters of crowns; 4) subsequent classification-based separation of the resulting objects into crown or cluster classes; 5) further iterative splitting of the cluster classes to delineate more crowns; and 6) identification and subsequent merging of oversplit objects into crowns or clusters. In forests with a high density of individuals (e.g., regrowth), objects associated with tree clusters rather than crowns are delineated and local maxima counted to approximate density. With reference to field data, the delineation process provided accuracies > ∼70% (range 48-88%) for individuals or clusters of trees of the same species with diameter at breast height (DBH) exceeding 10 cm (senescent and dead trees excluded), with lower accuracies associated with dense stands containing several canopy layers, as many trees were obscured from the view of the CASI sensor. Although developed using 1-m spatial resolution CASI data acquired over Australian forests, the algorithm has application elsewhere and is currently being considered for integration into the Definiens product portfolio for use by the wider community. {\textcopyright} 2006 Elsevier Inc. All rights reserved.},
author = {Bunting, Peter and Lucas, Richard},
doi = {10.1016/j.rse.2005.12.015},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2006/Bunting, Lucas_2006_The delineation of tree crowns in Australian mixed species forests using hyperspectral Compact Airborne Spectrograph.pdf:pdf},
issn = {00344257},
journal = {Remote Sensing of Environment},
keywords = {Australia,CASI,Classification,Crown delineation,Forests,Hyperspectral,Image segmentation,Queensland,eCognition},
number = {2},
pages = {230--248},
title = {{The delineation of tree crowns in Australian mixed species forests using hyperspectral Compact Airborne Spectrographic Imager (CASI) data}},
volume = {101},
year = {2006}
}
@article{Rashid2020,
abstract = {This paper describes a large dataset of underwater hyperspectral imagery that can be used by researchers in the domains of computer vision, machine learning, remote sensing, and coral reef ecology. We present the details of underwater data acquisition, processing and curation to create this large dataset of coral reef imagery annotated for habitat mapping. A diver-operated hyperspectral imaging system (HyperDiver) was used to survey 147 transects at 8 coral reef sites around the Caribbean island of Cura{\c{c}}ao. The underwater proximal sensing approach produced fine-scale images of the seafloor, with more than 2.2 billion points of detailed optical spectra. Of these, more than 10 million data points have been annotated for habitat descriptors or taxonomic identity with a total of 47 class labels up to genus-and species-levels. In addition to HyperDiver survey data, we also include images and annotations from traditional (color photo) quadrat surveys conducted along 23 of the 147 transects, which enables comparative reef description between two types of reef survey methods. This dataset promises benefits for efforts in classification algorithms, hyperspectral image segmentation and automated habitat mapping.},
author = {Rashid, Ahmad Rafiuddin and Chennu, Arjun},
doi = {10.3390/data5010019},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2020/Rashid, Chennu_2020_A trillion coral reef colors Deeply annotated underwater hyperspectral images for automated classification and habit.pdf:pdf},
issn = {23065729},
journal = {Data},
keywords = {Biodiversity,Classification,Coral reef,Habitat mapping,Hierarchical learning,Hyperspectral imaging,Image segmentation,Machine learning,Proximal sensing},
month = {feb},
number = {1},
pages = {19},
publisher = {MDPI AG},
title = {{A trillion coral reef colors: Deeply annotated underwater hyperspectral images for automated classification and habitat mapping}},
url = {https://www.mdpi.com/2306-5729/5/1/19},
volume = {5},
year = {2020}
}
@article{Conger2006,
abstract = {We have developed a simple technique to decorrelate remote sensing color band data from depth in optically shallow water. The method linearizes color band data with respect to depth by subtracting an optically deepwater value from the entire waveband under consideration and taking the natural logarithm of the result. Next, this linearized waveband is rotated about the model 2 regression line computed against a bathymetry band. The rotated color band is decorrelated from water depth. We demonstrate the technique for a small area of Kailua Bay, Oahu, HI, using Quick-bird multispectral and Scanning Hydrographic Operational Airborne Lidar Survey LIDAR data. Results indicate that color band data are effectively decorrelated from depth, while bottom reflector variability is maintained, thus providing the basis for further analysis of the depth-invariant wavebands. The primary benefit of our technique is that wavebands are rotated independently, preserving relative spectral information. {\textcopyright} 2006 IEEE.},
author = {Conger, Christopher L. and Hochberg, Eric J. and Fletcher, Charles H. and Atkinson, Marlin J.},
doi = {10.1109/TGRS.2006.870405},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2006/Conger et al._2006_Decorrelating remote sensing color bands from bathymetry in optically shallow waters.pdf:pdf},
issn = {01962892},
journal = {IEEE Transactions on Geoscience and Remote Sensing},
keywords = {Bathymetry,Coastal remote sensing,Kailua Bay,LIDAR,Quickbird,Radiative transfer,Reflectance},
number = {6},
pages = {1655--1660},
title = {{Decorrelating remote sensing color bands from bathymetry in optically shallow waters}},
volume = {44},
year = {2006}
}
@article{Hedley2005,
abstract = {Specular reflection of solar radiation on non-flat water surfaces is a serious confounding factor for benthic remote sensing in shallow-water environments. This problem was recently overcome by Hochberg et al., who provided an effective method for the removal of 'sun glint' from remotely sensed images by utilization of the brightness in a near-infrared (NIR) band. Application of the technique was shown to give an increase in the accuracy of benthic habitat classification. However, as presented, the method is sensitive to outlier pixels, requires a time-consuming masking of land and cloud, and is not formulated in a manner leading to ease of implementation. We present a revised version of the method, which is more robust, does not require masking and can be implemented very simply. The practical approach described here will hopefully expedite the routine adoption of this effective and simple technique throughout the aquatic remote sensing community. {\textcopyright} 2005 Taylor & Francis Group Ltd.},
author = {Hedley, J. D. and Harborne, A. R. and Mumby, P. J.},
doi = {10.1080/01431160500034086},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2005/Hedley, Harborne, Mumby_2005_Technical note Simple and robust removal of sun glint for mapping shallow‐water benthos.pdf:pdf},
issn = {13665901},
journal = {International Journal of Remote Sensing},
month = {may},
number = {10},
pages = {2107--2112},
publisher = {Taylor and Francis Ltd.},
title = {{Simple and robust removal of sun glint for mapping shallow-water benthos}},
url = {https://www.tandfonline.com/doi/full/10.1080/01431160500034086},
volume = {26},
year = {2005}
}
@article{McKenzie2022,
abstract = {Seagrass meadows are a key ecosystem of the Great Barrier Reef World Heritage Area, providing one of the natural heritage attributes underpinning the reef's outstanding universal value. We reviewed approaches employed to date to create maps of seagrass meadows in the optically complex waters of the Great Barrier Reef and explored enhanced mapping approaches with a focus on emerging technologies, and key considerations for future mapping. Our review showed that field-based mapping of seagrass has traditionally been the most common approach in the GBR-WHA, with few attempts to adopt remote sensing approaches and emerging technologies. Using a series of case studies to harness the power of machine-and deep-learning, we mapped seagrass cover with PlanetScope and UAV-captured imagery in a variety of settings. Using a machine-learn-ing pixel-based classification coupled with a bootstrapping process, we were able to significantly improve maps of seagrass, particularly in low cover, fragmented and complex habitats. We also used deep-learning models to derive enhanced maps from UAV imagery. Combined, these lessons and emerging technologies show that more accurate and efficient seagrass mapping approaches are possible, producing maps of higher confidence for users and enabling the upscaling of seagrass mapping into the future.},
author = {McKenzie, Len J. and Langlois, Lucas A. and Roelfsema, Chris M.},
doi = {10.3390/rs14112604},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2022/McKenzie, Langlois, Roelfsema_2022_Improving Approaches to Mapping Seagrass within the Great Barrier Reef From Field to Spaceborne Earth.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Great Barrier Reef,UAV,deep-learning,earth observing,machine-learning,map confidence,mapping,seagrass,spaceborne},
month = {may},
number = {11},
pages = {2604},
title = {{Improving Approaches to Mapping Seagrass within the Great Barrier Reef: From Field to Spaceborne Earth Observation}},
url = {https://www.mdpi.com/2072-4292/14/11/2604},
volume = {14},
year = {2022}
}
@article{Blakey2015,
abstract = {We tested a supervised classification approach with Landsat 5 Thematic Mapper (TM) data for time-series mapping of seagrass in a subtropical lagoon. Seagrass meadows are an integral link between marine and inland ecosystems and are at risk from upstream processes such as runoff and erosion. Despite the prevalence of image-specific approaches, the classification accuracies we achieved show that pixel-based spectral classes may be generalized and applied to a time series of images that were not included in the classifier training. We employed in-situ data on seagrass abundance from 2007 to 2011 to train and validate a classification model. We created depth-invariant bands from TM bands 1, 2, and 3 to correct for variations in water column depth prior to building the classification model. In-situ data showed mean total seagrass cover remained relatively stable over the study area and period, with seagrass cover generally denser in the west than the east. Our approach achieved mapping accuracies (67% and 76% for two validation years) comparable with those attained using spectral libraries, but was simpler to implement. We produced a series of annual maps illustrating inter-annual variability in seagrass occurrence. Accuracies may be improved in future work by better addressing the spatial mismatch between pixel size of remotely sensed data and footprint of field data and by employing atmospheric correction techniques that normalize reflectances across images.},
author = {Blakey, Tara and Melesse, Assefa and Hall, Margaret O.},
doi = {10.3390/rs70505098},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2015/Blakey, Melesse, Hall_2015_Supervised classification of benthic reflectance in shallow subtropical waters using a generalized pixel-base.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Benthic reflectance,Florida Bay,Landsat,Long-term monitoring,Seagrass landscapes,Supervised classification},
month = {apr},
number = {5},
pages = {5098--5116},
publisher = {MDPI AG},
title = {{Supervised classification of benthic reflectance in shallow subtropical waters using a generalized pixel-based classifier across a time series}},
url = {http://www.mdpi.com/2072-4292/7/5/5098},
volume = {7},
year = {2015}
}
@article{Inamdar2022,
abstract = {Our article describes a data processing workflow for hyperspectral imaging data to compensate for the water column in shallow, clear to moderate optical water types. We provide a MATLAB script that can be readily used to implement the described workflow. We break down each code segment of this script so that it is more approachable for use and modification by end users and data providers. The workflow initially implements the method for water column compensation described in Lyzenga (1978) and Lyzenga (1981), generating depth invariant indices from spectral band pairs. Given the high dimensionality of hyperspectral imaging data, an overwhelming number of depth invariant indices are generated in the workflow. As such, a correlation based feature selection methodology is applied to remove redundant depth invariant indices. In a post-processing step, a principal component transformation is applied, extracting features that account for a substantial amount of the variance from the non-redundant depth invariant indices while reducing dimensionality. To fully showcase the developed methodology and its potential for extracting bottom type information, we provide an example output of the water column compensation workflow using hyperspectral imaging data collected over the coast of Philpott's Island in Long Sault Parkway provincial park, Ontario, Canada. • Workflow calculates depth invariant indices for hyperspectral imaging data to compensate for the water column in shallow, clear to moderate optical water types. • The applied principal component transformation generates features that account for a substantial amount of the variance from the depth invariant indices while reducing dimensionality. • The output (both depth invariant index image and principal component image) allows for the analysis of bottom type in shallow, clear to moderate optical water types.},
author = {Inamdar, Deep and Rowan, Gillian S.L. and Kalacska, Margaret and Arroyo-Mora, J. Pablo},
doi = {10.1016/j.mex.2021.101601},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2022/Inamdar et al._2022_Water column compensation workflow for hyperspectral imaging data.pdf:pdf},
issn = {22150161},
journal = {MethodsX},
keywords = {Depth invariant index (DII),Hyperspectral Depth Invariant Index,Hyperspectral imaging,Principal component analysis (PCA),Water column compensation},
month = {jan},
pages = {101601},
publisher = {Elsevier},
title = {{Water column compensation workflow for hyperspectral imaging data}},
volume = {9},
year = {2022}
}
@article{Hedley2016,
abstract = {Seagrass meadows are important environments for the blue carbon budget and are potential early indicators for environmental change. Remote sensing is a viable monitoring tool for spatially extensive meadows but most current approaches are limited by the requirement for in situ calibration data or provide categorical level maps rather than quantitative estimates of direct physiological significance. In this paper we present a method for mapping water depth and the leaf area index (LAI, ratio of leaf area to substrate area) of Thalassia testudinum meadows, based on radiative transfer model inversion using an embedded three-dimensional aquatic canopy model. Variations in reflectance due to leaf length, leaf position, sediment coverage on leaves, water depth and solar zenith angle were included in the model to parameterise uncertainty propagation. The model revealed canopy reflectance as a function of LAI decreases exponentially at all wavelengths up to an LAI around four, beyond which increasing canopy density cannot be determined from reflectance. In addition, sediment coverage on leaves has surprisingly little effect on the reflectance of sparse canopies because shading is also a contributor to darkening. The capability of the method for image based mapping was assessed through sensitivity analyses and by application to hyperspectral airborne imagery of Florida Bay collected by the Portable Remote Imaging Spectrometer (PRISM), with the uncertainty propagation providing per-pixel confidence intervals on all the estimated parameters. Results were consistent across the sensitivity and image analyses and the agreement with field data was good, given the challenges in validation of submerged pixels at metre scale. Uncertainties were high for LAIs greater than two in water of depth 8 m, but lower for sparse canopies and shallower water. For water depths approaching 10 m the pixel-to-pixel variation arising from processes at the water surface upwards was greater than the uncertainties arising from the canopy or water column. The physics-based model inversion approach is readily adaptable to any sensor configuration and to different seagrass species and canopy morphologies. No site-specific in situ data is required and the uncertainty estimates can provide an objective basis for interpreting apparent changes in the distribution of seagrasses over time and space, as revealed by remote sensing techniques.},
author = {Hedley, John and Russell, Brandon and Randolph, Kaylan and Dierssen, Heidi},
doi = {10.1016/j.rse.2015.12.001},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2016/Hedley et al._2016_A physics-based method for the remote sensing of seagrasses.pdf:pdf},
issn = {00344257},
journal = {Remote Sensing of Environment},
keywords = {Inversion,LAI,Leaf area index,Radiative transfer model,Seagrass,Uncertainty},
month = {mar},
pages = {134--147},
publisher = {Elsevier},
title = {{A physics-based method for the remote sensing of seagrasses}},
url = {https://www.sciencedirect.com/science/article/pii/S0034425715302224},
volume = {174},
year = {2016}
}
@article{Ulmas2020,
abstract = {The focus of this paper is using a convolutional machine learning model with a modified U-Net structure for creating land cover classification mapping based on satellite imagery. The aim of the research is to train and test convolutional models for automatic land cover mapping and to assess their usability in increasing land cover mapping accuracy and change detection. To solve these tasks, authors prepared a dataset and trained machine learning models for land cover classification and semantic segmentation from satellite images. The results were analysed on three different land classification levels. BigEarthNet satellite image archive was selected for the research as one of two main datasets. This novel and recent dataset was published in 2019 and includes Sentinel-2 satellite photos from 10 European countries made in 2017 and 2018. As a second dataset the authors composed an original set containing a Sentinel-2 image and a CORINE land cover map of Estonia. The developed classification model shows a high overall F\textsubscript{1} score of 0.749 on multiclass land cover classification with 43 possible image labels. The model also highlights noisy data in the BigEarthNet dataset, where images seem to have incorrect labels. The segmentation models offer a solution for generating automatic land cover mappings based on Sentinel-2 satellite images and show a high IoU score for land cover classes such as forests, inland waters and arable land. The models show a capability of increasing the accuracy of existing land classification maps and in land cover change detection.},
archivePrefix = {arXiv},
arxivId = {2003.02899},
author = {Ulmas, Priit and Liiv, Innar},
eprint = {2003.02899},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2020/Ulmas, Liiv_2020_Segmentation of Satellite Imagery using U-Net Models for Land Cover Classification.pdf:pdf},
pages = {1--11},
title = {{Segmentation of Satellite Imagery using U-Net Models for Land Cover Classification}},
url = {http://arxiv.org/abs/2003.02899},
year = {2020}
}
@misc{Phiri2020,
abstract = {The advancement in satellite remote sensing technology has revolutionised the approaches to monitoring the Earth's surface. The development of the Copernicus Programme by the European Space Agency (ESA) and the European Union (EU) has contributed to the effective monitoring of the Earth's surface by producing the Sentinel-2 multispectral products. Sentinel-2 satellites are the second constellation of the ESA Sentinel missions and carry onboard multispectral scanners. The primary objective of the Sentinel-2mission is to provide high resolution satellite data for land cover/usemonitoring, climate change and disaster monitoring, as well as complementing the other satellite missions such as Landsat. Since the launch of Sentinel-2 multispectral instruments in 2015, there have been many studies on land cover/use classification which use Sentinel-2 images. However, no review studies have been dedicated to the application of ESA Sentinel-2 land cover/use monitoring. Therefore, this review focuses on two aspects: (1) assessing the contribution of ESA Sentinel-2 to land cover/use classification, and (2) exploring the performance of Sentinel-2 data in different applications (e.g., forest, urban area and natural hazard monitoring). The present review shows that Sentinel-2 has a positive impact on land cover/use monitoring, specifically in monitoring of crop, forests, urban areas, and water resources. The contemporary high adoption and application of Sentinel-2 can be attributed to the higher spatial resolution (10 m) than other medium spatial resolution images, the high temporal resolution of 5 days and the availability of the red-edge bands with multiple applications. The ability to integrate Sentinel-2 data with other remotely sensed data, as part of data analysis, improves the overall accuracy (OA) when working with Sentinel-2 images. The free access policy drives the increasing use of Sentinel-2 data, especially in developing countries where financial resources for the acquisition of remotely sensed data are limited. The literature also shows that the use of Sentinel-2 data produces high accuracies (>80%) with machine-learning classifiers such as support vector machine (SVM) and Random forest (RF). However, other classifiers such as maximum likelihood analysis are also common. Although Sentinel-2 offers many opportunities for land cover/use classification, there are challenges which include mismatching with Landsat OLI-8 data, a lack of thermal bands, and the differences in spatial resolution among the bands of Sentinel-2. Sentinel-2 data show promise and have the potential to contribute significantly towards land cover/use monitoring.},
author = {Phiri, Darius and Simwanda, Matamyo and Salekin, Serajis and Nyirenda, Vincent R. and Murayama, Yuji and Ranagalage, Manjula},
booktitle = {Remote Sensing},
doi = {10.3390/rs12142291},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2020/Phiri et al._2020_Sentinel-2 data for land coveruse mapping A review.pdf:pdf},
issn = {20724292},
keywords = {Classification,ESA,Land cover/use,Remote sensing,Sentinel-2},
month = {jul},
number = {14},
pages = {2291},
publisher = {Multidisciplinary Digital Publishing Institute},
title = {{Sentinel-2 data for land cover/use mapping: A review}},
url = {https://www.mdpi.com/2072-4292/12/14/2291/htm https://www.mdpi.com/2072-4292/12/14/2291},
volume = {12},
year = {2020}
}
@article{Clarke2021,
abstract = {Seagrasses are regarded as indicators and first line of impact for anthropogenic activities affecting the coasts. The underlying mechanisms driving seagrass cover however have been mostly studied on small scales, making it difficult to establish the connection to seagrass dynamics in an impacted seascape. In this study, hyperspectral airborne imagery, trained from field surveys, was used to investigate broadscale seagrass cover and genus distribution along the coast of Adelaide, South Australia. Overall mapping accuracy was high for both seagrass cover (98%, Kappa = 0.93), and genus level classification (85%, Kappa = 0.76). Spectral separability allowed confident genus mapping in waters up to 10 m depth, revealing a 3.5 ratio between the cover of the dominant Posidonia and Amphibolis. The work identified the absence of Amphibolis in areas historically affected by anthropogenic discharges, which occasionally contained Posidonia and might be recovering. The results suggest hyperspectral imagery as a useful tool to investigate the interplay between seagrass cover and genus distribution at large spatial scales.},
author = {Clarke, Kenneth and Hennessy, Andrew and McGrath, Andrew and Daly, Robert and Gaylard, Sam and Turner, Alison and Cameron, James and Lewis, Megan and Fernandes, Milena B},
doi = {10.1038/s41598-021-83728-6},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2021/Clarke et al._2021_Using hyperspectral imagery to investigate large-scale seagrass cover and genus distribution in a temperate coast.pdf:pdf},
isbn = {4159802183728},
issn = {20452322},
journal = {Scientific Reports},
number = {1},
pages = {1--9},
pmid = {33603192},
publisher = {Nature Publishing Group UK},
title = {{Using hyperspectral imagery to investigate large-scale seagrass cover and genus distribution in a temperate coast}},
url = {https://doi.org/10.1038/s41598-021-83728-6},
volume = {11},
year = {2021}
}
@article{Roelfsema2018,
abstract = {Despite being one of the most important and well-studied coral reefs in the world, the full extent of coral habitat of the Great Barrier Reef (GBR) is not well mapped and there is no current and comprehensive map of the GBR's geomorphic zonation or benthic composition. This paper demonstrates an approach that integrates ecological coral habitat mapping with empirical modelling to map the geomorphic zonation and benthic composition of the “shallow offshore reefs” of the GBR, using the Capricorn Bunker Group (CBG) as a case study. The approach combined environmental data sets and geo-ecological rule sets to identify geomorphic zones. The benthic composition of individual geomorphic zones was mapped for: shallow reef flat zones, using object-based image analysis with context driven rules based on coral reef ecology; and reef slope zones, using levels of wave exposure to predict the distribution of coral types. The environmental data sets used were field-based benthic composition data, Landsat 8 OLI satellite image-derived bottom reflectance, water depth and slope (15 m × 15 m pixel size) data, reef impact data, and modelled wave exposure. The study showed that the combination of geomorphic-ecological rules and models with remote sensing imagery provided robust mapping results over a large ($\sim$2500 km2) reef system, of which 245 km2 was mapped as shallow coral reefs and 88 km2 of that was mapped as areas containing coral. Most importantly, the method produced defined the geomorphic zones and benthic composition of a study area that is significantly larger than the majority of coral reef remote sensing mapping projects previously published. With some modifications, the methods presented have the potential to be applied to the full extent of the shallow offshore reefs of the GBR, or any large reef globally. Monitoring and management of coral reefs for conservation and other purposes, at regional to global scales will benefit from the ability to produce and use this type of essential information on a regular basis.},
author = {Roelfsema, Chris and Kovacs, Eva and Ortiz, Juan Carlos and Wolff, Nicholas H. and Callaghan, David and Wettle, Magnus and Ronan, Mike and Hamylton, Sarah M. and Mumby, Peter J. and Phinn, Stuart},
doi = {10.1016/j.rse.2018.02.005},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2018/Roelfsema et al._2018_Coral reef habitat mapping A combination of object-based image analysis and ecological modelling.pdf:pdf},
issn = {00344257},
journal = {Remote Sensing of Environment},
keywords = {Benthic composition,Benthic habitat map,Capricorn Bunker Group,Geomorphic zonation,Great Barrier Reef,Heron Reef},
number = {February},
pages = {27--41},
title = {{Coral reef habitat mapping: A combination of object-based image analysis and ecological modelling}},
volume = {208},
year = {2018}
}
@article{Stumpf2003,
abstract = {A standard algorithm for determining depth in clear water from passive sensors exists; but it requires tuning of five parameters and does not retrieve depths where the bottom has an extremely low albedo. To address these issues, we developed an empirical solution using a ratio of reflectances that has only two tunable parameters and can be applied to low-albedo features. The two algorithms - the standard linear transform and the new ratio transform - were compared through analysis of IKONOS satellite imagery against lidar bathymetry. The coefficients for the ratio algorithm were tuned manually to a few depths from a nautical chart, yet performed as well as the linear algorithm tuned using multiple linear regression against the lidar. Both algorithms compensate for variable bottom type and albedo (sand, pavement, algae, coral) and retrieve bathymetry in water depths of less than 10-15 m. However, the linear transform does not distinguish depths > 15 m and is more subject to variability across the studied atolls. The ratio transform can, in clear water, retrieve depths in > 25 m of water and shows greater stability between different areas. It also performs slightly better in scattering turbidity than the linear transform. The ratio algorithm is somewhat noisier and cannot always adequately resolve fine morphology (structures smaller than 4-5 pixels) in water depths > 15-20 m. In general, the ratio transform is more robust than the linear transform.},
author = {Stumpf, Richard P. and Holderied, Kristine and Sinclair, Mark},
doi = {10.4319/lo.2003.48.1_part_2.0547},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2003/Stumpf, Holderied, Sinclair_2003_Determination of water depth with high-resolution satellite imagery over variable bottom types.pdf:pdf},
issn = {00243590},
journal = {Limnology and Oceanography},
number = {1 II},
pages = {547--556},
title = {{Determination of water depth with high-resolution satellite imagery over variable bottom types}},
volume = {48},
year = {2003}
}
@article{Green1998,
abstract = {Imaging spectroscopy is of growing interest as a new approach to Earth remote sensing. The Airborne Visible/Infrared Imaging Spectrometer (AVIRIS) was the first imaging sensor to measure the solar reflected spectrum from 400 nm to 2500 nm at 10 nm intervals. The calibration accuracy and signal-to-noise of AVIRIS remain unique. The AVIRIS system as well as the science research and applications have evolved significantly in recent years. The initial design and upgraded characteristics of the AVIRIS system are described in terms of the sensor, calibration, data system, and flight operation. This update on the characteristics of AVIRIS provides the context for the science research and applications that use AVIRIS data acquired in the past several years. Recent science research and applications are reviewed spanning investigations of atmospheric correction, ecology and vegetation, geology and soils, inland and coastal waters, the atmosphere, snow and ice hydrology, biomass burning, environmental hazards, satellite simulation and calibration, commercial applications, spectral algorithms, human infrastructure, as well as spectral modeling.},
author = {Green, Robert O and Eastwood, Michael L and Sarture, Charles M and Chrien, Thomas G and Aronsson, Mikael and Chippendale, Bruce J and Faust, Jessica A and Pavri, Betina E and Chovit, Christopher J and Solis, Manuel and Olah, Martin R and Williams, Orlesa},
doi = {10.1016/S0034-4257(98)00064-9},
file = {:C\:/Users/mha114/Dropbox/Litteratur/1998/Green et al._1998_Imaging Spectroscopy and the Airborne VisibleInfrared Imaging Spectrometer (AVIRIS).pdf:pdf},
issn = {0034-4257},
journal = {Remote Sensing of Environment},
month = {sep},
number = {3},
pages = {227--248},
publisher = {Elsevier},
title = {{Imaging Spectroscopy and the Airborne Visible/Infrared Imaging Spectrometer (AVIRIS)}},
url = {https://www.sciencedirect.com/science/article/pii/S0034425798000649},
volume = {65},
year = {1998}
}
@article{LeBris2016,
abstract = {The invasion of the wild oyster Crassostrea gigas along the western European Atlantic coast has generated changes in the structure and functioning of intertidal ecosystems. Considered as an invasive species and a trophic competitor of the cultivated conspecific oyster, it is now seen as a resource by oyster farmers following recurrent mass summer mortalities of oyster spat since 2008. Spatial distribution maps of wild oyster reefs are required by local authorities to help define management strategies. In this work, visible-near infrared (VNIR) hyperspectral and multispectral remote sensing was investigated to map two contrasted intertidal reef structures: clusters of vertical oysters building three-dimensional dense reefs in muddy areas and oysters growing horizontally creating large flat reefs in rocky areas. A spectral library, collected in situ for various conditions with an ASD spectroradiometer, was used to run Spectral Angle Mapper classifications on airborne data obtained with an HySpex sensor (160 spectral bands) and SPOT satellite HRG multispectral data (3 spectral bands). With HySpex spectral/spatial resolution, horizontal oysters in the rocky area were correctly classified but the detection was less efficient for vertical oysters in muddy areas. Poor results were obtained with the multispectral image and from spatially or spectrally degraded HySpex data, it was clear that the spectral resolution was more important than the spatial resolution. In fact, there was a systematic mud deposition on shells of vertical oyster reefs explaining the misclassification of 30% of pixels recognized as mud or microphytobenthos. Spatial distribution maps of oyster reefs were coupled with in situ biomass measurements to illustrate the interest of a remote sensing product to provide stock estimations of wild oyster reefs to be exploited by oyster producers. This work highlights the interest of developing remote sensing techniques for aquaculture applications in coastal areas.},
author = {{Le Bris}, Anthony and Rosa, Philippe and Lerouxel, Astrid and Cognie, Bruno and Gernez, Pierre and Launeau, Patrick and Robin, Marc and Barill{\'{e}}, Laurent},
doi = {10.1016/j.ecss.2016.01.039},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2016/Le Bris et al._2016_Hyperspectral remote sensing of wild oyster reefs.pdf:pdf},
issn = {02727714},
journal = {Estuarine, Coastal and Shelf Science},
keywords = {Benthos,Crassostrea gigas,Hyperspectral,Oyster reefs,Remote sensing,Tidal flats},
pages = {1--12},
title = {{Hyperspectral remote sensing of wild oyster reefs}},
volume = {172},
year = {2016}
}
@article{Kuhwald2021,
abstract = {Seagrass meadows are one of the most important benthic habitats in the Baltic Sea. Nevertheless, spatially continuous mapping data of Zostera marina, the predominant seagrass species in the Baltic Sea, are lacking in the shallow coastal waters. Sentinel-2 turned out to be valuable for mapping coastal benthic habitats in clear waters, whereas knowledge in turbid waters is rare. Here, we transfer a clear water mapping approach to turbid waters to assess how Sentinel-2 can contribute to seagrass mapping in the Western Baltic Sea. Sentinel-2 data were atmospherically corrected using ACOLITE and subsequently corrected for water column effects. To generate a data basis for training and validating random forest classification models, we developed an upscaling approach using video transect data and aerial imagery. We were able to map five coastal benthic habitats: bare sand (25 km²), sand dominated (16 km²), seagrass dominated (7 km²), dense seagrass (25 km²) and mixed substrates with red/ brown algae (3.5 km²) in a study area along the northern German coastline. Validation with independent data pointed out that water column correction does not significantly improve classification results compared to solely atmospherically corrected data (balanced overall accuracies $\sim$0.92). Within optically shallow waters (0–4 m), per class and overall balanced accuracies (>0.82) differed marginally depending on the water depth. Overall balanced accuracy became worse (<0.8) approaching the border to optically deep water ($\sim$ 5 m). The spatial resolution of Sentinel-2 (10–20 m) allowed delineating detailed spatial patterns of seagrass habitats, which may serve as a basis to retrieve spatially continuous data for ecologically relevant metrics such as patchiness. Thus, Sentinel-2 can contribute unprecedented information for seagrass mapping between 0 and around 5 m water depths in the Western Baltic Sea.},
author = {Kuhwald, Katja and {Schneider von Deimling}, Jens and Schubert, Philipp and Oppelt, Natascha},
doi = {10.1002/rse2.246},
editor = {Scales, Kylie and Lecours, Vincent},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2021/Kuhwald et al._2021_How can Sentinel-2 contribute to seagrass mapping in shallow, turbid Baltic Sea waters.pdf:pdf},
issn = {20563485},
journal = {Remote Sensing in Ecology and Conservation},
keywords = {Baltic sea,Sentinel-2,benthic habitat mapping,eelgrass,random forest,submerged aquatic vegetation},
month = {dec},
number = {3},
pages = {328--346},
publisher = {John Wiley & Sons, Ltd},
title = {{How can Sentinel-2 contribute to seagrass mapping in shallow, turbid Baltic Sea waters?}},
url = {https://onlinelibrary.wiley.com/doi/full/10.1002/rse2.246 https://onlinelibrary.wiley.com/doi/abs/10.1002/rse2.246 https://zslpublications.onlinelibrary.wiley.com/doi/10.1002/rse2.246},
volume = {8},
year = {2022}
}
@article{Blaschke2010,
abstract = {Remote sensing imagery needs to be converted into tangible information which can be utilised in conjunction with other data sets, often within widely used Geographic Information Systems (GIS). As long as pixel sizes remained typically coarser than, or at the best, similar in size to the objects of interest, emphasis was placed on per-pixel analysis, or even sub-pixel analysis for this conversion, but with increasing spatial resolutions alternative paths have been followed, aimed at deriving objects that are made up of several pixels. This paper gives an overview of the development of object based methods, which aim to delineate readily usable objects from imagery while at the same time combining image processing and GIS functionalities in order to utilize spectral and contextual information in an integrative way. The most common approach used for building objects is image segmentation, which dates back to the 1970s. Around the year 2000 GIS and image processing started to grow together rapidly through object based image analysis (OBIA - or GEOBIA for geospatial object based image analysis). In contrast to typical Landsat resolutions, high resolution images support several scales within their images. Through a comprehensive literature review several thousand abstracts have been screened, and more than 820 OBIA-related articles comprising 145 journal papers, 84 book chapters and nearly 600 conference papers, are analysed in detail. It becomes evident that the first years of the OBIA/GEOBIA developments were characterised by the dominance of 'grey' literature, but that the number of peer-reviewed journal articles has increased sharply over the last four to five years. The pixel paradigm is beginning to show cracks and the OBIA methods are making considerable progress towards a spatially explicit information extraction workflow, such as is required for spatial planning as well as for many monitoring programmes. {\textcopyright} 2009 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS).},
author = {Blaschke, T.},
doi = {10.1016/j.isprsjprs.2009.06.004},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2010/Blaschke_2010_Object based image analysis for remote sensing.pdf:pdf},
issn = {09242716},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
keywords = {GEOBIA,GIScience,Multiscale image analysis,OBIA,Object based image analysis},
number = {1},
pages = {2--16},
publisher = {Elsevier B.V.},
title = {{Object based image analysis for remote sensing}},
url = {http://dx.doi.org/10.1016/j.isprsjprs.2009.06.004},
volume = {65},
year = {2010}
}
@article{Mount2005,
abstract = {The behavior of light at the air/water interface has substantial effects on the quality of vertical, or nadir-looking imagery used to interpret subsurface features for purposes such as marine habitat mapping. Reflection of the direct solar beam into the sensor by waves on the surface of the water creates bright glints, which obscure bottom features of interest. Sun angle, refraction, and reflection of the direct solar beam affect the amount of subsurface illumination and shadowing of bottom features. Simple interpretations of these sea surface effects are made with sufficient accuracy to improve planning for airborne, vertical image capture, particularly aerial photography or video imagery. The time available for image capture over shallow water is typically limited to a short period in the morning. The start time is controlled by subsurface illumination levels, which are determined by sun angle and locally variable factors, such as light attenuation by the water column, rather than surface reflection or subsurface shadowing. The end time is determined by sun glitter effects, which in this case study, are predictable from sun angle, camera field of view, and wind speed with an R2 value of 0.9554. {\textcopyright} 2005 American Society for Photogrammetry and Remote Sensing.},
author = {Mount, Richard},
doi = {10.14358/PERS.71.12.1407},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2005/Mount_2005_Acquisition of through-water aerial survey images Surface effects and the prediction of sun glitter and subsurface illuminati.pdf:pdf},
issn = {00991112},
journal = {Photogrammetric Engineering and Remote Sensing},
number = {12},
pages = {1407--1415},
publisher = {American Society for Photogrammetry and Remote Sensing},
title = {{Acquisition of through-water aerial survey images: Surface effects and the prediction of sun glitter and subsurface illumination}},
volume = {71},
year = {2005}
}
@article{Verrelst2012a,
abstract = {ESA's upcoming satellites Sentinel-2 (S2) and Sentinel-3 (S3) aim to ensure continuity for Landsat 5/7, SPOT-5, SPOT-Vegetation and Envisat MERIS observations by providing superspectral images of high spatial and temporal resolution. S2 and S3 will deliver near real-time operational products with a high accuracy for land monitoring. This unprecedented data availability leads to an urgent need for developing robust and accurate retrieval methods. Machine learning regression algorithms may be powerful candidates for the estimation of biophysical parameters from satellite reflectance measurements because of their ability to perform adaptive, nonlinear data fitting.By using data from the ESA-led field campaign SPARC (Barrax, Spain) we have compared the utility of four state-of-the-art machine learning regression algorithms and four different S2 and S3 band settings to assess three important biophysical parameters: leaf chlorophyll content (Chl), leaf area index (LAI) and fractional vegetation cover (FVC). The tested Sentinel configurations were: S2-10. m (4 bands), S2-20. m (8 bands), S2-60. m (10 bands) and S3-300. m (19 bands), and the tested methods were: neural networks (NN), support vector regression (SVR), kernel ridge regression (KRR), and Gaussian processes regression (GPR).GPR outperformed the other retrieval methods for the majority of tested configurations and was the only method that reached the 10% precision required by end users in the estimation of Chl. Also, although validated with an RMSE accuracy around 20%, GPR yielded optimal LAI and FVC estimates at highest S2 spatial resolution of 10. m with only four bands. In addition to high accuracy values, GPR also provided confidence intervals of the estimates and insight in relevant bands, which are key advantages over the other methods. Given all this, GPR proved to be a fast and accurate nonlinear retrieval algorithm that can be potentially implemented for operational monitoring applications. {\textcopyright} 2011 Elsevier Inc.},
author = {Verrelst, Jochem and Mu{\~{n}}oz, Jordi and Alonso, Luis and Delegido, Jes{\'{u}}s and Rivera, Juan Pablo and Camps-Valls, Gustavo and Moreno, Jos{\'{e}}},
doi = {10.1016/j.rse.2011.11.002},
file = {:C\:/Users/mha114/Dropbox/Litteratur/2012/Verrelst et al._2012_Machine learning regression algorithms for biophysical parameter retrieval Opportunities for Sentinel-2 and -3.pdf:pdf},
issn = {00344257},
journal = {Remote Sensing of Environment},
keywords = {Biophysical parameter retrieval,Gaussian Processes regression (GPR),Kernel ridge regression (KRR),Machine learning,Regression algorithms,Sentinel-2,Sentinel-3,Support vector regression (SVR)},
month = {mar},
pages = {127--139},
publisher = {Elsevier},
title = {{Machine learning regression algorithms for biophysical parameter retrieval: Opportunities for Sentinel-2 and -3}},
url = {https://www.sciencedirect.com/science/article/pii/S003442571100397X},
volume = {118},
year = {2012}
}
