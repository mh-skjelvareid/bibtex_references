Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Schlapfer2020,
abstract = {Remote sensing with unmanned aerial vehicles (UAVs) is a fast and cost-efficient tool for mapping and environmental monitoring. The sensors are operated at low flight altitudes, usually below 500 m above ground, leading to spatial resolutions up to the centimeter range. This type of data causes new challenges in atmospheric compensation and surface reflectance retrieval. Based on these specific boundary conditions, a new drone based atmospheric correction concept (DROACOR) is proposed, which is designed for currently available UAV based sensors. It is suited for multispectral visible/near infrared sensors as well as hyperspectral instruments covering the 400-1000&thinsp;nm spectral region or the 400-2500&thinsp;nm spectrum. The goal of the development is a fully automatic processor which dynamically adjusts to the given instrument and the atmospheric conditions. Optionally, irradiance measurements from simultaneously measured cosine receptors or from in-field reference panels can be taken into account to improve the processing quality by adjusting the irradiance parameter or by performing an in-flight vicarious calibration. Examples of DROACOR processing results are presented for a multispectral image data set and a hyperspectral data set, both acquired at variable flight altitudes. The resulting spectra show the applicability of the methods for both sensor types and an accuracy level below 2.5% reflectance units.},
author = {Schl{\"{a}}pfer, D. and Popp, C. and Richter, R.},
doi = {10.5194/isprs-archives-XLIII-B3-2020-473-2020},
file = {:C\:/Users/mha114/Dropbox/Litteratur_Mendeley/2020/Schl{\"{a}}pfer, Popp, Richter_2020_Drone data atmospheric correction concept for multi-and hyperspectral imagery-The droacor model.pdf:pdf},
issn = {16821750},
journal = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
keywords = {Atmospheric Correction,Drone data processing,Reflectance Retrieval,irradiance correction},
number = {B3},
pages = {473--478},
title = {{Drone data atmospheric correction concept for multi-and hyperspectral imagery-The droacor model}},
volume = {43},
year = {2020}
}
@article{Thompson2017,
abstract = {Remote imaging spectroscopy from 400 to 800 nm can use benthic reflectance signatures to map the composition and condition of shallow water ecosystems. We present a novel probabilistic approach to jointly estimate the seafloor reflectance and water properties while flexibly incorporating varied domain knowledge and in situ measurements. The inversion transforms remote radiance data with an atmospheric correction followed by a water column correction. Benthic reflectance and water optical properties are both represented by linear mixtures of endmember spectra. We combine remote measurements, prior knowledge and field data using a flexible Bayesian optimal estimation, solving for the Maximum A Posteriori (MAP) combination of water column properties, seafloor reflectance, and depth. We then demonstrate performance in controlled simulations and in overflights of a coral reef in Hawaii with coincident in situ measurements. The measurement approach helps lay a foundation for wide-area airborne mapping of the condition of threatened coastal ecosystems such as coral reefs.},
author = {Thompson, David R. and Hochberg, Eric J. and Asner, Gregory P. and Green, Robert O. and Knapp, David E. and Gao, Bo Cai and Garcia, Rodrigo and Gierach, Michelle and Lee, Zhongping and Maritorena, Stephane and Fick, Ronald},
doi = {10.1016/j.rse.2017.07.030},
issn = {00344257},
journal = {Remote Sensing of Environment},
keywords = {Atmospheric correction,Coral reefs,Imaging spectroscopy,Remote sensing},
month = {oct},
pages = {18--30},
publisher = {Elsevier Inc.},
title = {{Airborne mapping of benthic reflectance spectra with Bayesian linear mixtures}},
volume = {200},
year = {2017}
}
@article{Wei2019,
abstract = {The fine classification of crops is critical for food security and agricultural management. There are many different species of crops, some of which have similar spectral curves. As a result, the precise classification of crops is a difficult task. Although the classification methods that incorporate spatial information can reduce the noise and improve the classification accuracy, to a certain extent, the problem is far from solved. Therefore, in this paper, the method of spatial-spectral fusion based on conditional random fields (SSF-CRF) for the fine classification of crops in UAV-borne hyperspectral remote sensing imagery is presented. The proposed method designs suitable potential functions in a pairwise conditional random field model, fusing the spectral and spatial features to reduce the spectral variation within the homogenous regions and accurately identify the crops. The experiments on hyperspectral datasets of the cities of Hanchuan and Honghu in China showed that, compared with the traditional methods, the proposed classification method can effectively improve the classification accuracy, protect the edges and shapes of the features, and relieve excessive smoothing, while retaining detailed information. This method has important significance for the fine classification of crops in hyperspectral remote sensing imagery.},
author = {Wei, Lifei and Yu, Ming and Zhong, Yanfei and Zhao, Ji and Liang, Yajing and Hu, Xin},
doi = {10.3390/rs11070780},
file = {:C\:/Users/mha114/Dropbox/Litteratur_Mendeley/2019/Wei et al._2019_Spatial-spectral fusion based on conditional random fields for the fine classification of crops in UAV-borne hyperspectr.pdf:pdf},
isbn = {2017111108110},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Conditional random fields,Fine crop classification,Hyperspectral remote sensing imagery,Spectral-spatial fusion,Unmanned aerial vehicle},
number = {7},
title = {{Spatial-spectral fusion based on conditional random fields for the fine classification of crops in UAV-borne hyperspectral remote sensing imagery}},
volume = {11},
year = {2019}
}
@article{Kok2020,
abstract = {This paper describes an aerial drone-based hyperspectral remote sensing system and recommends standard operating procedures for successful deployment in marine environments. Unlike conventional drone operations based on land, working in the open ocean requires additional legal and operational considerations to be addressed in order to collect and process calibrated quality hyperspectral data. The hyperspectral data is processed and converted to reflectance using field calibration targets, priming the dataset for analysis. The data is ingested into a processing pipeline to facilitate data management, distribution and retrieval. The resulting hyperspectral map and information are invaluable for scientists, academics, policymakers and managers to utilise. A case study is presented to demonstrate the results of habitat mapping in a shallow reef region at Keeper Reef, Great Barrier Reef, Australia.},
author = {Kok, Jon and Bainbridge, Scott and Olsen, Melanie and Rigby, Paul},
doi = {10.1109/IEEECONF38699.2020.9389025},
file = {:C\:/Users/mha114/Dropbox/Litteratur_Mendeley/2020/Kok et al._2020_Towards Effective Aerial Drone-based Hyperspectral Remote Sensing of Coral Reefs.pdf:pdf},
isbn = {9781728154466},
journal = {2020 Global Oceans 2020: Singapore - U.S. Gulf Coast},
keywords = {Hyperspectral,UAV,coral reefs,drone,remote sensing},
title = {{Towards Effective Aerial Drone-based Hyperspectral Remote Sensing of Coral Reefs}},
year = {2020}
}
@article{Martin2021,
abstract = {Beach litter assessments rely on time inefficient and high human cost protocols, mining the attainment of global beach litter estimates. Here we show the application of an emerging technique, the use of drones for acquisition of high-resolution beach images coupled with machine learning for their automatic processing, aimed at achieving the first national-scale beach litter survey completed by only one operator. The aerial survey had a time efficiency of 570 ± 40 m2 min−1 and the machine learning reached a mean (±SE) detection sensitivity of 59 ± 3% with high resolution images. The resulting mean (±SE) litter density on Saudi Arabian shores of the Red Sea is of 0.12 ± 0.02 litter items m−2, distributed independently of the population density in the area around the sampling station. Instead, accumulation of litter depended on the exposure of the beach to the prevailing wind and litter composition differed between islands and the main shore, where recreational activities are the major source of anthropogenic debris. A national-scale monitoring of beach litter along the Red Sea coast of Saudi Arabia, conducted by a single drone operator, shows that litter distributes according to wind exposure.},
author = {Martin, Cecilia and Zhang, Qiannan and Zhai, Dongjun and Zhang, Xiangliang and Duarte, Carlos M.},
doi = {10.1016/j.envpol.2021.116730},
issn = {18736424},
journal = {Environmental Pollution},
keywords = {Beach litter,Deep neural network,Marine debris,Plastic,Unmanned aerial vehicles},
month = {feb},
pages = {116730},
pmid = {33652184},
publisher = {Elsevier},
title = {{Enabling a large-scale assessment of litter along Saudi Arabian red sea shores by combining drones and machine learning}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0269749121003109},
volume = {277},
year = {2021}
}
@article{Rossiter2020,
abstract = {Intertidal macroalgal communities mark the boundary of the marine realm and are faced with many direct and indirect anthropogenic pressures. The effective and sustainable management of these resources must be underpinned by accurate, efficient and cost-effective environmental data collection. Traditional field survey methods, whilst accurate, are time-consuming and limited in the area that can be covered. Remote sensing permits large areas to be rapidly surveyed but the effectiveness of satellites and aircraft for mapping fine-scale intertidal macroalgal mapping is limited by their coarse spatial resolution and restricted operational flexibility. The rapid development of unoccupied aerial vehicle (UAV) and sensor technology can address these issues and provide a potential alternative to established remote sensing platforms. Here, a detailed methodology is presented for the assessment of the commercially and ecologically important intertidal brown macroalga Ascophyllum nodosum using a multirotor UAV and pushbroom hyperspectral sensor. Two different classifiers, Maximum Likelihood Classifier (MLC) and Spectral Angle Mapper (SAM), were compared along with two different sources of spectral profiles, one collected in-situ with a spectral radiometer and the other derived from hyperspectral imagery. Of the classifiers compared, both trained using image-derived spectra, MLC more accurately classified A. nodosum, and other common intertidal species and substratum (Overall Accuracy (OA) 94.7%) than SAM (OA 81.1%). In addition, SAM, trained using in-situ spectra, was the least accurate of the three classifier workflows used (OA 71.4%). The low accuracy of the spectral radiometer approach was likely due to high levels of noise present in the hyperspectral data, a result of the relative instability of the UAV platform causing vibration. The accurate mapping of non-target species also highlights the applicability of this methodology for a broader range of intertidal macroalgal species and communities. This research clearly demonstrates the potential of UAV-mounted hyperspectral remote sensing for mapping the spatially and spectral complex macroalgal habitats found within the intertidal zone.},
author = {Rossiter, Thomas and Furey, Thomas and McCarthy, Tim and Stengel, Dagmar B.},
doi = {10.1016/j.ecss.2020.106789},
file = {:C\:/Users/mha114/Dropbox/Litteratur_Mendeley/2020/Rossiter et al._2020_UAV-mounted hyperspectral mapping of intertidal macroalgae.pdf:pdf},
issn = {02727714},
journal = {Estuarine, Coastal and Shelf Science},
keywords = {Ascophyllum nodosum,Hyperspectral,Intertidal,Macroalgae,Remote sensing,UAVs},
number = {August 2019},
pages = {106789},
publisher = {Elsevier Ltd},
title = {{UAV-mounted hyperspectral mapping of intertidal macroalgae}},
url = {https://doi.org/10.1016/j.ecss.2020.106789},
volume = {242},
year = {2020}
}
@inproceedings{English2014,
address = {Portland, Maine},
author = {English, David and Zhang, Minwei and Hu, Chuanmin and Carlson, Paul and Herwitz, Stan and Nakanishi, Keith and Pan, Zhihong and Merrill, John},
booktitle = {Ocean Optics XXII},
file = {:C\:/Users/mha114/Dropbox/Litteratur_Mendeley/2014/English et al._2014_Hyperspectral remote sensing of shallow coastal waters in the Florida Keys using Unmanned Aircraft Systems ( UAS ) I.pdf:pdf},
number = {October},
title = {{Hyperspectral remote sensing of shallow coastal waters in the Florida Keys using Unmanned Aircraft Systems ( UAS ): Initial results from atmospheric correction and glint reduction}},
year = {2014}
}
@article{Trier2018,
abstract = {This article compares four new automatic methods to discriminate between spruce, pine and birch, which are the dominating tree species in Norwegian forests. Airborne laser scanning and hyperspectral data were used. The laser scanning data was used to mask pixels with low or no vegetation in the hyperspectral data. A green–blue ratio was used to remove shadow areas from tree canopies, and the normalized difference vegetation index to remove dead vegetation and non-vegetation. The best method was hyperspectral pixel classification with 160 spectral channels in the visible and near-infrared spectrum, using a deep neural network. This method achieved 87% correct classification rate. Partial least squares regression for hyperspectral pixel classification achieved 78%. Deep neural network image classification using canopy height blended with three hyperspectral channels achieved 74%. A simple pixel classification method based on two spectral indices resulted in 67% correct classification. A possible future improvement is to find a better way to combine hyperspectral data with canopy height data in a deep neural network.},
author = {Trier, {\O}ivind Due and Salberg, Arnt B{\o}rre and Kermit, Martin and Rudjord, {\O}ystein and Gobakken, Terje and N{\ae}sset, Erik and Aarsten, Dagrun},
doi = {10.1080/22797254.2018.1434424},
file = {:C\:/Users/mha114/Dropbox/Litteratur_Mendeley/2018/Trier et al._2018_Tree species classification in Norway from airborne hyperspectral and airborne laser scanning data.pdf:pdf},
issn = {22797254},
journal = {European Journal of Remote Sensing},
keywords = {Lidar,automatic processing,canopy height model,deep learning,forestry,imaging spectroscopy},
month = {jan},
number = {1},
pages = {336--351},
publisher = {Taylor & Francis},
title = {{Tree species classification in Norway from airborne hyperspectral and airborne laser scanning data}},
url = {https://www.tandfonline.com/doi/abs/10.1080/22797254.2018.1434424},
volume = {51},
year = {2018}
}
@article{Honkavaara2013a,
abstract = {Imaging using lightweight, unmanned airborne vehicles (UAVs) is one of the most rapidly developing fields in remote sensing technology. The new, tunable, Fabry-Perot interferometer-based (FPI) spectral camera, which weighs less than 700 g, makes it possible to collect spectrometric image blocks with stereoscopic overlaps using light-weight UAV platforms. This new technology is highly relevant, because it opens up new possibilities for measuring and monitoring the environment, which is becoming increasingly important for many environmental challenges. Our objectives were to investigate the processing and use of this new type of image data in precision agriculture. We developed the entire processing chain from raw images up to georeferenced reflectance images, digital surface models and biomass estimates. The processing integrates photogrammetric and quantitative remote sensing approaches. We carried out an empirical assessment using FPI spectral imagery collected at an agricultural wheat test site in the summer of 2012. Poor weather conditions during the campaign complicated the data processing, but this is one of the challenges that are faced in operational applications. The results indicated that the camera performed consistently and that the data processing was consistent, as well. During the agricultural experiments, promising results were obtained for biomass estimation when the spectral data was used and when an appropriate radiometric correction was applied to the data. Our results showed that the new FPI technology has a great potential in precision agriculture and indicated many possible future research topics. {\textcopyright} 2013 by the authors.},
author = {Honkavaara, Eija and Saari, Heikki and Kaivosoja, Jere and P{\"{o}}l{\"{o}}nen, Ilkka and Hakala, Teemu and Litkey, Paula and M{\"{a}}kynen, Jussi and Pesonen, Liisa},
doi = {10.3390/rs5105006},
file = {:C\:/Users/mha114/Dropbox/Litteratur_Mendeley/2013/Honkavaara et al._2013_Processing and assessment of spectrometric, stereoscopic imagery collected using a lightweight UAV spectral camer.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Agriculture,Biomass,Dsm,Hyperspectral,Photogrammetry,Point cloud,Radiometry,Spectrometry,Uav},
month = {oct},
number = {10},
pages = {5006--5039},
publisher = {Multidisciplinary Digital Publishing Institute},
title = {{Processing and assessment of spectrometric, stereoscopic imagery collected using a lightweight UAV spectral camera for precision agriculture}},
url = {http://www.mdpi.com/2072-4292/5/10/5006},
volume = {5},
year = {2013}
}
@article{Kemker2018,
abstract = {Deep convolutional neural networks (DCNNs) have been used to achieve state-of-the-art performance on many computer vision tasks (e.g., object recognition, object detection, semantic segmentation) thanks to a large repository of annotated image data. Large labeled datasets for other sensor modalities, e.g., multispectral imagery (MSI), are not available due to the large cost and manpower required. In this paper, we adapt state-of-the-art DCNN frameworks in computer vision for semantic segmentation for MSI imagery. To overcome label scarcity for MSI data, we substitute real MSI for generated synthetic MSI in order to initialize a DCNN framework. We evaluate our network initialization scheme on the new RIT-18 dataset that we present in this paper. This dataset contains very-high resolution MSI collected by an unmanned aircraft system. The models initialized with synthetic imagery were less prone to over-fitting and provide a state-of-the-art baseline for future work.},
archivePrefix = {arXiv},
arxivId = {1703.06452},
author = {Kemker, Ronald and Salvaggio, Carl and Kanan, Christopher},
doi = {10.1016/j.isprsjprs.2018.04.014},
eprint = {1703.06452},
file = {:C\:/Users/mha114/Dropbox/Litteratur_Mendeley/2018/Kemker, Salvaggio, Kanan_2018_Algorithms for semantic segmentation of multispectral remote sensing imagery using deep learning.pdf:pdf},
issn = {09242716},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
keywords = {Convolutional neural network,Deep learning,Multispectral,Semantic segmentation,Synthetic imagery,Unmanned aerial system},
number = {April},
pages = {60--77},
publisher = {Elsevier},
title = {{Algorithms for semantic segmentation of multispectral remote sensing imagery using deep learning}},
url = {https://doi.org/10.1016/j.isprsjprs.2018.04.014},
volume = {145},
year = {2018}
}
@article{Sandino2017,
abstract = {The increased technological developments in Unmanned Aerial Vehicles (UAVs) combined with artificial intelligence and Machine Learning (ML) approaches have opened the possibility of remote sensing of extensive areas of arid lands. In this paper, a novel approach towards the detection of termite mounds with the use of a UAV, hyperspectral imagery, ML and digital image processing is intended. A new pipeline process is proposed to detect termite mounds automatically and to reduce, consequently, detection times. For the classification stage, several ML classification algorithms' outcomes were studied, selecting support vector machines as the best approach for their role in image classification of pre-existing termite mounds. Various test conditions were applied to the proposed algorithm, obtaining an overall accuracy of 68%. Images with satisfactory mound detection proved that the method is “resolution-dependent”. These mounds were detected regardless of their rotation and position in the aerial image. However, image distortion reduced the number of detected mounds due to the inclusion of a shape analysis method in the object detection phase, and image resolution is still determinant to obtain accurate results. Hyperspectral imagery demonstrated better capabilities to classify a huge set of materials than implementing traditional segmentation methods on RGB images only.},
author = {Sandino, Juan and Wooler, Adam and Gonzalez, Felipe},
doi = {10.3390/s17102196},
file = {:C\:/Users/mha114/Dropbox/Litteratur_Mendeley/2017/Sandino, Wooler, Gonzalez_2017_Towards the automatic detection of pre-existing termite mounds through UAS and hyperspectral imagery.pdf:pdf},
issn = {14248220},
journal = {Sensors (Switzerland)},
keywords = {Hyperspectral camera,Image segmentation,Machine learning,Pre-existing termite mounds,Support vector machines,UAV},
month = {sep},
number = {10},
pages = {2196},
pmid = {28946639},
publisher = {MDPI AG},
title = {{Towards the automatic detection of pre-existing termite mounds through UAS and hyperspectral imagery}},
url = {http://www.mdpi.com/1424-8220/17/10/2196},
volume = {17},
year = {2017}
}
@techreport{Schmiel2023a,
author = {Schmiel, Alexandre C. G. and Thormar, Jonas and Oveland, Ivar and Thorsnes, Terje and Elvenes, Sigrid and Kurz, Tobias and Welde, Helge},
file = {:C\:/Users/mha114/Dropbox/Litteratur_Mendeley/2023/Schmiel et al._2023_Summary report of datasets acquired for the purpose of method development within the Marine Base Maps for the Coasta.pdf:pdf},
title = {{Summary report of datasets acquired for the purpose of method development within the Marine Base Maps for the Coastal Zone (Marine grunnkart i kystsonen) project at Fj{\o}l{\o}y and Kloster{\o}y, Stavanger, Norway}},
year = {2023}
}
@article{Zhong2018b,
abstract = {In recent years, with the rapid development of unmanned aerial vehicles (UAVs) and lightweight hyperspectral imaging (HSI) sensors, mini-UAV-borne hyperspectral remote sensing (HRS) systems have been developed and demonstrate great value and application potential. Compared to spaceborne and airborne HSI systems, mini-UAV-borne HSI systems come with relatively low manufacturing and running costs and have thus become a new research focus in the field of HRS.},
author = {Zhong, Yanfei and Wang, Xinyu and Xu, Yao and Wang, Shaoyu and Jia, Tianyi and Hu, Xin and Zhao, Ji and Wei, Lifei and Zhang, Liangpei},
doi = {10.1109/MGRS.2018.2867592},
file = {:C\:/Users/mha114/Dropbox/Litteratur_Mendeley/2018/Zhong et al._2018_Mini-UAV-Borne Hyperspectral Remote Sensing From Observation and Processing to Applications.pdf:pdf},
issn = {21686831},
journal = {IEEE Geoscience and Remote Sensing Magazine},
month = {dec},
number = {4},
pages = {46--62},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Mini-UAV-Borne Hyperspectral Remote Sensing: From Observation and Processing to Applications}},
volume = {6},
year = {2018}
}
@article{Tait2019,
abstract = {Developments in the capabilities and affordability of unmanned aerial vehicles (UAVs) have led to an explosion in their use for a range of ecological and agricultural remote sensing applications. However, the ubiquity of visible light cameras aboard readily available UAVs may be limiting the application of these devices for fine-scale, high taxonomic resolution monitoring. Here we compare the use of RGB and multispectral cameras deployed aboard UAVs for assessing intertidal and shallow subtidal marine macroalgae to a high taxonomic resolution. Our results show that the diverse spectral profiles of marine macroalgae naturally lend themselves to remote sensing and habitat classification. Furthermore, we show that biodiversity assessments, particularly in shallow subtidal habitats, are enhanced using six-band discrete wavelength multispectral sensors (81% accuracy, Cohen's Kappa) compared to three-band broad channel RGB sensors (79% accuracy, Cohen's Kappa) for 10 habitat classes. Combining broad band RGB signals and narrow band multispectral sensing further improved the accuracy of classification with a combined accuracy of 90% (Cohen's Kappa). Despite notable improvements in accuracy with multispectral imaging, RGB sensors were highly capable of broad habitat classification and rivaled multispectral sensors for classifying intertidal habitats. High spatial scale monitoring of turbid exposed rocky reefs presents a unique set of challenges, but the limitations of more traditional methods can be overcome by targeting ideal conditions with UAVs.},
author = {Tait, Leigh and Bind, Jochen and Charan-Dixon, Hannah and Hawes, Ian and Pirker, John and Schiel, David},
doi = {10.3390/rs11192332},
file = {:C\:/Users/mha114/Dropbox/Litteratur_Mendeley/2019/Tait et al._2019_Unmanned aerial vehicles (UAVs) for monitoring macroalgal biodiversity Comparison of RGB and multispectral imaging sens.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Biodiversity,Classification,Drones,Habitat,Macroalgae,Multispectral,Unmanned aerial vehicles (UAVs)},
month = {oct},
number = {19},
pages = {2332},
publisher = {Multidisciplinary Digital Publishing Institute},
title = {{Unmanned aerial vehicles (UAVs) for monitoring macroalgal biodiversity: Comparison of RGB and multispectral imaging sensors for biodiversity assessments}},
url = {https://www.mdpi.com/2072-4292/11/19/2332/htm https://www.mdpi.com/2072-4292/11/19/2332},
volume = {11},
year = {2019}
}
